{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3da4a3d5",
   "metadata": {},
   "source": [
    "A (cluster model) + B (stabilizer features) + C (treatment outlier) Tambah D (Tweedie) dan E (hierarchy) sebagai refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f82f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app/profiling/sku_profiler.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def build_sku_profile(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"qty\"] = df[\"qty\"].astype(float)\n",
    "\n",
    "    profile = (\n",
    "        df.groupby([\"cabang\", \"sku\"])\n",
    "          .agg(\n",
    "              n_months=(\"periode\", \"nunique\"),\n",
    "              qty_mean=(\"qty\", \"mean\"),\n",
    "              qty_std=(\"qty\", \"std\"),\n",
    "              qty_max=(\"qty\", \"max\"),\n",
    "              qty_min=(\"qty\", \"min\"),\n",
    "              total_qty=(\"qty\", \"sum\"),\n",
    "              zero_months=(\"qty\", lambda x: (x == 0).sum()),\n",
    "          )\n",
    "          .reset_index()\n",
    "    )\n",
    "\n",
    "    profile[\"zero_ratio\"] = profile[\"zero_months\"] / profile[\"n_months\"]\n",
    "    profile[\"cv\"] = profile[\"qty_std\"] / profile[\"qty_mean\"].replace(0, np.nan)\n",
    "\n",
    "    # demand_level_bin\n",
    "    profile[\"demand_level\"] = pd.qcut(profile[\"qty_mean\"], q=4, labels=[0,1,2,3])\n",
    "\n",
    "    return profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79428b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app/profiling/clustering.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def run_sku_clustering(profile: pd.DataFrame, n_clusters=4) -> pd.DataFrame:\n",
    "    \n",
    "    cluster_feats = [\"qty_mean\", \"cv\", \"zero_ratio\"]\n",
    "    prof_clean = profile.dropna(subset=cluster_feats).copy()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(prof_clean[cluster_feats].values)\n",
    "\n",
    "    km = KMeans(n_clusters=n_clusters, random_state=1337, n_init=\"auto\")\n",
    "    prof_clean[\"cluster\"] = km.fit_predict(X_scaled)\n",
    "\n",
    "    profile = profile.merge(\n",
    "        prof_clean[[\"cabang\", \"sku\", \"cluster\"]],\n",
    "        on=[\"cabang\", \"sku\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    profile[\"cluster\"] = profile[\"cluster\"].fillna(-1).astype(int)\n",
    "    return profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88cb56d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app/features/stabilizer_features.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def add_stabilizer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Tambah fitur stabilizer:\n",
    "    - qty_mean_cs, qty_std_cs, qty_cnt_cs: dihitung HANYA dari data train (is_train == 1)\n",
    "    - seasonal_ratio_12, volatility_score: dihitung di level panel dengan rolling causal\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Stats SKU HANYA dari train (supaya tidak ngintip test)\n",
    "    df_train = df[df[\"is_train\"] == 1].copy()\n",
    "\n",
    "    sku_stats = (\n",
    "        df_train.groupby([\"cabang\",\"sku\"])[\"qty\"]\n",
    "        .agg([\"mean\",\"std\",\"count\"])\n",
    "        .reset_index()\n",
    "    )\n",
    "    sku_stats.columns = [\"cabang\",\"sku\",\"qty_mean_cs\",\"qty_std_cs\",\"qty_cnt_cs\"]\n",
    "\n",
    "    # merge ke full panel (train + test)\n",
    "    df = df.merge(sku_stats, on=[\"cabang\",\"sku\"], how=\"left\")\n",
    "\n",
    "    # rolling + seasonal ratio pakai seri full, tapi rolling itu causal (hanya masa lalu)\n",
    "    df = df.sort_values([\"cabang\",\"sku\",\"periode\"])\n",
    "\n",
    "    df[\"roll_mean_3\"] = (\n",
    "        df.groupby([\"cabang\",\"sku\"])[\"qty\"]\n",
    "          .transform(lambda x: x.rolling(3, min_periods=1).mean())\n",
    "    )\n",
    "    df[\"roll_mean_12\"] = (\n",
    "        df.groupby([\"cabang\",\"sku\"])[\"qty\"]\n",
    "          .transform(lambda x: x.rolling(12, min_periods=1).mean())\n",
    "    )\n",
    "    df[\"seasonal_ratio_12\"] = df[\"roll_mean_3\"] / (df[\"roll_mean_12\"] + 1e-9)\n",
    "\n",
    "    # volatility_score dari stats train\n",
    "    df[\"volatility_score\"] = df[\"qty_std_cs\"] / (df[\"qty_mean_cs\"] + 1e-9)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "173535dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app/features/outlier_handler.py\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def winsorize_outliers(df: pd.DataFrame, clip_ratio=0.01) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Winsorize qty pakai quantile dari TRAIN saja, lalu diaplikasikan ke seluruh periode.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    df_train = df[df[\"is_train\"] == 1].copy()\n",
    "\n",
    "    q_stats = (\n",
    "        df_train.groupby([\"cabang\",\"sku\"])[\"qty\"]\n",
    "        .quantile([clip_ratio, 1 - clip_ratio])\n",
    "        .unstack()\n",
    "        .reset_index()\n",
    "    )\n",
    "    q_stats.columns = [\"cabang\",\"sku\",\"q_low\",\"q_high\"]\n",
    "\n",
    "    df = df.merge(q_stats, on=[\"cabang\",\"sku\"], how=\"left\")\n",
    "\n",
    "    # kalau ada SKU yang tidak punya train (edge case), pakai qty apa adanya\n",
    "    df[\"qty_wins\"] = df[\"qty\"]\n",
    "    mask = df[\"q_low\"].notna()\n",
    "\n",
    "    df.loc[mask, \"qty_wins\"] = df.loc[mask].apply(\n",
    "        lambda row: max(min(row[\"qty\"], row[\"q_high\"]), row[\"q_low\"]), axis=1\n",
    "    )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "070225a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app/features/hierarchy_features.py\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def add_hierarchy_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    def sku_family(s):\n",
    "        s = str(s).upper().strip()\n",
    "\n",
    "        if s.endswith(\"CHAR\"):\n",
    "            return \"char\"\n",
    "        if s.endswith(\"CPOX\"):\n",
    "            return \"cpox\"\n",
    "        if s.endswith(\"CSW\"):\n",
    "            return \"csw\"\n",
    "        if s.endswith(\"CSB\") or \"KSB\" in s:\n",
    "            return \"csb\"\n",
    "\n",
    "        # fallback: prefix 4 huruf\n",
    "        return s[:4]\n",
    "\n",
    "    df[\"family\"] = df[\"sku\"].apply(sku_family)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2621f454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app/modeling/tweedie_params.py\n",
    "\n",
    "def get_tweedie_params():\n",
    "    return {\n",
    "        \"objective\": \"tweedie\",\n",
    "        \"tweedie_variance_power\": 1.25,\n",
    "        \"metric\": \"rmse\",\n",
    "        \"verbosity\": -1,\n",
    "        \"force_row_wise\": True,\n",
    "        \"seed\": 1337,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc10bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app/modeling/lgbm_trainer_cluster.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "\n",
    "def train_lgbm_per_cluster(\n",
    "    df: pd.DataFrame,\n",
    "    cluster_id: int,\n",
    "    feature_cols: list,\n",
    "    log_target=True,\n",
    "    n_trials=40,\n",
    "):\n",
    "    df_c = df[df[\"cluster\"] == cluster_id].copy()\n",
    "    if df_c.empty:\n",
    "        print(\"Cluster\", cluster_id, \"kosong. Skip.\")\n",
    "        return None\n",
    "\n",
    "    df_c = df_c.sort_values([\"cabang\",\"sku\",\"periode\"]).reset_index(drop=True)\n",
    "\n",
    "    if log_target:\n",
    "        df_c[\"tgt\"] = np.log1p(df_c[\"qty_wins\"])\n",
    "    else:\n",
    "        df_c[\"tgt\"] = df_c[\"qty_wins\"]\n",
    "\n",
    "    train_all = df_c[df_c[\"is_train\"] == 1].copy()\n",
    "    val_cutoff = pd.Timestamp(\"2024-02-01\")\n",
    "\n",
    "    train_inner = train_all[train_all[\"periode\"] < val_cutoff]\n",
    "    val_inner   = train_all[train_all[\"periode\"] >= val_cutoff]\n",
    "\n",
    "    if train_inner.empty or val_inner.empty:\n",
    "        return None\n",
    "\n",
    "    X_train = train_inner[feature_cols]\n",
    "    X_val   = val_inner[feature_cols]\n",
    "\n",
    "    y_train = train_inner[\"tgt\"].values\n",
    "    y_val   = val_inner[\"tgt\"].values\n",
    "\n",
    "    # optuna objective\n",
    "    def objective(trial):\n",
    "        params = get_tweedie_params()\n",
    "        params.update({\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 255),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 20, 200),\n",
    "            \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
    "            \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
    "            \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 12),\n",
    "        })\n",
    "\n",
    "        train_set = lgb.Dataset(X_train, y_train)\n",
    "        val_set   = lgb.Dataset(X_val, y_val)\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_set,\n",
    "            num_boost_round=2000,\n",
    "            valid_sets=[train_set, val_set],\n",
    "            valid_names=[\"train\",\"val\"],\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=100, verbose=False)\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        pred_val = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "\n",
    "        if log_target:\n",
    "            pred_val = np.expm1(pred_val)\n",
    "\n",
    "        true_val = val_inner[\"qty\"].values\n",
    "        rmse_val = np.sqrt(np.mean((true_val - pred_val)**2))\n",
    "        return rmse_val\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\", sampler=TPESampler(seed=1337))\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "\n",
    "    best_iter = study.best_trial.user_attrs.get(\"best_iteration\", 200)\n",
    "    best_params = study.best_params\n",
    "\n",
    "    final_params = get_tweedie_params()\n",
    "    final_params.update(best_params)\n",
    "\n",
    "    train_full = df_c[df_c[\"is_train\"] == 1]\n",
    "    X_full = train_full[feature_cols]\n",
    "    y_full = train_full[\"tgt\"].values\n",
    "\n",
    "    model = lgb.train(\n",
    "        final_params,\n",
    "        lgb.Dataset(X_full, y_full),\n",
    "        num_boost_round=best_iter,\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2c64a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app/inference/predict_cluster_pipeline.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "def load_cluster_models(path_dict):\n",
    "    \"\"\"path_dict: { cluster_id : model_path }\"\"\"\n",
    "    models = {}\n",
    "    for cid, path in path_dict.items():\n",
    "        models[cid] = lgb.Booster(model_file=str(path))\n",
    "    return models\n",
    "\n",
    "def predict_full(df, models, feature_cols):\n",
    "    df = df.copy()\n",
    "    preds = []\n",
    "\n",
    "    for cid, model in models.items():\n",
    "        df_c = df[df[\"cluster\"] == cid].copy()\n",
    "        if df_c.empty:\n",
    "            continue\n",
    "\n",
    "        pred = model.predict(df_c[feature_cols])\n",
    "        pred = np.expm1(pred)\n",
    "        df_c[\"pred_qty\"] = pred\n",
    "        preds.append(df_c)\n",
    "\n",
    "    return pd.concat(preds, axis=0).sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8efba38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "RUN FULL TRAINING (NO LEAK): A+B+C+D+E\n",
      "====================================\n",
      "Load data: D:\\Documents\\Skripsi\\demand-forecasting\\data\\dataset_15\\lgbm_dataset_15_fullfeat.csv\n",
      "Rows: 4965\n",
      "\n",
      "[STEP 2] Build SKU profile dari TRAIN...\n",
      "Saved raw train profile to: D:\\Documents\\Skripsi\\demand-forecasting\\data\\dataset_15\\cluster_profiles_raw_train_only.csv\n",
      "\n",
      "[STEP 3] Clustering SKU (TRAIN only)...\n",
      "Saved clustered profile to: D:\\Documents\\Skripsi\\demand-forecasting\\data\\dataset_15\\cluster_profiles_lgbm15_train_only.csv\n",
      "Cluster summary (train stats):\n",
      "         qty_mean    cv  zero_ratio  total_qty\n",
      "cluster                                       \n",
      "0         1382.52  0.39         0.0   56683.43\n",
      "1         4741.34  0.54         0.0  194394.92\n",
      "2         3926.01  1.14         0.0  160966.57\n",
      "3         1623.43  0.80         0.0   66560.77\n",
      "\n",
      "[STEP 4] Merge cluster dan demand_level ke panel (train+test)...\n",
      "\n",
      "[STEP 5] Tambah hierarchy features (family)...\n",
      "Family mapping: {'APQR': 0, 'ATUV': 1, 'AUVW': 2, 'BBCD': 3, 'BKLM': 4, 'BUVW': 5, 'BVWX': 6, 'CFGH': 7, 'CKLM': 8, 'DKLM': 9, 'DOPQ': 10, 'FIJK': 11, 'FQRS': 12, 'FSTU': 13, 'char': 14, 'cpox': 15, 'csb': 16, 'csw': 17}\n",
      "\n",
      "[STEP 6] Tambah stabilizer features (no leak)...\n",
      "\n",
      "[STEP 7] Winsorize outliers per SKU (no leak)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 20:51:22,806] A new study created in memory with name: no-name-a403765d-c47e-4402-b153-9cc84b24759a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 8] Num features: 40\n",
      "Contoh fitur: ['event_flag', 'event_flag_lag1', 'holiday_count', 'holiday_count_lag1', 'rainfall_lag1', 'imputed', 'spike_flag', 'month', 'year', 'qtr', 'qty_lag1', 'qty_lag2', 'qty_lag3', 'qty_lag4', 'qty_lag5', 'qty_lag6', 'qty_lag7', 'qty_lag8', 'qty_lag9', 'qty_lag10']\n",
      "\n",
      "[STEP 9] Training LGBM per cluster (Tweedie, no leak)...\n",
      "\n",
      "====================================\n",
      "TRAINING CLUSTER 0\n",
      "====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 20:51:26,936] Trial 0 finished with value: 121.59964812496591 and parameters: {'learning_rate': 0.021923099845827587, 'num_leaves': 66, 'max_depth': 5, 'min_data_in_leaf': 103, 'feature_fraction': 0.7284002162080668, 'bagging_fraction': 0.8073571282390148, 'bagging_freq': 4}. Best is trial 0 with value: 121.59964812496591.\n",
      "[I 2025-11-23 20:51:28,538] Trial 1 finished with value: 126.00291693328303 and parameters: {'learning_rate': 0.18617280148093396, 'num_leaves': 195, 'max_depth': 3, 'min_data_in_leaf': 89, 'feature_fraction': 0.8514004718158846, 'bagging_fraction': 0.6500231705342397, 'bagging_freq': 12}. Best is trial 0 with value: 121.59964812496591.\n",
      "[I 2025-11-23 20:51:33,919] Trial 2 finished with value: 107.21132632409115 and parameters: {'learning_rate': 0.03772670263489984, 'num_leaves': 208, 'max_depth': 9, 'min_data_in_leaf': 85, 'feature_fraction': 0.7664415758283992, 'bagging_fraction': 0.8337032512441286, 'bagging_freq': 10}. Best is trial 2 with value: 107.21132632409115.\n",
      "[I 2025-11-23 20:51:41,578] Trial 3 finished with value: 125.5484136610177 and parameters: {'learning_rate': 0.017552717730729438, 'num_leaves': 95, 'max_depth': 8, 'min_data_in_leaf': 110, 'feature_fraction': 0.6714274708654108, 'bagging_fraction': 0.7652565205698636, 'bagging_freq': 3}. Best is trial 2 with value: 107.21132632409115.\n",
      "[I 2025-11-23 20:51:44,846] Trial 4 finished with value: 142.81191469994397 and parameters: {'learning_rate': 0.04917641586078737, 'num_leaves': 218, 'max_depth': 4, 'min_data_in_leaf': 193, 'feature_fraction': 0.7701658660578067, 'bagging_fraction': 0.8016028156645749, 'bagging_freq': 7}. Best is trial 2 with value: 107.21132632409115.\n",
      "[I 2025-11-23 20:51:58,355] Trial 5 finished with value: 116.55617295909018 and parameters: {'learning_rate': 0.010484437931803238, 'num_leaves': 195, 'max_depth': 10, 'min_data_in_leaf': 49, 'feature_fraction': 0.650653911876335, 'bagging_fraction': 0.7499336738320284, 'bagging_freq': 9}. Best is trial 2 with value: 107.21132632409115.\n",
      "[I 2025-11-23 20:52:02,300] Trial 6 finished with value: 201.85784867395947 and parameters: {'learning_rate': 0.010087285835579165, 'num_leaves': 114, 'max_depth': 3, 'min_data_in_leaf': 162, 'feature_fraction': 0.7399076850799927, 'bagging_fraction': 0.8810094878855033, 'bagging_freq': 6}. Best is trial 2 with value: 107.21132632409115.\n",
      "[I 2025-11-23 20:52:03,177] Trial 7 finished with value: 140.21596951448376 and parameters: {'learning_rate': 0.18438945603419024, 'num_leaves': 219, 'max_depth': 7, 'min_data_in_leaf': 122, 'feature_fraction': 0.9989556572883548, 'bagging_fraction': 0.7018896545783523, 'bagging_freq': 1}. Best is trial 2 with value: 107.21132632409115.\n",
      "[I 2025-11-23 20:52:21,360] Trial 8 finished with value: 113.57236456348468 and parameters: {'learning_rate': 0.013057207427597006, 'num_leaves': 242, 'max_depth': 10, 'min_data_in_leaf': 108, 'feature_fraction': 0.7363743886612995, 'bagging_fraction': 0.8891430471738933, 'bagging_freq': 1}. Best is trial 2 with value: 107.21132632409115.\n",
      "[I 2025-11-23 20:52:24,117] Trial 9 finished with value: 134.22060347978396 and parameters: {'learning_rate': 0.09743654578334514, 'num_leaves': 182, 'max_depth': 4, 'min_data_in_leaf': 140, 'feature_fraction': 0.9644489606241253, 'bagging_fraction': 0.6648469703039904, 'bagging_freq': 11}. Best is trial 2 with value: 107.21132632409115.\n",
      "[I 2025-11-23 20:52:33,949] Trial 10 finished with value: 91.79210502193013 and parameters: {'learning_rate': 0.03608224558766931, 'num_leaves': 150, 'max_depth': 8, 'min_data_in_leaf': 26, 'feature_fraction': 0.8530834863107196, 'bagging_fraction': 0.9346681200663051, 'bagging_freq': 9}. Best is trial 10 with value: 91.79210502193013.\n",
      "[I 2025-11-23 20:52:48,971] Trial 11 finished with value: 97.68450693349348 and parameters: {'learning_rate': 0.03728779107707359, 'num_leaves': 151, 'max_depth': 8, 'min_data_in_leaf': 23, 'feature_fraction': 0.8591617204722812, 'bagging_fraction': 0.9723351352588018, 'bagging_freq': 9}. Best is trial 10 with value: 91.79210502193013.\n",
      "[I 2025-11-23 20:52:57,708] Trial 12 finished with value: 96.61875233664658 and parameters: {'learning_rate': 0.0425622458249321, 'num_leaves': 145, 'max_depth': 7, 'min_data_in_leaf': 23, 'feature_fraction': 0.8721199633776775, 'bagging_fraction': 0.9695992590068537, 'bagging_freq': 8}. Best is trial 10 with value: 91.79210502193013.\n",
      "[I 2025-11-23 20:53:09,343] Trial 13 finished with value: 96.63383915246874 and parameters: {'learning_rate': 0.06732467269901733, 'num_leaves': 151, 'max_depth': 6, 'min_data_in_leaf': 20, 'feature_fraction': 0.9032590468854201, 'bagging_fraction': 0.9931500703170151, 'bagging_freq': 7}. Best is trial 10 with value: 91.79210502193013.\n",
      "[I 2025-11-23 20:53:19,526] Trial 14 finished with value: 91.86017176534058 and parameters: {'learning_rate': 0.025417546590970952, 'num_leaves': 112, 'max_depth': 7, 'min_data_in_leaf': 56, 'feature_fraction': 0.8519038423180565, 'bagging_fraction': 0.9320561058751814, 'bagging_freq': 8}. Best is trial 10 with value: 91.79210502193013.\n",
      "[I 2025-11-23 20:53:27,244] Trial 15 finished with value: 107.65048088081194 and parameters: {'learning_rate': 0.024214687715781346, 'num_leaves': 45, 'max_depth': 6, 'min_data_in_leaf': 56, 'feature_fraction': 0.8174380806050532, 'bagging_fraction': 0.9176530142771471, 'bagging_freq': 5}. Best is trial 10 with value: 91.79210502193013.\n",
      "[I 2025-11-23 20:53:32,584] Trial 16 finished with value: 94.13234142101508 and parameters: {'learning_rate': 0.026600904546119526, 'num_leaves': 108, 'max_depth': 8, 'min_data_in_leaf': 56, 'feature_fraction': 0.9289913984013037, 'bagging_fraction': 0.9258674845444388, 'bagging_freq': 10}. Best is trial 10 with value: 91.79210502193013.\n",
      "[I 2025-11-23 20:53:36,685] Trial 17 finished with value: 105.68305277509953 and parameters: {'learning_rate': 0.07923974565258225, 'num_leaves': 81, 'max_depth': 9, 'min_data_in_leaf': 71, 'feature_fraction': 0.8154969417770326, 'bagging_fraction': 0.8667235951205251, 'bagging_freq': 8}. Best is trial 10 with value: 91.79210502193013.\n",
      "[I 2025-11-23 20:53:46,463] Trial 18 finished with value: 91.94776547902377 and parameters: {'learning_rate': 0.03075331647108625, 'num_leaves': 132, 'max_depth': 7, 'min_data_in_leaf': 43, 'feature_fraction': 0.9175785079135313, 'bagging_fraction': 0.9312903793324026, 'bagging_freq': 12}. Best is trial 10 with value: 91.79210502193013.\n",
      "[I 2025-11-23 20:53:52,835] Trial 19 finished with value: 116.03419374390106 and parameters: {'learning_rate': 0.05502265680272034, 'num_leaves': 165, 'max_depth': 9, 'min_data_in_leaf': 73, 'feature_fraction': 0.6012500563370582, 'bagging_fraction': 0.8468108926854633, 'bagging_freq': 6}. Best is trial 10 with value: 91.79210502193013.\n",
      "[I 2025-11-23 20:53:57,954] Trial 20 finished with value: 106.14113555236781 and parameters: {'learning_rate': 0.017081157127599667, 'num_leaves': 122, 'max_depth': 5, 'min_data_in_leaf': 41, 'feature_fraction': 0.8355827296187708, 'bagging_fraction': 0.9578682724295832, 'bagging_freq': 9}. Best is trial 10 with value: 91.79210502193013.\n",
      "[I 2025-11-23 20:54:04,531] Trial 21 finished with value: 88.98802676468706 and parameters: {'learning_rate': 0.03314080989497029, 'num_leaves': 127, 'max_depth': 7, 'min_data_in_leaf': 41, 'feature_fraction': 0.9032405080721289, 'bagging_fraction': 0.9227325412366975, 'bagging_freq': 12}. Best is trial 21 with value: 88.98802676468706.\n",
      "[I 2025-11-23 20:54:08,517] Trial 22 finished with value: 91.82128796525346 and parameters: {'learning_rate': 0.03293593435960235, 'num_leaves': 168, 'max_depth': 6, 'min_data_in_leaf': 38, 'feature_fraction': 0.8772958799408591, 'bagging_fraction': 0.9039697100928431, 'bagging_freq': 11}. Best is trial 21 with value: 88.98802676468706.\n",
      "[I 2025-11-23 20:54:13,352] Trial 23 finished with value: 91.21545194444244 and parameters: {'learning_rate': 0.033062804904013574, 'num_leaves': 172, 'max_depth': 6, 'min_data_in_leaf': 37, 'feature_fraction': 0.8974562208329464, 'bagging_fraction': 0.8871295870456094, 'bagging_freq': 11}. Best is trial 21 with value: 88.98802676468706.\n",
      "[I 2025-11-23 20:54:17,488] Trial 24 finished with value: 89.75077179081138 and parameters: {'learning_rate': 0.056154431985042344, 'num_leaves': 172, 'max_depth': 5, 'min_data_in_leaf': 32, 'feature_fraction': 0.9493338797965968, 'bagging_fraction': 0.9994870171614031, 'bagging_freq': 11}. Best is trial 21 with value: 88.98802676468706.\n",
      "[I 2025-11-23 20:54:19,346] Trial 25 finished with value: 100.1818132380136 and parameters: {'learning_rate': 0.1071244560096509, 'num_leaves': 175, 'max_depth': 5, 'min_data_in_leaf': 66, 'feature_fraction': 0.9541105817692251, 'bagging_fraction': 0.997799063169696, 'bagging_freq': 11}. Best is trial 21 with value: 88.98802676468706.\n",
      "[I 2025-11-23 20:54:21,399] Trial 26 finished with value: 117.14161754751694 and parameters: {'learning_rate': 0.05447496538533909, 'num_leaves': 246, 'max_depth': 4, 'min_data_in_leaf': 37, 'feature_fraction': 0.9794944487852071, 'bagging_fraction': 0.6031161845052188, 'bagging_freq': 12}. Best is trial 21 with value: 88.98802676468706.\n",
      "[I 2025-11-23 20:54:24,142] Trial 27 finished with value: 110.17453275849685 and parameters: {'learning_rate': 0.06890884442927377, 'num_leaves': 132, 'max_depth': 5, 'min_data_in_leaf': 87, 'feature_fraction': 0.93959263572933, 'bagging_fraction': 0.9607483195958475, 'bagging_freq': 10}. Best is trial 21 with value: 88.98802676468706.\n",
      "[I 2025-11-23 20:54:29,179] Trial 28 finished with value: 98.0156042774102 and parameters: {'learning_rate': 0.019977268211478404, 'num_leaves': 194, 'max_depth': 6, 'min_data_in_leaf': 32, 'feature_fraction': 0.8887146744037934, 'bagging_fraction': 0.8639045966888675, 'bagging_freq': 11}. Best is trial 21 with value: 88.98802676468706.\n",
      "[I 2025-11-23 20:54:30,277] Trial 29 finished with value: 132.8690711367361 and parameters: {'learning_rate': 0.11867029174642157, 'num_leaves': 70, 'max_depth': 5, 'min_data_in_leaf': 131, 'feature_fraction': 0.9051427344212355, 'bagging_fraction': 0.8289710081882093, 'bagging_freq': 12}. Best is trial 21 with value: 88.98802676468706.\n",
      "[I 2025-11-23 20:54:32,463] Trial 30 finished with value: 119.32067334511233 and parameters: {'learning_rate': 0.04326702196554342, 'num_leaves': 93, 'max_depth': 6, 'min_data_in_leaf': 96, 'feature_fraction': 0.9867128141981614, 'bagging_fraction': 0.7620609090531901, 'bagging_freq': 10}. Best is trial 21 with value: 88.98802676468706.\n",
      "[I 2025-11-23 20:54:36,339] Trial 31 finished with value: 91.64032044928256 and parameters: {'learning_rate': 0.029239118829350864, 'num_leaves': 160, 'max_depth': 8, 'min_data_in_leaf': 32, 'feature_fraction': 0.9385472103223254, 'bagging_fraction': 0.937049543180115, 'bagging_freq': 11}. Best is trial 21 with value: 88.98802676468706.\n",
      "[I 2025-11-23 20:54:39,583] Trial 32 finished with value: 99.42622231180279 and parameters: {'learning_rate': 0.02922597030706103, 'num_leaves': 166, 'max_depth': 7, 'min_data_in_leaf': 51, 'feature_fraction': 0.9504082232930998, 'bagging_fraction': 0.9050816003327945, 'bagging_freq': 11}. Best is trial 21 with value: 88.98802676468706.\n",
      "[I 2025-11-23 20:54:45,101] Trial 33 finished with value: 92.76750008040223 and parameters: {'learning_rate': 0.021446642309582088, 'num_leaves': 184, 'max_depth': 8, 'min_data_in_leaf': 66, 'feature_fraction': 0.925116531377886, 'bagging_fraction': 0.979801845296256, 'bagging_freq': 12}. Best is trial 21 with value: 88.98802676468706.\n",
      "[I 2025-11-23 20:54:48,314] Trial 34 finished with value: 98.11686669386044 and parameters: {'learning_rate': 0.0572720972330357, 'num_leaves': 138, 'max_depth': 9, 'min_data_in_leaf': 34, 'feature_fraction': 0.8961534203314155, 'bagging_fraction': 0.9484494009801892, 'bagging_freq': 11}. Best is trial 21 with value: 88.98802676468706.\n",
      "[I 2025-11-23 20:54:51,661] Trial 35 finished with value: 96.37021189788175 and parameters: {'learning_rate': 0.043406420129567316, 'num_leaves': 208, 'max_depth': 6, 'min_data_in_leaf': 78, 'feature_fraction': 0.9677930327832279, 'bagging_fraction': 0.9999087949646916, 'bagging_freq': 10}. Best is trial 21 with value: 88.98802676468706.\n",
      "[I 2025-11-23 20:54:55,021] Trial 36 finished with value: 119.62168971735579 and parameters: {'learning_rate': 0.016911065892678222, 'num_leaves': 160, 'max_depth': 4, 'min_data_in_leaf': 46, 'feature_fraction': 0.7947903803393062, 'bagging_fraction': 0.893485683256103, 'bagging_freq': 12}. Best is trial 21 with value: 88.98802676468706.\n",
      "[I 2025-11-23 20:54:59,138] Trial 37 finished with value: 88.99293555676809 and parameters: {'learning_rate': 0.033457803469137765, 'num_leaves': 197, 'max_depth': 7, 'min_data_in_leaf': 32, 'feature_fraction': 0.934860000597243, 'bagging_fraction': 0.8220225137750049, 'bagging_freq': 3}. Best is trial 21 with value: 88.98802676468706.\n",
      "[I 2025-11-23 20:55:03,086] Trial 38 finished with value: 99.95566122745629 and parameters: {'learning_rate': 0.047937014497322745, 'num_leaves': 221, 'max_depth': 5, 'min_data_in_leaf': 62, 'feature_fraction': 0.9173005884508244, 'bagging_fraction': 0.7903037345936285, 'bagging_freq': 2}. Best is trial 21 with value: 88.98802676468706.\n",
      "[I 2025-11-23 20:55:06,982] Trial 39 finished with value: 136.47497711473986 and parameters: {'learning_rate': 0.034908897188803, 'num_leaves': 203, 'max_depth': 7, 'min_data_in_leaf': 185, 'feature_fraction': 0.6988464585544988, 'bagging_fraction': 0.8232859685178168, 'bagging_freq': 4}. Best is trial 21 with value: 88.98802676468706.\n",
      "[I 2025-11-23 20:55:07,782] A new study created in memory with name: no-name-c7b3755b-bb4e-44af-94b5-427f08a483b1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: model saved to D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\lgbm_15_clusters_tweedie_noleak\\models\\lgbm_15_cluster_0.txt\n",
      "\n",
      "====================================\n",
      "TRAINING CLUSTER 1\n",
      "====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 20:55:08,362] Trial 0 finished with value: 2131.3749911918694 and parameters: {'learning_rate': 0.021923099845827587, 'num_leaves': 66, 'max_depth': 5, 'min_data_in_leaf': 103, 'feature_fraction': 0.7284002162080668, 'bagging_fraction': 0.8073571282390148, 'bagging_freq': 4}. Best is trial 0 with value: 2131.3749911918694.\n",
      "[I 2025-11-23 20:55:08,555] Trial 1 finished with value: 2024.649452623456 and parameters: {'learning_rate': 0.18617280148093396, 'num_leaves': 195, 'max_depth': 3, 'min_data_in_leaf': 89, 'feature_fraction': 0.8514004718158846, 'bagging_fraction': 0.6500231705342397, 'bagging_freq': 12}. Best is trial 1 with value: 2024.649452623456.\n",
      "[I 2025-11-23 20:55:09,015] Trial 2 finished with value: 1864.41206721324 and parameters: {'learning_rate': 0.03772670263489984, 'num_leaves': 208, 'max_depth': 9, 'min_data_in_leaf': 85, 'feature_fraction': 0.7664415758283992, 'bagging_fraction': 0.8337032512441286, 'bagging_freq': 10}. Best is trial 2 with value: 1864.41206721324.\n",
      "[I 2025-11-23 20:55:09,804] Trial 3 finished with value: 2194.7855666898154 and parameters: {'learning_rate': 0.017552717730729438, 'num_leaves': 95, 'max_depth': 8, 'min_data_in_leaf': 110, 'feature_fraction': 0.6714274708654108, 'bagging_fraction': 0.7652565205698636, 'bagging_freq': 3}. Best is trial 2 with value: 1864.41206721324.\n",
      "[I 2025-11-23 20:55:09,965] Trial 4 finished with value: 3149.5366012433096 and parameters: {'learning_rate': 0.04917641586078737, 'num_leaves': 218, 'max_depth': 4, 'min_data_in_leaf': 193, 'feature_fraction': 0.7701658660578067, 'bagging_fraction': 0.8016028156645749, 'bagging_freq': 7}. Best is trial 2 with value: 1864.41206721324.\n",
      "[I 2025-11-23 20:55:11,588] Trial 5 finished with value: 1208.610394416783 and parameters: {'learning_rate': 0.010484437931803238, 'num_leaves': 195, 'max_depth': 10, 'min_data_in_leaf': 49, 'feature_fraction': 0.650653911876335, 'bagging_fraction': 0.7499336738320284, 'bagging_freq': 9}. Best is trial 5 with value: 1208.610394416783.\n",
      "[I 2025-11-23 20:55:12,378] Trial 6 finished with value: 2470.9518041733486 and parameters: {'learning_rate': 0.010087285835579165, 'num_leaves': 114, 'max_depth': 3, 'min_data_in_leaf': 162, 'feature_fraction': 0.7399076850799927, 'bagging_fraction': 0.8810094878855033, 'bagging_freq': 6}. Best is trial 5 with value: 1208.610394416783.\n",
      "[I 2025-11-23 20:55:12,513] Trial 7 finished with value: 2345.9088740997718 and parameters: {'learning_rate': 0.18438945603419024, 'num_leaves': 219, 'max_depth': 7, 'min_data_in_leaf': 122, 'feature_fraction': 0.9989556572883548, 'bagging_fraction': 0.7018896545783523, 'bagging_freq': 1}. Best is trial 5 with value: 1208.610394416783.\n",
      "[I 2025-11-23 20:55:13,288] Trial 8 finished with value: 2042.1403220089996 and parameters: {'learning_rate': 0.013057207427597006, 'num_leaves': 242, 'max_depth': 10, 'min_data_in_leaf': 108, 'feature_fraction': 0.7363743886612995, 'bagging_fraction': 0.8891430471738933, 'bagging_freq': 1}. Best is trial 5 with value: 1208.610394416783.\n",
      "[I 2025-11-23 20:55:13,474] Trial 9 finished with value: 2172.804428396609 and parameters: {'learning_rate': 0.09743654578334514, 'num_leaves': 182, 'max_depth': 4, 'min_data_in_leaf': 140, 'feature_fraction': 0.9644489606241253, 'bagging_fraction': 0.6648469703039904, 'bagging_freq': 11}. Best is trial 5 with value: 1208.610394416783.\n",
      "[I 2025-11-23 20:55:14,016] Trial 10 finished with value: 1050.8606619324846 and parameters: {'learning_rate': 0.03117674183171104, 'num_leaves': 150, 'max_depth': 10, 'min_data_in_leaf': 26, 'feature_fraction': 0.6019325816101151, 'bagging_fraction': 0.6084093710444248, 'bagging_freq': 9}. Best is trial 10 with value: 1050.8606619324846.\n",
      "[I 2025-11-23 20:55:14,799] Trial 11 finished with value: 1001.4179003366246 and parameters: {'learning_rate': 0.032449597033723854, 'num_leaves': 151, 'max_depth': 10, 'min_data_in_leaf': 21, 'feature_fraction': 0.6034726117087735, 'bagging_fraction': 0.6117743234820278, 'bagging_freq': 9}. Best is trial 11 with value: 1001.4179003366246.\n",
      "[I 2025-11-23 20:55:15,460] Trial 12 finished with value: 1060.4733723217637 and parameters: {'learning_rate': 0.03760947819283732, 'num_leaves': 145, 'max_depth': 8, 'min_data_in_leaf': 23, 'feature_fraction': 0.6395702395992799, 'bagging_fraction': 0.6006633318408394, 'bagging_freq': 8}. Best is trial 11 with value: 1001.4179003366246.\n",
      "[I 2025-11-23 20:55:19,200] Trial 13 finished with value: 1044.4655965669247 and parameters: {'learning_rate': 0.06255737023361943, 'num_leaves': 151, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.600263858473535, 'bagging_fraction': 0.9806491361735392, 'bagging_freq': 6}. Best is trial 11 with value: 1001.4179003366246.\n",
      "[I 2025-11-23 20:55:20,275] Trial 14 finished with value: 1029.43626698512 and parameters: {'learning_rate': 0.06774167403530304, 'num_leaves': 113, 'max_depth': 6, 'min_data_in_leaf': 55, 'feature_fraction': 0.8519038423180565, 'bagging_fraction': 0.982541909399351, 'bagging_freq': 5}. Best is trial 11 with value: 1001.4179003366246.\n",
      "[I 2025-11-23 20:55:20,964] Trial 15 finished with value: 1154.8974326975433 and parameters: {'learning_rate': 0.08392859900850048, 'num_leaves': 46, 'max_depth': 6, 'min_data_in_leaf': 60, 'feature_fraction': 0.8655471428491822, 'bagging_fraction': 0.983830464379701, 'bagging_freq': 4}. Best is trial 11 with value: 1001.4179003366246.\n",
      "[I 2025-11-23 20:55:22,087] Trial 16 finished with value: 1149.3778150450044 and parameters: {'learning_rate': 0.025214790495863188, 'num_leaves': 108, 'max_depth': 6, 'min_data_in_leaf': 56, 'feature_fraction': 0.8466401877232571, 'bagging_fraction': 0.9258674845444388, 'bagging_freq': 5}. Best is trial 11 with value: 1001.4179003366246.\n",
      "[I 2025-11-23 20:55:22,593] Trial 17 finished with value: 1005.3187644716646 and parameters: {'learning_rate': 0.11511491701576398, 'num_leaves': 81, 'max_depth': 7, 'min_data_in_leaf': 47, 'feature_fraction': 0.9156296716252988, 'bagging_fraction': 0.7255064868123725, 'bagging_freq': 8}. Best is trial 11 with value: 1001.4179003366246.\n",
      "[I 2025-11-23 20:55:22,821] Trial 18 finished with value: 1777.7004281058494 and parameters: {'learning_rate': 0.1330379149396476, 'num_leaves': 77, 'max_depth': 8, 'min_data_in_leaf': 76, 'feature_fraction': 0.9034387156332983, 'bagging_fraction': 0.7140561789109721, 'bagging_freq': 8}. Best is trial 11 with value: 1001.4179003366246.\n",
      "[I 2025-11-23 20:55:23,249] Trial 19 finished with value: 1262.8547178490876 and parameters: {'learning_rate': 0.1238768119240087, 'num_leaves': 129, 'max_depth': 7, 'min_data_in_leaf': 39, 'feature_fraction': 0.8986314095056189, 'bagging_fraction': 0.673691065597885, 'bagging_freq': 10}. Best is trial 11 with value: 1001.4179003366246.\n",
      "[I 2025-11-23 20:55:23,587] Trial 20 finished with value: 1951.2988295125444 and parameters: {'learning_rate': 0.050669059078655855, 'num_leaves': 34, 'max_depth': 9, 'min_data_in_leaf': 71, 'feature_fraction': 0.9420219649426268, 'bagging_fraction': 0.6303183592476092, 'bagging_freq': 12}. Best is trial 11 with value: 1001.4179003366246.\n",
      "[I 2025-11-23 20:55:24,388] Trial 21 finished with value: 919.8246046271205 and parameters: {'learning_rate': 0.06404308566302068, 'num_leaves': 172, 'max_depth': 5, 'min_data_in_leaf': 41, 'feature_fraction': 0.8139501107083261, 'bagging_fraction': 0.7436685927353031, 'bagging_freq': 7}. Best is trial 21 with value: 919.8246046271205.\n",
      "[I 2025-11-23 20:55:24,755] Trial 22 finished with value: 1187.4533048957258 and parameters: {'learning_rate': 0.08719029797338707, 'num_leaves': 169, 'max_depth': 5, 'min_data_in_leaf': 37, 'feature_fraction': 0.7933769158333628, 'bagging_fraction': 0.7247592881268932, 'bagging_freq': 8}. Best is trial 21 with value: 919.8246046271205.\n",
      "[I 2025-11-23 20:55:25,118] Trial 23 finished with value: 1018.4005942596141 and parameters: {'learning_rate': 0.12105029491465902, 'num_leaves': 176, 'max_depth': 5, 'min_data_in_leaf': 38, 'feature_fraction': 0.7046929879038688, 'bagging_fraction': 0.745965992370801, 'bagging_freq': 7}. Best is trial 21 with value: 919.8246046271205.\n",
      "[I 2025-11-23 20:55:25,972] Trial 24 finished with value: 940.1383868795256 and parameters: {'learning_rate': 0.06525735896220866, 'num_leaves': 162, 'max_depth': 4, 'min_data_in_leaf': 39, 'feature_fraction': 0.8234878186667589, 'bagging_fraction': 0.6848672848467146, 'bagging_freq': 9}. Best is trial 21 with value: 919.8246046271205.\n",
      "[I 2025-11-23 20:55:26,217] Trial 25 finished with value: 1923.7445485163023 and parameters: {'learning_rate': 0.06089420883335044, 'num_leaves': 161, 'max_depth': 4, 'min_data_in_leaf': 70, 'feature_fraction': 0.8210106451012746, 'bagging_fraction': 0.6877493825093551, 'bagging_freq': 10}. Best is trial 21 with value: 919.8246046271205.\n",
      "[I 2025-11-23 20:55:26,639] Trial 26 finished with value: 1225.965222747053 and parameters: {'learning_rate': 0.0400730199803823, 'num_leaves': 126, 'max_depth': 4, 'min_data_in_leaf': 33, 'feature_fraction': 0.8079333406454079, 'bagging_fraction': 0.6370455373996083, 'bagging_freq': 9}. Best is trial 21 with value: 919.8246046271205.\n",
      "[I 2025-11-23 20:55:27,037] Trial 27 finished with value: 2020.110747266176 and parameters: {'learning_rate': 0.02851735717639408, 'num_leaves': 248, 'max_depth': 5, 'min_data_in_leaf': 91, 'feature_fraction': 0.7805919975577233, 'bagging_fraction': 0.7737896859208785, 'bagging_freq': 11}. Best is trial 21 with value: 919.8246046271205.\n",
      "[I 2025-11-23 20:55:27,461] Trial 28 finished with value: 1535.1963964348704 and parameters: {'learning_rate': 0.07001668727308155, 'num_leaves': 132, 'max_depth': 3, 'min_data_in_leaf': 63, 'feature_fraction': 0.8218877701614283, 'bagging_fraction': 0.6841593786403783, 'bagging_freq': 7}. Best is trial 21 with value: 919.8246046271205.\n",
      "[I 2025-11-23 20:55:27,925] Trial 29 finished with value: 2360.5124342003214 and parameters: {'learning_rate': 0.020239103310197744, 'num_leaves': 189, 'max_depth': 5, 'min_data_in_leaf': 131, 'feature_fraction': 0.70546379217775, 'bagging_fraction': 0.8479133072220224, 'bagging_freq': 9}. Best is trial 21 with value: 919.8246046271205.\n",
      "[I 2025-11-23 20:55:28,556] Trial 30 finished with value: 1019.2535240703149 and parameters: {'learning_rate': 0.05184981717015665, 'num_leaves': 162, 'max_depth': 4, 'min_data_in_leaf': 20, 'feature_fraction': 0.8698872810572416, 'bagging_fraction': 0.6280087953048882, 'bagging_freq': 11}. Best is trial 21 with value: 919.8246046271205.\n",
      "[I 2025-11-23 20:55:28,885] Trial 31 finished with value: 1202.6106681165115 and parameters: {'learning_rate': 0.10318763361140884, 'num_leaves': 81, 'max_depth': 7, 'min_data_in_leaf': 45, 'feature_fraction': 0.9052767643284395, 'bagging_fraction': 0.7207459316270861, 'bagging_freq': 8}. Best is trial 21 with value: 919.8246046271205.\n",
      "[I 2025-11-23 20:55:29,171] Trial 32 finished with value: 1140.7563297329243 and parameters: {'learning_rate': 0.15582569180147793, 'num_leaves': 55, 'max_depth': 9, 'min_data_in_leaf': 49, 'feature_fraction': 0.9583720298286809, 'bagging_fraction': 0.655212836344935, 'bagging_freq': 6}. Best is trial 21 with value: 919.8246046271205.\n",
      "[I 2025-11-23 20:55:29,680] Trial 33 finished with value: 1125.4298374955256 and parameters: {'learning_rate': 0.07860144232386204, 'num_leaves': 202, 'max_depth': 6, 'min_data_in_leaf': 33, 'feature_fraction': 0.8846424210963757, 'bagging_fraction': 0.7922124983298054, 'bagging_freq': 10}. Best is trial 21 with value: 919.8246046271205.\n",
      "[I 2025-11-23 20:55:29,989] Trial 34 finished with value: 2161.9463513762466 and parameters: {'learning_rate': 0.03337059552562277, 'num_leaves': 96, 'max_depth': 3, 'min_data_in_leaf': 95, 'feature_fraction': 0.9350920120699073, 'bagging_fraction': 0.7373417356421204, 'bagging_freq': 8}. Best is trial 21 with value: 919.8246046271205.\n",
      "[I 2025-11-23 20:55:30,463] Trial 35 finished with value: 1700.6256766008385 and parameters: {'learning_rate': 0.04126727059080209, 'num_leaves': 140, 'max_depth': 8, 'min_data_in_leaf': 81, 'feature_fraction': 0.761338232632216, 'bagging_fraction': 0.7706985443615394, 'bagging_freq': 7}. Best is trial 21 with value: 919.8246046271205.\n",
      "[I 2025-11-23 20:55:31,402] Trial 36 finished with value: 995.2504400629488 and parameters: {'learning_rate': 0.05731394550190601, 'num_leaves': 160, 'max_depth': 9, 'min_data_in_leaf': 46, 'feature_fraction': 0.8429682730265273, 'bagging_fraction': 0.8214072148279835, 'bagging_freq': 9}. Best is trial 21 with value: 919.8246046271205.\n",
      "[I 2025-11-23 20:55:32,230] Trial 37 finished with value: 1012.9180502894243 and parameters: {'learning_rate': 0.05581704257071254, 'num_leaves': 216, 'max_depth': 9, 'min_data_in_leaf': 30, 'feature_fraction': 0.827985382502791, 'bagging_fraction': 0.824813671624701, 'bagging_freq': 10}. Best is trial 21 with value: 919.8246046271205.\n",
      "[I 2025-11-23 20:55:32,919] Trial 38 finished with value: 1502.6833259624286 and parameters: {'learning_rate': 0.023631925899040927, 'num_leaves': 161, 'max_depth': 10, 'min_data_in_leaf': 65, 'feature_fraction': 0.7554295467989154, 'bagging_fraction': 0.8483698684202667, 'bagging_freq': 9}. Best is trial 21 with value: 919.8246046271205.\n",
      "[I 2025-11-23 20:55:33,705] Trial 39 finished with value: 933.8020944715224 and parameters: {'learning_rate': 0.04375127766470519, 'num_leaves': 233, 'max_depth': 9, 'min_data_in_leaf': 44, 'feature_fraction': 0.7940103084999821, 'bagging_fraction': 0.7964748803417675, 'bagging_freq': 11}. Best is trial 21 with value: 919.8246046271205.\n",
      "[I 2025-11-23 20:55:33,896] A new study created in memory with name: no-name-3a452694-1d34-47de-adab-1a644f962eef\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1: model saved to D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\lgbm_15_clusters_tweedie_noleak\\models\\lgbm_15_cluster_1.txt\n",
      "\n",
      "====================================\n",
      "TRAINING CLUSTER 2\n",
      "====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 20:55:34,220] Trial 0 finished with value: 5019.127933989106 and parameters: {'learning_rate': 0.021923099845827587, 'num_leaves': 66, 'max_depth': 5, 'min_data_in_leaf': 103, 'feature_fraction': 0.7284002162080668, 'bagging_fraction': 0.8073571282390148, 'bagging_freq': 4}. Best is trial 0 with value: 5019.127933989106.\n",
      "[I 2025-11-23 20:55:34,331] Trial 1 finished with value: 4483.913725156995 and parameters: {'learning_rate': 0.18617280148093396, 'num_leaves': 195, 'max_depth': 3, 'min_data_in_leaf': 89, 'feature_fraction': 0.8514004718158846, 'bagging_fraction': 0.6500231705342397, 'bagging_freq': 12}. Best is trial 1 with value: 4483.913725156995.\n",
      "[I 2025-11-23 20:55:34,540] Trial 2 finished with value: 4594.299331087771 and parameters: {'learning_rate': 0.03772670263489984, 'num_leaves': 208, 'max_depth': 9, 'min_data_in_leaf': 85, 'feature_fraction': 0.7664415758283992, 'bagging_fraction': 0.8337032512441286, 'bagging_freq': 10}. Best is trial 1 with value: 4483.913725156995.\n",
      "[I 2025-11-23 20:55:34,595] Trial 3 finished with value: 6103.182623466325 and parameters: {'learning_rate': 0.017552717730729438, 'num_leaves': 95, 'max_depth': 8, 'min_data_in_leaf': 110, 'feature_fraction': 0.6714274708654108, 'bagging_fraction': 0.7652565205698636, 'bagging_freq': 3}. Best is trial 1 with value: 4483.913725156995.\n",
      "[I 2025-11-23 20:55:34,637] Trial 4 finished with value: 6103.182623466325 and parameters: {'learning_rate': 0.04917641586078737, 'num_leaves': 218, 'max_depth': 4, 'min_data_in_leaf': 193, 'feature_fraction': 0.7701658660578067, 'bagging_fraction': 0.8016028156645749, 'bagging_freq': 7}. Best is trial 1 with value: 4483.913725156995.\n",
      "[I 2025-11-23 20:55:35,049] Trial 5 finished with value: 3923.7939860100855 and parameters: {'learning_rate': 0.010484437931803238, 'num_leaves': 195, 'max_depth': 10, 'min_data_in_leaf': 49, 'feature_fraction': 0.650653911876335, 'bagging_fraction': 0.7499336738320284, 'bagging_freq': 9}. Best is trial 5 with value: 3923.7939860100855.\n",
      "[I 2025-11-23 20:55:35,095] Trial 6 finished with value: 6103.182623466325 and parameters: {'learning_rate': 0.010087285835579165, 'num_leaves': 114, 'max_depth': 3, 'min_data_in_leaf': 162, 'feature_fraction': 0.7399076850799927, 'bagging_fraction': 0.8810094878855033, 'bagging_freq': 6}. Best is trial 5 with value: 3923.7939860100855.\n",
      "[I 2025-11-23 20:55:35,141] Trial 7 finished with value: 6103.182623466325 and parameters: {'learning_rate': 0.18438945603419024, 'num_leaves': 219, 'max_depth': 7, 'min_data_in_leaf': 122, 'feature_fraction': 0.9989556572883548, 'bagging_fraction': 0.7018896545783523, 'bagging_freq': 1}. Best is trial 5 with value: 3923.7939860100855.\n",
      "[I 2025-11-23 20:55:35,929] Trial 8 finished with value: 4481.978702411875 and parameters: {'learning_rate': 0.013057207427597006, 'num_leaves': 242, 'max_depth': 10, 'min_data_in_leaf': 108, 'feature_fraction': 0.7363743886612995, 'bagging_fraction': 0.8891430471738933, 'bagging_freq': 1}. Best is trial 5 with value: 3923.7939860100855.\n",
      "[I 2025-11-23 20:55:35,971] Trial 9 finished with value: 6103.182623466325 and parameters: {'learning_rate': 0.09743654578334514, 'num_leaves': 182, 'max_depth': 4, 'min_data_in_leaf': 140, 'feature_fraction': 0.9644489606241253, 'bagging_fraction': 0.6648469703039904, 'bagging_freq': 11}. Best is trial 5 with value: 3923.7939860100855.\n",
      "[I 2025-11-23 20:55:36,202] Trial 10 finished with value: 3436.817381591349 and parameters: {'learning_rate': 0.03117674183171104, 'num_leaves': 150, 'max_depth': 10, 'min_data_in_leaf': 26, 'feature_fraction': 0.6019325816101151, 'bagging_fraction': 0.6084093710444248, 'bagging_freq': 9}. Best is trial 10 with value: 3436.817381591349.\n",
      "[I 2025-11-23 20:55:36,679] Trial 11 finished with value: 3355.226620078219 and parameters: {'learning_rate': 0.032449597033723854, 'num_leaves': 151, 'max_depth': 10, 'min_data_in_leaf': 21, 'feature_fraction': 0.6034726117087735, 'bagging_fraction': 0.6117743234820278, 'bagging_freq': 9}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:36,893] Trial 12 finished with value: 3802.7613689558825 and parameters: {'learning_rate': 0.03760947819283732, 'num_leaves': 145, 'max_depth': 8, 'min_data_in_leaf': 23, 'feature_fraction': 0.6395702395992799, 'bagging_fraction': 0.6006633318408394, 'bagging_freq': 8}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:37,502] Trial 13 finished with value: 3733.454229013765 and parameters: {'learning_rate': 0.06255737023361943, 'num_leaves': 151, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.600263858473535, 'bagging_fraction': 0.9806491361735392, 'bagging_freq': 6}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:37,726] Trial 14 finished with value: 4375.385259381557 and parameters: {'learning_rate': 0.025417546590970952, 'num_leaves': 112, 'max_depth': 6, 'min_data_in_leaf': 55, 'feature_fraction': 0.8519038423180565, 'bagging_fraction': 0.6334873514299972, 'bagging_freq': 9}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:37,941] Trial 15 finished with value: 3514.4940991569256 and parameters: {'learning_rate': 0.07585811646400287, 'num_leaves': 160, 'max_depth': 9, 'min_data_in_leaf': 53, 'feature_fraction': 0.6937548652798766, 'bagging_fraction': 0.7156246860267522, 'bagging_freq': 12}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:38,242] Trial 16 finished with value: 3684.440939481527 and parameters: {'learning_rate': 0.027774639564959406, 'num_leaves': 34, 'max_depth': 8, 'min_data_in_leaf': 40, 'feature_fraction': 0.6046736852562886, 'bagging_fraction': 0.6129023741068643, 'bagging_freq': 10}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:38,600] Trial 17 finished with value: 3955.880435344558 and parameters: {'learning_rate': 0.1132052199104558, 'num_leaves': 123, 'max_depth': 9, 'min_data_in_leaf': 73, 'feature_fraction': 0.8285253046724953, 'bagging_fraction': 0.6784015298387152, 'bagging_freq': 8}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:38,871] Trial 18 finished with value: 3670.630370130728 and parameters: {'learning_rate': 0.03201879226009522, 'num_leaves': 162, 'max_depth': 7, 'min_data_in_leaf': 34, 'feature_fraction': 0.692451727273276, 'bagging_fraction': 0.7268152829079271, 'bagging_freq': 5}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:39,042] Trial 19 finished with value: 4248.002630391745 and parameters: {'learning_rate': 0.05313804355012844, 'num_leaves': 74, 'max_depth': 10, 'min_data_in_leaf': 67, 'feature_fraction': 0.8943994474077841, 'bagging_fraction': 0.9944153599605876, 'bagging_freq': 8}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:39,470] Trial 20 finished with value: 4361.6995257350945 and parameters: {'learning_rate': 0.01867069921369678, 'num_leaves': 131, 'max_depth': 6, 'min_data_in_leaf': 69, 'feature_fraction': 0.6383448728185537, 'bagging_fraction': 0.6781607197635302, 'bagging_freq': 10}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:39,636] Trial 21 finished with value: 4096.218076337473 and parameters: {'learning_rate': 0.07824037893601943, 'num_leaves': 172, 'max_depth': 9, 'min_data_in_leaf': 41, 'feature_fraction': 0.6948789301764325, 'bagging_fraction': 0.6003742754838391, 'bagging_freq': 12}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:39,935] Trial 22 finished with value: 3858.2859176746765 and parameters: {'learning_rate': 0.07117867031178245, 'num_leaves': 160, 'max_depth': 9, 'min_data_in_leaf': 20, 'feature_fraction': 0.6184429051313562, 'bagging_fraction': 0.7127804250225459, 'bagging_freq': 11}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:40,179] Trial 23 finished with value: 3750.355682949327 and parameters: {'learning_rate': 0.03916584183383448, 'num_leaves': 134, 'max_depth': 10, 'min_data_in_leaf': 56, 'feature_fraction': 0.6849554419804678, 'bagging_fraction': 0.6385587067843085, 'bagging_freq': 11}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:40,397] Trial 24 finished with value: 3906.2533980458916 and parameters: {'learning_rate': 0.09438426365800952, 'num_leaves': 180, 'max_depth': 9, 'min_data_in_leaf': 36, 'feature_fraction': 0.6546724802881967, 'bagging_fraction': 0.7587399682423277, 'bagging_freq': 9}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:40,574] Trial 25 finished with value: 4055.795923854412 and parameters: {'learning_rate': 0.052528378561319596, 'num_leaves': 87, 'max_depth': 8, 'min_data_in_leaf': 57, 'feature_fraction': 0.717327261217132, 'bagging_fraction': 0.6884234410137582, 'bagging_freq': 7}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:40,793] Trial 26 finished with value: 3972.240640917291 and parameters: {'learning_rate': 0.029070254632336406, 'num_leaves': 146, 'max_depth': 10, 'min_data_in_leaf': 32, 'feature_fraction': 0.6270147016081182, 'bagging_fraction': 0.6354381862790471, 'bagging_freq': 12}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:40,968] Trial 27 finished with value: 3925.175305813914 and parameters: {'learning_rate': 0.13240642335865618, 'num_leaves': 248, 'max_depth': 9, 'min_data_in_leaf': 78, 'feature_fraction': 0.6750316050860911, 'bagging_fraction': 0.6636321023310849, 'bagging_freq': 10}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:41,273] Trial 28 finished with value: 3992.937957941536 and parameters: {'learning_rate': 0.016703967592134973, 'num_leaves': 99, 'max_depth': 7, 'min_data_in_leaf': 43, 'feature_fraction': 0.6010339970659963, 'bagging_fraction': 0.7405404219377506, 'bagging_freq': 9}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:41,611] Trial 29 finished with value: 4539.890203235602 and parameters: {'learning_rate': 0.02327197407844011, 'num_leaves': 53, 'max_depth': 10, 'min_data_in_leaf': 96, 'feature_fraction': 0.7206626123766999, 'bagging_fraction': 0.8343197498601869, 'bagging_freq': 4}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:41,736] Trial 30 finished with value: 6103.182623466325 and parameters: {'learning_rate': 0.0627530131889747, 'num_leaves': 162, 'max_depth': 8, 'min_data_in_leaf': 123, 'feature_fraction': 0.7882351020802065, 'bagging_fraction': 0.785849102770699, 'bagging_freq': 11}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:42,059] Trial 31 finished with value: 3372.3822124992553 and parameters: {'learning_rate': 0.034505057411396055, 'num_leaves': 171, 'max_depth': 7, 'min_data_in_leaf': 32, 'feature_fraction': 0.6989316775963362, 'bagging_fraction': 0.7202085893999175, 'bagging_freq': 5}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:42,361] Trial 32 finished with value: 3738.177767098256 and parameters: {'learning_rate': 0.03057544482137014, 'num_leaves': 189, 'max_depth': 5, 'min_data_in_leaf': 29, 'feature_fraction': 0.6582473126569168, 'bagging_fraction': 0.7130161765596342, 'bagging_freq': 5}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:42,629] Trial 33 finished with value: 4059.8761930290666 and parameters: {'learning_rate': 0.04248486998239389, 'num_leaves': 171, 'max_depth': 9, 'min_data_in_leaf': 61, 'feature_fraction': 0.7024697763724667, 'bagging_fraction': 0.6259186117400588, 'bagging_freq': 3}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:42,916] Trial 34 finished with value: 3855.7732530786857 and parameters: {'learning_rate': 0.02091227058934201, 'num_leaves': 211, 'max_depth': 6, 'min_data_in_leaf': 49, 'feature_fraction': 0.7676937807236855, 'bagging_fraction': 0.7808764704165817, 'bagging_freq': 4}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:43,171] Trial 35 finished with value: 4578.192781653116 and parameters: {'learning_rate': 0.03514408924001828, 'num_leaves': 202, 'max_depth': 9, 'min_data_in_leaf': 89, 'feature_fraction': 0.8101034164847389, 'bagging_fraction': 0.8316245249851345, 'bagging_freq': 5}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:43,371] Trial 36 finished with value: 4131.36463774712 and parameters: {'learning_rate': 0.04731599189137172, 'num_leaves': 125, 'max_depth': 8, 'min_data_in_leaf': 27, 'feature_fraction': 0.6270639711542334, 'bagging_fraction': 0.6657502639024453, 'bagging_freq': 7}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:43,670] Trial 37 finished with value: 4017.165382235724 and parameters: {'learning_rate': 0.014456422218548232, 'num_leaves': 158, 'max_depth': 5, 'min_data_in_leaf': 46, 'feature_fraction': 0.7529707747093097, 'bagging_fraction': 0.6491570250065576, 'bagging_freq': 12}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:44,073] Trial 38 finished with value: 4280.184082263949 and parameters: {'learning_rate': 0.022380896832662246, 'num_leaves': 140, 'max_depth': 10, 'min_data_in_leaf': 82, 'feature_fraction': 0.6702600655648278, 'bagging_fraction': 0.7338729494072034, 'bagging_freq': 6}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:44,312] Trial 39 finished with value: 3995.8470332836314 and parameters: {'learning_rate': 0.045394399628198794, 'num_leaves': 109, 'max_depth': 7, 'min_data_in_leaf': 32, 'feature_fraction': 0.7112003117954938, 'bagging_fraction': 0.6995145954305636, 'bagging_freq': 2}. Best is trial 11 with value: 3355.226620078219.\n",
      "[I 2025-11-23 20:55:44,509] A new study created in memory with name: no-name-ec43162a-47c4-4643-aa3c-a97073118aed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 2: model saved to D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\lgbm_15_clusters_tweedie_noleak\\models\\lgbm_15_cluster_2.txt\n",
      "\n",
      "====================================\n",
      "TRAINING CLUSTER 3\n",
      "====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 20:55:45,686] Trial 0 finished with value: 613.9524689397414 and parameters: {'learning_rate': 0.021923099845827587, 'num_leaves': 66, 'max_depth': 5, 'min_data_in_leaf': 103, 'feature_fraction': 0.7284002162080668, 'bagging_fraction': 0.8073571282390148, 'bagging_freq': 4}. Best is trial 0 with value: 613.9524689397414.\n",
      "[I 2025-11-23 20:55:45,925] Trial 1 finished with value: 657.0625738189198 and parameters: {'learning_rate': 0.18617280148093396, 'num_leaves': 195, 'max_depth': 3, 'min_data_in_leaf': 89, 'feature_fraction': 0.8514004718158846, 'bagging_fraction': 0.6500231705342397, 'bagging_freq': 12}. Best is trial 0 with value: 613.9524689397414.\n",
      "[I 2025-11-23 20:55:47,039] Trial 2 finished with value: 537.1565237500789 and parameters: {'learning_rate': 0.03772670263489984, 'num_leaves': 208, 'max_depth': 9, 'min_data_in_leaf': 85, 'feature_fraction': 0.7664415758283992, 'bagging_fraction': 0.8337032512441286, 'bagging_freq': 10}. Best is trial 2 with value: 537.1565237500789.\n",
      "[I 2025-11-23 20:55:48,387] Trial 3 finished with value: 636.6388592400518 and parameters: {'learning_rate': 0.017552717730729438, 'num_leaves': 95, 'max_depth': 8, 'min_data_in_leaf': 110, 'feature_fraction': 0.6714274708654108, 'bagging_fraction': 0.7652565205698636, 'bagging_freq': 3}. Best is trial 2 with value: 537.1565237500789.\n",
      "[I 2025-11-23 20:55:48,698] Trial 4 finished with value: 728.3859331291646 and parameters: {'learning_rate': 0.04917641586078737, 'num_leaves': 218, 'max_depth': 4, 'min_data_in_leaf': 193, 'feature_fraction': 0.7701658660578067, 'bagging_fraction': 0.8016028156645749, 'bagging_freq': 7}. Best is trial 2 with value: 537.1565237500789.\n",
      "[I 2025-11-23 20:55:51,562] Trial 5 finished with value: 508.09354979617297 and parameters: {'learning_rate': 0.010484437931803238, 'num_leaves': 195, 'max_depth': 10, 'min_data_in_leaf': 49, 'feature_fraction': 0.650653911876335, 'bagging_fraction': 0.7499336738320284, 'bagging_freq': 9}. Best is trial 5 with value: 508.09354979617297.\n",
      "[I 2025-11-23 20:55:52,422] Trial 6 finished with value: 678.4734457619438 and parameters: {'learning_rate': 0.010087285835579165, 'num_leaves': 114, 'max_depth': 3, 'min_data_in_leaf': 162, 'feature_fraction': 0.7399076850799927, 'bagging_fraction': 0.8810094878855033, 'bagging_freq': 6}. Best is trial 5 with value: 508.09354979617297.\n",
      "[I 2025-11-23 20:55:52,666] Trial 7 finished with value: 708.3949107710429 and parameters: {'learning_rate': 0.18438945603419024, 'num_leaves': 219, 'max_depth': 7, 'min_data_in_leaf': 122, 'feature_fraction': 0.9989556572883548, 'bagging_fraction': 0.7018896545783523, 'bagging_freq': 1}. Best is trial 5 with value: 508.09354979617297.\n",
      "[I 2025-11-23 20:55:54,631] Trial 8 finished with value: 578.8043355567971 and parameters: {'learning_rate': 0.013057207427597006, 'num_leaves': 242, 'max_depth': 10, 'min_data_in_leaf': 108, 'feature_fraction': 0.7363743886612995, 'bagging_fraction': 0.8891430471738933, 'bagging_freq': 1}. Best is trial 5 with value: 508.09354979617297.\n",
      "[I 2025-11-23 20:55:54,817] Trial 9 finished with value: 691.7884085522161 and parameters: {'learning_rate': 0.09743654578334514, 'num_leaves': 182, 'max_depth': 4, 'min_data_in_leaf': 140, 'feature_fraction': 0.9644489606241253, 'bagging_fraction': 0.6648469703039904, 'bagging_freq': 11}. Best is trial 5 with value: 508.09354979617297.\n",
      "[I 2025-11-23 20:55:56,419] Trial 10 finished with value: 472.17301010204335 and parameters: {'learning_rate': 0.03117674183171104, 'num_leaves': 150, 'max_depth': 10, 'min_data_in_leaf': 26, 'feature_fraction': 0.6019325816101151, 'bagging_fraction': 0.6084093710444248, 'bagging_freq': 9}. Best is trial 10 with value: 472.17301010204335.\n",
      "[I 2025-11-23 20:55:58,483] Trial 11 finished with value: 481.8772479384384 and parameters: {'learning_rate': 0.032449597033723854, 'num_leaves': 151, 'max_depth': 10, 'min_data_in_leaf': 21, 'feature_fraction': 0.6034726117087735, 'bagging_fraction': 0.6117743234820278, 'bagging_freq': 9}. Best is trial 10 with value: 472.17301010204335.\n",
      "[I 2025-11-23 20:55:59,335] Trial 12 finished with value: 453.5220864559255 and parameters: {'learning_rate': 0.03760947819283732, 'num_leaves': 145, 'max_depth': 8, 'min_data_in_leaf': 23, 'feature_fraction': 0.6395702395992799, 'bagging_fraction': 0.6006633318408394, 'bagging_freq': 8}. Best is trial 12 with value: 453.5220864559255.\n",
      "[I 2025-11-23 20:56:03,834] Trial 13 finished with value: 569.984577087136 and parameters: {'learning_rate': 0.06374271015631741, 'num_leaves': 151, 'max_depth': 8, 'min_data_in_leaf': 20, 'feature_fraction': 0.600263858473535, 'bagging_fraction': 0.9806491361735392, 'bagging_freq': 7}. Best is trial 12 with value: 453.5220864559255.\n",
      "[I 2025-11-23 20:56:04,972] Trial 14 finished with value: 518.5822744218369 and parameters: {'learning_rate': 0.025417546590970952, 'num_leaves': 112, 'max_depth': 6, 'min_data_in_leaf': 56, 'feature_fraction': 0.8519038423180565, 'bagging_fraction': 0.6260590289224254, 'bagging_freq': 8}. Best is trial 12 with value: 453.5220864559255.\n",
      "[I 2025-11-23 20:56:05,662] Trial 15 finished with value: 538.6176405254004 and parameters: {'learning_rate': 0.07118387981906618, 'num_leaves': 47, 'max_depth': 8, 'min_data_in_leaf': 53, 'feature_fraction': 0.6704295712937708, 'bagging_fraction': 0.7073191583782878, 'bagging_freq': 5}. Best is trial 12 with value: 453.5220864559255.\n",
      "[I 2025-11-23 20:56:06,703] Trial 16 finished with value: 536.0710618003939 and parameters: {'learning_rate': 0.02933502618097958, 'num_leaves': 166, 'max_depth': 9, 'min_data_in_leaf': 40, 'feature_fraction': 0.6411237992064867, 'bagging_fraction': 0.6068172899748788, 'bagging_freq': 10}. Best is trial 12 with value: 453.5220864559255.\n",
      "[I 2025-11-23 20:56:07,497] Trial 17 finished with value: 570.8073705687775 and parameters: {'learning_rate': 0.050563956171059465, 'num_leaves': 118, 'max_depth': 7, 'min_data_in_leaf': 74, 'feature_fraction': 0.8285253046724953, 'bagging_fraction': 0.6814300970354713, 'bagging_freq': 8}. Best is trial 12 with value: 453.5220864559255.\n",
      "[I 2025-11-23 20:56:08,111] Trial 18 finished with value: 487.98162884003887 and parameters: {'learning_rate': 0.10458211592298242, 'num_leaves': 132, 'max_depth': 9, 'min_data_in_leaf': 34, 'feature_fraction': 0.7014556073270178, 'bagging_fraction': 0.7321912316388586, 'bagging_freq': 12}. Best is trial 12 with value: 453.5220864559255.\n",
      "[I 2025-11-23 20:56:10,039] Trial 19 finished with value: 522.6873185867979 and parameters: {'learning_rate': 0.020156204991595754, 'num_leaves': 74, 'max_depth': 6, 'min_data_in_leaf': 67, 'feature_fraction': 0.8943994474077841, 'bagging_fraction': 0.9944153599605876, 'bagging_freq': 6}. Best is trial 12 with value: 453.5220864559255.\n",
      "[I 2025-11-23 20:56:11,813] Trial 20 finished with value: 528.7515864849357 and parameters: {'learning_rate': 0.015623724777479295, 'num_leaves': 162, 'max_depth': 9, 'min_data_in_leaf': 36, 'feature_fraction': 0.6383448728185537, 'bagging_fraction': 0.6339687561254853, 'bagging_freq': 9}. Best is trial 12 with value: 453.5220864559255.\n",
      "[I 2025-11-23 20:56:13,546] Trial 21 finished with value: 431.8554535056269 and parameters: {'learning_rate': 0.033206249347244025, 'num_leaves': 139, 'max_depth': 10, 'min_data_in_leaf': 22, 'feature_fraction': 0.6007633013774947, 'bagging_fraction': 0.6006262338895773, 'bagging_freq': 9}. Best is trial 21 with value: 431.8554535056269.\n",
      "[I 2025-11-23 20:56:15,914] Trial 22 finished with value: 469.2687311374353 and parameters: {'learning_rate': 0.03853494513570253, 'num_leaves': 133, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.6078661646448984, 'bagging_fraction': 0.6030860937843565, 'bagging_freq': 10}. Best is trial 21 with value: 431.8554535056269.\n",
      "[I 2025-11-23 20:56:16,573] Trial 23 finished with value: 536.6637288467779 and parameters: {'learning_rate': 0.040855934485827236, 'num_leaves': 89, 'max_depth': 9, 'min_data_in_leaf': 64, 'feature_fraction': 0.6813850848071021, 'bagging_fraction': 0.6642165693738489, 'bagging_freq': 11}. Best is trial 21 with value: 431.8554535056269.\n",
      "[I 2025-11-23 20:56:17,524] Trial 24 finished with value: 545.5016980692986 and parameters: {'learning_rate': 0.056154431985042344, 'num_leaves': 133, 'max_depth': 8, 'min_data_in_leaf': 45, 'feature_fraction': 0.6445361595626841, 'bagging_fraction': 0.6487890150924688, 'bagging_freq': 8}. Best is trial 21 with value: 431.8554535056269.\n",
      "[I 2025-11-23 20:56:18,544] Trial 25 finished with value: 514.5002482140478 and parameters: {'learning_rate': 0.08713168499144844, 'num_leaves': 130, 'max_depth': 10, 'min_data_in_leaf': 33, 'feature_fraction': 0.6981994756909102, 'bagging_fraction': 0.7004884502763795, 'bagging_freq': 10}. Best is trial 21 with value: 431.8554535056269.\n",
      "[I 2025-11-23 20:56:20,203] Trial 26 finished with value: 436.2012990836114 and parameters: {'learning_rate': 0.02480936481259061, 'num_leaves': 174, 'max_depth': 9, 'min_data_in_leaf': 21, 'feature_fraction': 0.6229870483476011, 'bagging_fraction': 0.6031161845052188, 'bagging_freq': 11}. Best is trial 21 with value: 431.8554535056269.\n",
      "[I 2025-11-23 20:56:21,673] Trial 27 finished with value: 570.6896611772978 and parameters: {'learning_rate': 0.02458466909629566, 'num_leaves': 178, 'max_depth': 7, 'min_data_in_leaf': 77, 'feature_fraction': 0.630380006477636, 'bagging_fraction': 0.6373578234378805, 'bagging_freq': 11}. Best is trial 21 with value: 431.8554535056269.\n",
      "[I 2025-11-23 20:56:24,840] Trial 28 finished with value: 522.6068171133842 and parameters: {'learning_rate': 0.01543328525777468, 'num_leaves': 248, 'max_depth': 8, 'min_data_in_leaf': 59, 'feature_fraction': 0.7118423096170219, 'bagging_fraction': 0.6765668564573103, 'bagging_freq': 12}. Best is trial 21 with value: 431.8554535056269.\n",
      "[I 2025-11-23 20:56:27,740] Trial 29 finished with value: 630.7938082464666 and parameters: {'learning_rate': 0.018940030339885876, 'num_leaves': 176, 'max_depth': 9, 'min_data_in_leaf': 131, 'feature_fraction': 0.6697171580626748, 'bagging_fraction': 0.9536368158499369, 'bagging_freq': 4}. Best is trial 21 with value: 431.8554535056269.\n",
      "[I 2025-11-23 20:56:29,527] Trial 30 finished with value: 528.7102933216339 and parameters: {'learning_rate': 0.024345231749492418, 'num_leaves': 93, 'max_depth': 7, 'min_data_in_leaf': 45, 'feature_fraction': 0.7925554530934026, 'bagging_fraction': 0.7787877490339566, 'bagging_freq': 7}. Best is trial 21 with value: 431.8554535056269.\n",
      "[I 2025-11-23 20:56:30,891] Trial 31 finished with value: 493.0962516316858 and parameters: {'learning_rate': 0.033944090479768124, 'num_leaves': 142, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.6267279182648902, 'bagging_fraction': 0.6153031028842704, 'bagging_freq': 10}. Best is trial 21 with value: 431.8554535056269.\n",
      "[I 2025-11-23 20:56:32,086] Trial 32 finished with value: 458.18223914927177 and parameters: {'learning_rate': 0.041022660537161894, 'num_leaves': 166, 'max_depth': 9, 'min_data_in_leaf': 30, 'feature_fraction': 0.6187068408212176, 'bagging_fraction': 0.6011758624465127, 'bagging_freq': 11}. Best is trial 21 with value: 431.8554535056269.\n",
      "[I 2025-11-23 20:56:34,121] Trial 33 finished with value: 523.492441101349 and parameters: {'learning_rate': 0.041737612611849634, 'num_leaves': 192, 'max_depth': 9, 'min_data_in_leaf': 33, 'feature_fraction': 0.6199991640536666, 'bagging_fraction': 0.6421875444930082, 'bagging_freq': 11}. Best is trial 21 with value: 431.8554535056269.\n",
      "[I 2025-11-23 20:56:35,605] Trial 34 finished with value: 498.06211414763965 and parameters: {'learning_rate': 0.02767433756226714, 'num_leaves': 164, 'max_depth': 8, 'min_data_in_leaf': 33, 'feature_fraction': 0.6583383984103424, 'bagging_fraction': 0.6586907687584382, 'bagging_freq': 12}. Best is trial 21 with value: 431.8554535056269.\n",
      "[I 2025-11-23 20:56:38,071] Trial 35 finished with value: 530.1828805389888 and parameters: {'learning_rate': 0.022426135167349075, 'num_leaves': 210, 'max_depth': 9, 'min_data_in_leaf': 87, 'feature_fraction': 0.6881679281194709, 'bagging_fraction': 0.8359657466886187, 'bagging_freq': 8}. Best is trial 21 with value: 431.8554535056269.\n",
      "[I 2025-11-23 20:56:40,326] Trial 36 finished with value: 540.8828857974346 and parameters: {'learning_rate': 0.04738356806659233, 'num_leaves': 164, 'max_depth': 8, 'min_data_in_leaf': 46, 'feature_fraction': 0.7251838858463204, 'bagging_fraction': 0.6329598972896403, 'bagging_freq': 11}. Best is trial 21 with value: 431.8554535056269.\n",
      "[I 2025-11-23 20:56:41,346] Trial 37 finished with value: 655.0018553357038 and parameters: {'learning_rate': 0.0353603084099415, 'num_leaves': 104, 'max_depth': 9, 'min_data_in_leaf': 95, 'feature_fraction': 0.650433279286905, 'bagging_fraction': 0.6002384639307827, 'bagging_freq': 9}. Best is trial 21 with value: 431.8554535056269.\n",
      "[I 2025-11-23 20:56:41,982] Trial 38 finished with value: 702.4048309920971 and parameters: {'learning_rate': 0.05861072409545268, 'num_leaves': 193, 'max_depth': 10, 'min_data_in_leaf': 156, 'feature_fraction': 0.7586382261474677, 'bagging_fraction': 0.7240282904573384, 'bagging_freq': 12}. Best is trial 21 with value: 431.8554535056269.\n",
      "[I 2025-11-23 20:56:43,322] Trial 39 finished with value: 477.99942641811055 and parameters: {'learning_rate': 0.07178853582804678, 'num_leaves': 206, 'max_depth': 8, 'min_data_in_leaf': 29, 'feature_fraction': 0.6225184127297076, 'bagging_fraction': 0.6918865804719658, 'bagging_freq': 9}. Best is trial 21 with value: 431.8554535056269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 3: model saved to D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\lgbm_15_clusters_tweedie_noleak\\models\\lgbm_15_cluster_3.txt\n",
      "\n",
      "[STEP 10] Prediksi penuh (train + test) per cluster...\n",
      "Saved full panel with predictions to: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\lgbm_15_clusters_tweedie_noleak\\panel_with_predictions.csv\n",
      "\n",
      "[STEP 11] Global metrics train/test...\n",
      "Saved global metrics to: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\lgbm_15_clusters_tweedie_noleak\\metrics\\global_metrics_clusters_tweedie_noleak.csv\n",
      "split  n_obs           MSE       RMSE        MAE      MAPE     sMAPE\n",
      "train   4920 313683.507019 560.074555 173.828192  8.962125  8.243627\n",
      " test     45 626566.313539 791.559419 512.546156 16.429938 15.987120\n",
      "\n",
      "[STEP 12] Metrics per cabangSKU...\n",
      "Saved metrics per series to: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\lgbm_15_clusters_tweedie_noleak\\metrics\\metrics_by_series_clusters_tweedie_noleak.csv\n",
      "cabang          sku  cluster  n_train  n_test  train_mae     train_mse  train_rmse  train_mape  train_smape  test_mae      test_mse  test_rmse  test_mape  test_smape   gap_RMSE  ratio_RMSE\n",
      "   02A  BNOP400CHAR        3       41       0 107.446634  30689.200830  175.183335   19.373510    17.284699       NaN           NaN        NaN        NaN         NaN        NaN         NaN\n",
      "   02A  BNOP400CPOX        3       41       0 107.446634  30689.200830  175.183335   19.373510    17.284699       NaN           NaN        NaN        NaN         NaN        NaN         NaN\n",
      "   02A  BUVW001K194        0       41       0  57.082359   4703.758006   68.583949   10.413650     9.964357       NaN           NaN        NaN        NaN         NaN        NaN         NaN\n",
      "   02A   BUVW001KSB        0       41       0  59.052998   5984.431506   77.359107    6.438621     6.383096       NaN           NaN        NaN        NaN         NaN        NaN         NaN\n",
      "   02A  BUVW001KSBM        0       41       0  47.146943   3581.647476   59.846867    8.749747     8.370795       NaN           NaN        NaN        NaN         NaN        NaN         NaN\n",
      "   02A   BUVW001KSW        1       41       5 290.894826 148937.231092  385.923867    8.797327     8.767288 663.99912 734259.001014 856.889142  28.320828   25.288253 470.965275    2.220358\n",
      "   02A  BUVW100C192        0       41       0  53.695679   5743.778294   75.787719    7.315020     6.997519       NaN           NaN        NaN        NaN         NaN        NaN         NaN\n",
      "   02A   BUVW100CSB        0       41       0  88.037971  16971.381563  130.274255    4.192651     4.227054       NaN           NaN        NaN        NaN         NaN        NaN         NaN\n",
      "   02A   BUVW100CSW        0       41       0  76.304775  12448.423214  111.572502    4.465687     4.350016       NaN           NaN        NaN        NaN         NaN        NaN         NaN\n",
      "   02A CKLM001KS607        0       41       0  49.524626   3933.104792   62.714470    5.825466     5.770989       NaN           NaN        NaN        NaN         NaN        NaN         NaN\n",
      "\n",
      "[STEP 13] Plot actual vs pred TEST per seri ke: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\lgbm_15_clusters_tweedie_noleak\\plots_per_series\n",
      "\n",
      "[STEP 14] Diagnostics ke: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\lgbm_15_clusters_tweedie_noleak\\diagnostics\n",
      "Saved top outliers train to: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\lgbm_15_clusters_tweedie_noleak\\diagnostics\\top_outliers_train.csv\n",
      "\n",
      "Seri dengan ratio_RMSE > 1.3 (indikasi sulit di test / overfit lokal):\n",
      "cabang         sku  cluster  train_rmse  test_rmse  ratio_RMSE\n",
      "   14A  BUVW001KSW        1  276.735887 710.508607    2.567461\n",
      "   16C DOPQ001K009        3  390.427345 870.854397    2.230516\n",
      "   02A  BUVW001KSW        1  385.923867 856.889142    2.220358\n",
      "\n",
      "Seri dengan ratio_RMSE < 0.8 (train lebih jelek dari test):\n",
      "cabang         sku  cluster  train_rmse   test_rmse  ratio_RMSE\n",
      "   05A  BUVW001KSW        1  755.827588  256.797569    0.339757\n",
      "   13I  BUVW001KSW        1 4165.319838 1697.368958    0.407500\n",
      "   13A DOPQ001K002        1  773.196588  407.558277    0.527108\n",
      "   23A  BUVW001KSW        1  736.431243  403.446302    0.547840\n",
      "   17A DOPQ001K002        0  138.990105   95.846012    0.689589\n",
      "   29A  BUVW001KSW        1  843.387005  597.128513    0.708012\n",
      "\n",
      "SELESAI: A+B+C+D+E (NO LEAK) + diagnostics lengkap.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==============================\n",
    "# METRIC FUNCTIONS\n",
    "# ==============================\n",
    "def mae(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mse(y_true, y_pred))\n",
    "\n",
    "\n",
    "def mape(y_true, y_pred, eps=1e-8):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    denom = np.maximum(np.abs(y_true), eps)\n",
    "    return np.mean(np.abs(y_true - y_pred) / denom) * 100.0\n",
    "\n",
    "\n",
    "def smape(y_true, y_pred, eps=1e-8):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    denom = np.maximum(np.abs(y_true) + np.abs(y_pred), eps)\n",
    "    return np.mean(2.0 * np.abs(y_true - y_pred) / denom) * 100.0\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# PATH CONFIG\n",
    "# ==============================\n",
    "PROJECT_ROOT   = Path(r\"D:\\Documents\\Skripsi\\demand-forecasting\")\n",
    "DATASET15_DIR  = PROJECT_ROOT / \"data\" / \"dataset_15\"\n",
    "\n",
    "DATA_PATH      = DATASET15_DIR / \"lgbm_dataset_15_fullfeat.csv\"\n",
    "\n",
    "OUT_ROOT       = PROJECT_ROOT / \"outputs\" / \"lgbm_15_clusters_tweedie_noleak\"\n",
    "MODEL_DIR      = OUT_ROOT / \"models\"\n",
    "METRIC_DIR     = OUT_ROOT / \"metrics\"\n",
    "PLOT_DIR       = OUT_ROOT / \"plots_per_series\"\n",
    "DIAG_DIR       = OUT_ROOT / \"diagnostics\"\n",
    "\n",
    "for d in [OUT_ROOT, MODEL_DIR, METRIC_DIR, PLOT_DIR, DIAG_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"====================================\")\n",
    "    print(\"RUN FULL TRAINING (NO LEAK): A+B+C+D+E\")\n",
    "    print(\"====================================\")\n",
    "    print(\"Load data:\", DATA_PATH)\n",
    "\n",
    "    df = pd.read_csv(DATA_PATH, parse_dates=[\"periode\"])\n",
    "    print(\"Rows:\", len(df))\n",
    "\n",
    "    df[\"qty\"] = df[\"qty\"].astype(float)\n",
    "    df = df.sort_values([\"cabang\",\"sku\",\"periode\"]).reset_index(drop=True)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 2: build SKU profile dari TRAIN\n",
    "    # ----------------------------------\n",
    "    print(\"\\n[STEP 2] Build SKU profile dari TRAIN...\")\n",
    "    df_train = df[df[\"is_train\"] == 1].copy()\n",
    "    profile = build_sku_profile(df_train)\n",
    "    PROFILE_PATH = DATASET15_DIR / \"cluster_profiles_raw_train_only.csv\"\n",
    "    profile.to_csv(PROFILE_PATH, index=False)\n",
    "    print(\"Saved raw train profile to:\", PROFILE_PATH)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 3: clustering (A) dari TRAIN\n",
    "    # ----------------------------------\n",
    "    print(\"\\n[STEP 3] Clustering SKU (TRAIN only)...\")\n",
    "    profile_clustered = run_sku_clustering(profile, n_clusters=4)\n",
    "    PROFILE_CLUSTER_PATH = DATASET15_DIR / \"cluster_profiles_lgbm15_train_only.csv\"\n",
    "    profile_clustered.to_csv(PROFILE_CLUSTER_PATH, index=False)\n",
    "    print(\"Saved clustered profile to:\", PROFILE_CLUSTER_PATH)\n",
    "    print(\"Cluster summary (train stats):\")\n",
    "    print(\n",
    "        profile_clustered.groupby(\"cluster\")[[\"qty_mean\", \"cv\", \"zero_ratio\", \"total_qty\"]]\n",
    "        .mean()\n",
    "        .round(2)\n",
    "        .to_string()\n",
    "    )\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 4: merge cluster + demand_level ke panel penuh\n",
    "    # ----------------------------------\n",
    "    print(\"\\n[STEP 4] Merge cluster dan demand_level ke panel (train+test)...\")\n",
    "    df = df.merge(\n",
    "        profile_clustered[[\"cabang\", \"sku\", \"cluster\", \"demand_level\"]],\n",
    "        on=[\"cabang\", \"sku\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    df[\"cluster\"] = df[\"cluster\"].fillna(-1).astype(int)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 5: add hierarchy features (E)\n",
    "    # ----------------------------------\n",
    "    print(\"\\n[STEP 5] Tambah hierarchy features (family)...\")\n",
    "    df = add_hierarchy_features(df)\n",
    "\n",
    "    # Encode family -> family_idx (numeric)\n",
    "    if \"family\" in df.columns:\n",
    "        family_map = {\n",
    "            fam: idx for idx, fam in enumerate(sorted(df[\"family\"].astype(str).unique()))\n",
    "        }\n",
    "        df[\"family_idx\"] = df[\"family\"].astype(str).map(family_map).astype(\"int16\")\n",
    "        print(\"Family mapping:\", family_map)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 6: add stabilizer features (B) - pakai stats TRAIN\n",
    "    # ----------------------------------\n",
    "    print(\"\\n[STEP 6] Tambah stabilizer features (no leak)...\")\n",
    "    df = add_stabilizer_features(df)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 7: outlier treatment (C) - quantile dari TRAIN\n",
    "    # ----------------------------------\n",
    "    print(\"\\n[STEP 7] Winsorize outliers per SKU (no leak)...\")\n",
    "    df = winsorize_outliers(df)\n",
    "\n",
    "    # backup log1p original qty juga, kalau mau analisis\n",
    "    df[\"log_qty\"] = np.log1p(df[\"qty\"])\n",
    "    df[\"log_qty_wins\"] = np.log1p(df[\"qty_wins\"])\n",
    "\n",
    "    df = df.sort_values([\"cabang\", \"sku\", \"periode\"]).reset_index(drop=True)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 8: feature columns\n",
    "    # ----------------------------------\n",
    "    drop_cols = [\n",
    "        \"area\",\n",
    "        \"cabang\",\n",
    "        \"sku\",\n",
    "        \"periode\",\n",
    "        \"qty\",\n",
    "        \"qty_wins\",\n",
    "        \"log_qty\",\n",
    "        \"log_qty_wins\",\n",
    "        \"is_train\",\n",
    "        \"is_test\",\n",
    "        \"sample_weight\",\n",
    "        \"family\",\n",
    "    ]\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "    print(\"\\n[STEP 8] Num features:\", len(feature_cols))\n",
    "    print(\"Contoh fitur:\", feature_cols[:20])\n",
    "\n",
    "    obj_cols = df[feature_cols].select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "    if obj_cols:\n",
    "        print(\"WARNING: Masih ada kolom object di feature_cols:\", obj_cols)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 9: train per cluster\n",
    "    # ----------------------------------\n",
    "    print(\"\\n[STEP 9] Training LGBM per cluster (Tweedie, no leak)...\")\n",
    "    cluster_ids = sorted(df[\"cluster\"].dropna().unique())\n",
    "    models: Dict[int, lgb.Booster] = {}\n",
    "\n",
    "    for cid in cluster_ids:\n",
    "        if cid == -1:\n",
    "            print(f\"Cluster {cid} = -1 (unknown), skip training.\")\n",
    "            continue\n",
    "\n",
    "        print(\"\\n====================================\")\n",
    "        print(f\"TRAINING CLUSTER {cid}\")\n",
    "        print(\"====================================\")\n",
    "\n",
    "        model = train_lgbm_per_cluster(\n",
    "            df=df,\n",
    "            cluster_id=int(cid),\n",
    "            feature_cols=feature_cols,\n",
    "            log_target=True,\n",
    "            n_trials=40,\n",
    "        )\n",
    "\n",
    "        if model is None:\n",
    "            print(f\"Cluster {cid}: model is None, skip saving.\")\n",
    "            continue\n",
    "\n",
    "        models[cid] = model\n",
    "\n",
    "        model_path = MODEL_DIR / f\"lgbm_15_cluster_{cid}.txt\"\n",
    "        model.save_model(str(model_path))\n",
    "        print(f\"Cluster {cid}: model saved to {model_path}\")\n",
    "\n",
    "    if not models:\n",
    "        raise RuntimeError(\"Tidak ada model yang berhasil dilatih. Cek cluster atau flag is_train.\")\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 10: prediksi penuh\n",
    "    # ----------------------------------\n",
    "    print(\"\\n[STEP 10] Prediksi penuh (train + test) per cluster...\")\n",
    "    df_pred_list = []\n",
    "\n",
    "    for cid, model in models.items():\n",
    "        df_c = df[df[\"cluster\"] == cid].copy()\n",
    "        if df_c.empty:\n",
    "            continue\n",
    "\n",
    "        X_c = df_c[feature_cols]\n",
    "        pred_log = model.predict(X_c)\n",
    "        pred_qty = np.expm1(pred_log)\n",
    "\n",
    "        df_c[\"pred_qty\"] = pred_qty\n",
    "        df_pred_list.append(df_c)\n",
    "\n",
    "    df_pred = pd.concat(df_pred_list, axis=0).sort_index()\n",
    "    PRED_PATH = OUT_ROOT / \"panel_with_predictions.csv\"\n",
    "    df_pred.to_csv(PRED_PATH, index=False)\n",
    "    print(\"Saved full panel with predictions to:\", PRED_PATH)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 11: GLOBAL METRICS\n",
    "    # ----------------------------------\n",
    "    print(\"\\n[STEP 11] Global metrics train/test...\")\n",
    "    metrics_global = []\n",
    "\n",
    "    for split_name, mask in [\n",
    "        (\"train\", df_pred[\"is_train\"] == 1),\n",
    "        (\"test\", df_pred[\"is_test\"] == 1),\n",
    "    ]:\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        yt = df_pred.loc[mask, \"qty\"].values\n",
    "        yp = df_pred.loc[mask, \"pred_qty\"].values\n",
    "\n",
    "        metrics_global.append({\n",
    "            \"split\": split_name,\n",
    "            \"n_obs\": int(len(yt)),\n",
    "            \"MSE\": mse(yt, yp),\n",
    "            \"RMSE\": rmse(yt, yp),\n",
    "            \"MAE\": mae(yt, yp),\n",
    "            \"MAPE\": mape(yt, yp),\n",
    "            \"sMAPE\": smape(yt, yp),\n",
    "        })\n",
    "\n",
    "    global_df = pd.DataFrame(metrics_global)\n",
    "    GLOBAL_METRIC_PATH = METRIC_DIR / \"global_metrics_clusters_tweedie_noleak.csv\"\n",
    "    global_df.to_csv(GLOBAL_METRIC_PATH, index=False)\n",
    "    print(\"Saved global metrics to:\", GLOBAL_METRIC_PATH)\n",
    "    print(global_df.to_string(index=False))\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 12: METRICS PER SERIES\n",
    "    # ----------------------------------\n",
    "    print(\"\\n[STEP 12] Metrics per cabangSKU...\")\n",
    "    rows = []\n",
    "\n",
    "    for (cab, sku), g in df_pred.groupby([\"cabang\", \"sku\"], sort=False):\n",
    "        g_tr = g[g[\"is_train\"] == 1]\n",
    "        g_te = g[g[\"is_test\"] == 1]\n",
    "\n",
    "        row = {\n",
    "            \"cabang\": cab,\n",
    "            \"sku\": sku,\n",
    "            \"cluster\": g[\"cluster\"].iloc[0],\n",
    "            \"n_train\": int(len(g_tr)),\n",
    "            \"n_test\": int(len(g_te)),\n",
    "        }\n",
    "\n",
    "        if len(g_tr) > 0:\n",
    "            yt_tr = g_tr[\"qty\"].values\n",
    "            yp_tr = g_tr[\"pred_qty\"].values\n",
    "            row.update({\n",
    "                \"train_mae\": mae(yt_tr, yp_tr),\n",
    "                \"train_mse\": mse(yt_tr, yp_tr),\n",
    "                \"train_rmse\": rmse(yt_tr, yp_tr),\n",
    "                \"train_mape\": mape(yt_tr, yp_tr),\n",
    "                \"train_smape\": smape(yt_tr, yp_tr),\n",
    "            })\n",
    "        else:\n",
    "            row.update({\n",
    "                \"train_mae\": np.nan,\n",
    "                \"train_mse\": np.nan,\n",
    "                \"train_rmse\": np.nan,\n",
    "                \"train_mape\": np.nan,\n",
    "                \"train_smape\": np.nan,\n",
    "            })\n",
    "\n",
    "        if len(g_te) > 0:\n",
    "            yt_te = g_te[\"qty\"].values\n",
    "            yp_te = g_te[\"pred_qty\"].values\n",
    "            row.update({\n",
    "                \"test_mae\": mae(yt_te, yp_te),\n",
    "                \"test_mse\": mse(yt_te, yp_te),\n",
    "                \"test_rmse\": rmse(yt_te, yp_te),\n",
    "                \"test_mape\": mape(yt_te, yp_te),\n",
    "                \"test_smape\": smape(yt_te, yp_te),\n",
    "            })\n",
    "        else:\n",
    "            row.update({\n",
    "                \"test_mae\": np.nan,\n",
    "                \"test_mse\": np.nan,\n",
    "                \"test_rmse\": np.nan,\n",
    "                \"test_mape\": np.nan,\n",
    "                \"test_smape\": np.nan,\n",
    "            })\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    metrics_series = pd.DataFrame(rows)\n",
    "    metrics_series[\"gap_RMSE\"] = metrics_series[\"test_rmse\"] - metrics_series[\"train_rmse\"]\n",
    "    metrics_series[\"ratio_RMSE\"] = metrics_series[\"test_rmse\"] / metrics_series[\"train_rmse\"]\n",
    "\n",
    "    SERIES_METRIC_PATH = METRIC_DIR / \"metrics_by_series_clusters_tweedie_noleak.csv\"\n",
    "    metrics_series.to_csv(SERIES_METRIC_PATH, index=False)\n",
    "    print(\"Saved metrics per series to:\", SERIES_METRIC_PATH)\n",
    "    print(metrics_series.head(10).to_string(index=False))\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 13: PLOT ACTUAL vs PRED (TEST)\n",
    "    # ----------------------------------\n",
    "    print(f\"\\n[STEP 13] Plot actual vs pred TEST per seri ke: {PLOT_DIR}\")\n",
    "\n",
    "    test_only = df_pred[df_pred[\"is_test\"] == 1].copy()\n",
    "\n",
    "    for (cab, sku), g in test_only.groupby([\"cabang\", \"sku\"], sort=False):\n",
    "        g = g.sort_values(\"periode\")\n",
    "\n",
    "        if g[\"qty\"].notna().sum() == 0:\n",
    "            continue\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(g[\"periode\"], g[\"qty\"], marker=\"o\", label=\"Actual qty\")\n",
    "        plt.plot(g[\"periode\"], g[\"pred_qty\"], marker=\"x\", label=\"Predicted qty\")\n",
    "        plt.xlabel(\"Periode\")\n",
    "        plt.ylabel(\"Qty\")\n",
    "        plt.title(f\"Actual vs Predicted - TEST\\nCabang {cab}, SKU {sku}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        fname = f\"{cab}_{sku}_test_actual_vs_pred.png\".replace(\"/\", \"-\")\n",
    "        plt.savefig(PLOT_DIR / fname, dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 14: DIAGNOSTICS (residual, overfit, dll)\n",
    "    # ----------------------------------\n",
    "    print(f\"\\n[STEP 14] Diagnostics ke: {DIAG_DIR}\")\n",
    "\n",
    "    df_resid = df_pred.copy()\n",
    "    df_resid[\"resid\"] = df_resid[\"qty\"].astype(float) - df_resid[\"pred_qty\"].astype(float)\n",
    "    df_resid[\"abs_resid\"] = df_resid[\"resid\"].abs()\n",
    "\n",
    "    # Histogram residual global\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(df_resid[\"resid\"], bins=80)\n",
    "    plt.xlabel(\"Residual (qty - pred_qty)\")\n",
    "    plt.ylabel(\"Frekuensi\")\n",
    "    plt.title(\"Histogram residual global (train + test)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(DIAG_DIR / \"hist_residual_global.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # Residual vs predicted\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.scatter(df_resid[\"pred_qty\"], df_resid[\"resid\"], alpha=0.3)\n",
    "    plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
    "    plt.xlabel(\"Predicted qty\")\n",
    "    plt.ylabel(\"Residual\")\n",
    "    plt.title(\"Residual vs predicted qty\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(DIAG_DIR / \"scatter_resid_vs_pred.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # Top outliers (train)\n",
    "    TOP_N = 50\n",
    "    top_outliers = (\n",
    "        df_resid[df_resid[\"is_train\"] == 1]\n",
    "        .sort_values(\"abs_resid\", ascending=False)\n",
    "        .head(TOP_N)\n",
    "        [[\"area\", \"cabang\", \"sku\", \"periode\", \"qty\", \"pred_qty\", \"resid\", \"abs_resid\"]]\n",
    "    )\n",
    "    OUTLIER_PATH = DIAG_DIR / \"top_outliers_train.csv\"\n",
    "    top_outliers.to_csv(OUTLIER_PATH, index=False)\n",
    "    print(\"Saved top outliers train to:\", OUTLIER_PATH)\n",
    "\n",
    "    # Hist ratio_RMSE\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(metrics_series[\"ratio_RMSE\"].dropna(), bins=30)\n",
    "    plt.xlabel(\"ratio_RMSE = test_rmse / train_rmse\")\n",
    "    plt.ylabel(\"Jumlah seri\")\n",
    "    plt.title(\"Distribusi ratio_RMSE antar seri\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(DIAG_DIR / \"hist_ratio_RMSE.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # Scatter train vs test RMSE\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(metrics_series[\"train_rmse\"], metrics_series[\"test_rmse\"], alpha=0.7)\n",
    "    max_val = np.nanmax([\n",
    "        metrics_series[\"train_rmse\"].max(),\n",
    "        metrics_series[\"test_rmse\"].max()\n",
    "    ])\n",
    "    plt.plot([0, max_val], [0, max_val], \"r--\")\n",
    "    plt.xlabel(\"Train RMSE\")\n",
    "    plt.ylabel(\"Test RMSE\")\n",
    "    plt.title(\"Train vs Test RMSE per cabangSKU\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(DIAG_DIR / \"scatter_train_vs_test_RMSE.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # Seri overfit / underfit\n",
    "    overfit_series = metrics_series[metrics_series[\"ratio_RMSE\"] > 1.3].copy()\n",
    "    under_series   = metrics_series[metrics_series[\"ratio_RMSE\"] < 0.8].copy()\n",
    "\n",
    "    print(\"\\nSeri dengan ratio_RMSE > 1.3 (indikasi sulit di test / overfit lokal):\")\n",
    "    if len(overfit_series) > 0:\n",
    "        print(\n",
    "            overfit_series[[\"cabang\", \"sku\", \"cluster\", \"train_rmse\", \"test_rmse\", \"ratio_RMSE\"]]\n",
    "            .sort_values(\"ratio_RMSE\", ascending=False)\n",
    "            .head(20)\n",
    "            .to_string(index=False)\n",
    "        )\n",
    "    else:\n",
    "        print(\"Tidak ada.\")\n",
    "\n",
    "    print(\"\\nSeri dengan ratio_RMSE < 0.8 (train lebih jelek dari test):\")\n",
    "    if len(under_series) > 0:\n",
    "        print(\n",
    "            under_series[[\"cabang\", \"sku\", \"cluster\", \"train_rmse\", \"test_rmse\", \"ratio_RMSE\"]]\n",
    "            .sort_values(\"ratio_RMSE\")\n",
    "            .head(20)\n",
    "            .to_string(index=False)\n",
    "        )\n",
    "    else:\n",
    "        print(\"Tidak ada.\")\n",
    "\n",
    "    print(\"\\nSELESAI: A+B+C+D+E (NO LEAK) + diagnostics lengkap.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d750176a",
   "metadata": {},
   "source": [
    "train semua sku eligible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8626d941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "RUN FULL TRAINING (NO LEAK): A+B+C+D+E - DATASET FULL\n",
      "====================================\n",
      "Load data: D:\\Documents\\Skripsi\\demand-forecasting\\data\\dataset_full\\lgbm_dataset_full_fullfeat.csv\n",
      "Rows: 158863\n",
      "\n",
      "[STEP 2] Build SKU profile dari TRAIN...\n",
      "Saved raw train profile to: D:\\Documents\\Skripsi\\demand-forecasting\\data\\dataset_full\\cluster_profiles_raw_train_only.csv\n",
      "\n",
      "[STEP 3] Clustering SKU (TRAIN only)...\n",
      "Saved clustered profile to: D:\\Documents\\Skripsi\\demand-forecasting\\data\\dataset_full\\cluster_profiles_full_train_only.csv\n",
      "Cluster summary (train stats):\n",
      "         qty_mean    cv  zero_ratio  total_qty\n",
      "cluster                                       \n",
      "0           53.35  1.19        0.30    2185.03\n",
      "1          116.64  0.64        0.02    4780.90\n",
      "2         2409.69  0.58        0.00   98797.44\n",
      "3           14.43  1.82        0.52     587.28\n",
      "\n",
      "[STEP 4] Merge cluster dan demand_level ke panel (train+test)...\n",
      "\n",
      "[STEP 5] Tambah hierarchy features (family)...\n",
      "Family mapping: {'AIJK': 0, 'APQR': 1, 'AQRS': 2, 'ARST': 3, 'ATUV': 4, 'AUVW': 5, 'AVWX': 6, 'AXYZ': 7, 'AYZA': 8, 'BBCD': 9, 'BCDE': 10, 'BGHI': 11, 'BKLM': 12, 'BNOP': 13, 'BOPQ': 14, 'BPQR': 15, 'BQRS': 16, 'BSTU': 17, 'BTUV': 18, 'BUVW': 19, 'BVWX': 20, 'BWXY': 21, 'BYZA': 22, 'CEFG': 23, 'CFGH': 24, 'CHIJ': 25, 'CKLM': 26, 'CVWX': 27, 'CXYZ': 28, 'CYZA': 29, 'DABC': 30, 'DCDE': 31, 'DDEF': 32, 'DGHI': 33, 'DHIJ': 34, 'DJKL': 35, 'DKLM': 36, 'DNOP': 37, 'DOPQ': 38, 'DPQR': 39, 'DQRS': 40, 'DTUV': 41, 'DUVW': 42, 'EJKL': 43, 'EKLM': 44, 'EPQR': 45, 'EQRS': 46, 'ERST': 47, 'ESTU': 48, 'EVWX': 49, 'EXYZ': 50, 'EZAB': 51, 'FHIJ': 52, 'FIJK': 53, 'FNOP': 54, 'FQRS': 55, 'FRST': 56, 'FSTU': 57, 'char': 58, 'cpox': 59, 'csb': 60, 'csw': 61}\n",
      "\n",
      "[STEP 6] Tambah stabilizer features (no leak)...\n",
      "\n",
      "[STEP 7] Winsorize outliers per SKU (no leak)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-24 02:16:28,113] A new study created in memory with name: no-name-fa8854f9-eb87-49bf-a269-c9bfa9a815cd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 8] Num features: 40\n",
      "Contoh fitur: ['event_flag', 'event_flag_lag1', 'holiday_count', 'holiday_count_lag1', 'rainfall_lag1', 'imputed', 'spike_flag', 'month', 'year', 'qtr', 'qty_lag1', 'qty_lag2', 'qty_lag3', 'qty_lag4', 'qty_lag5', 'qty_lag6', 'qty_lag7', 'qty_lag8', 'qty_lag9', 'qty_lag10']\n",
      "\n",
      "[STEP 9] Training LGBM per cluster (Tweedie, no leak)...\n",
      "\n",
      "====================================\n",
      "TRAINING CLUSTER 0\n",
      "====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-24 02:16:30,517] Trial 0 finished with value: 164.37121692825158 and parameters: {'learning_rate': 0.021923099845827587, 'num_leaves': 66, 'max_depth': 5, 'min_data_in_leaf': 103, 'feature_fraction': 0.7284002162080668, 'bagging_fraction': 0.8073571282390148, 'bagging_freq': 4}. Best is trial 0 with value: 164.37121692825158.\n",
      "[I 2025-11-24 02:16:30,938] Trial 1 finished with value: 163.30382246291862 and parameters: {'learning_rate': 0.18617280148093396, 'num_leaves': 195, 'max_depth': 3, 'min_data_in_leaf': 89, 'feature_fraction': 0.8514004718158846, 'bagging_fraction': 0.6500231705342397, 'bagging_freq': 12}. Best is trial 1 with value: 163.30382246291862.\n",
      "[I 2025-11-24 02:16:32,779] Trial 2 finished with value: 156.65571579358547 and parameters: {'learning_rate': 0.03772670263489984, 'num_leaves': 208, 'max_depth': 9, 'min_data_in_leaf': 85, 'feature_fraction': 0.7664415758283992, 'bagging_fraction': 0.8337032512441286, 'bagging_freq': 10}. Best is trial 2 with value: 156.65571579358547.\n",
      "[I 2025-11-24 02:16:35,694] Trial 3 finished with value: 170.29788408646596 and parameters: {'learning_rate': 0.017552717730729438, 'num_leaves': 95, 'max_depth': 8, 'min_data_in_leaf': 110, 'feature_fraction': 0.6714274708654108, 'bagging_fraction': 0.7652565205698636, 'bagging_freq': 3}. Best is trial 2 with value: 156.65571579358547.\n",
      "[I 2025-11-24 02:16:36,234] Trial 4 finished with value: 182.80375849127873 and parameters: {'learning_rate': 0.04917641586078737, 'num_leaves': 218, 'max_depth': 4, 'min_data_in_leaf': 193, 'feature_fraction': 0.7701658660578067, 'bagging_fraction': 0.8016028156645749, 'bagging_freq': 7}. Best is trial 2 with value: 156.65571579358547.\n",
      "[I 2025-11-24 02:16:42,182] Trial 5 finished with value: 190.33772012756376 and parameters: {'learning_rate': 0.010484437931803238, 'num_leaves': 195, 'max_depth': 10, 'min_data_in_leaf': 49, 'feature_fraction': 0.650653911876335, 'bagging_fraction': 0.7499336738320284, 'bagging_freq': 9}. Best is trial 2 with value: 156.65571579358547.\n",
      "[I 2025-11-24 02:16:44,143] Trial 6 finished with value: 150.83760194326806 and parameters: {'learning_rate': 0.010087285835579165, 'num_leaves': 114, 'max_depth': 3, 'min_data_in_leaf': 162, 'feature_fraction': 0.7399076850799927, 'bagging_fraction': 0.8810094878855033, 'bagging_freq': 6}. Best is trial 6 with value: 150.83760194326806.\n",
      "[I 2025-11-24 02:16:44,900] Trial 7 finished with value: 136.7991475307669 and parameters: {'learning_rate': 0.18438945603419024, 'num_leaves': 219, 'max_depth': 7, 'min_data_in_leaf': 122, 'feature_fraction': 0.9989556572883548, 'bagging_fraction': 0.7018896545783523, 'bagging_freq': 1}. Best is trial 7 with value: 136.7991475307669.\n",
      "[I 2025-11-24 02:16:49,471] Trial 8 finished with value: 143.92309851815298 and parameters: {'learning_rate': 0.013057207427597006, 'num_leaves': 242, 'max_depth': 10, 'min_data_in_leaf': 108, 'feature_fraction': 0.7363743886612995, 'bagging_fraction': 0.8891430471738933, 'bagging_freq': 1}. Best is trial 7 with value: 136.7991475307669.\n",
      "[I 2025-11-24 02:16:50,053] Trial 9 finished with value: 165.38410694474192 and parameters: {'learning_rate': 0.09743654578334514, 'num_leaves': 182, 'max_depth': 4, 'min_data_in_leaf': 140, 'feature_fraction': 0.9644489606241253, 'bagging_fraction': 0.6648469703039904, 'bagging_freq': 11}. Best is trial 7 with value: 136.7991475307669.\n",
      "[I 2025-11-24 02:16:50,604] Trial 10 finished with value: 134.69380082549387 and parameters: {'learning_rate': 0.1956920961985854, 'num_leaves': 150, 'max_depth': 7, 'min_data_in_leaf': 26, 'feature_fraction': 0.9380128268701577, 'bagging_fraction': 0.6084093710444248, 'bagging_freq': 1}. Best is trial 10 with value: 134.69380082549387.\n",
      "[I 2025-11-24 02:16:51,145] Trial 11 finished with value: 144.33835853801043 and parameters: {'learning_rate': 0.1975197699147762, 'num_leaves': 149, 'max_depth': 7, 'min_data_in_leaf': 34, 'feature_fraction': 0.9932277509546589, 'bagging_fraction': 0.6085270294925768, 'bagging_freq': 1}. Best is trial 10 with value: 134.69380082549387.\n",
      "[I 2025-11-24 02:16:51,876] Trial 12 finished with value: 144.6861581041705 and parameters: {'learning_rate': 0.10475482750742798, 'num_leaves': 33, 'max_depth': 6, 'min_data_in_leaf': 58, 'feature_fraction': 0.8967372474316442, 'bagging_fraction': 0.6958718362202143, 'bagging_freq': 3}. Best is trial 10 with value: 134.69380082549387.\n",
      "[I 2025-11-24 02:16:52,821] Trial 13 finished with value: 132.8106529879993 and parameters: {'learning_rate': 0.11027505427419977, 'num_leaves': 151, 'max_depth': 7, 'min_data_in_leaf': 143, 'feature_fraction': 0.9266693134033833, 'bagging_fraction': 0.9806491361735392, 'bagging_freq': 5}. Best is trial 13 with value: 132.8106529879993.\n",
      "[I 2025-11-24 02:16:53,942] Trial 14 finished with value: 121.43824185611422 and parameters: {'learning_rate': 0.10255033135264813, 'num_leaves': 146, 'max_depth': 8, 'min_data_in_leaf': 21, 'feature_fraction': 0.9103486931695306, 'bagging_fraction': 0.982541909399351, 'bagging_freq': 6}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:16:55,085] Trial 15 finished with value: 139.70285866890765 and parameters: {'learning_rate': 0.09376503783221472, 'num_leaves': 118, 'max_depth': 8, 'min_data_in_leaf': 161, 'feature_fraction': 0.85534863392725, 'bagging_fraction': 0.983830464379701, 'bagging_freq': 6}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:16:56,772] Trial 16 finished with value: 182.457816709123 and parameters: {'learning_rate': 0.06350256464900017, 'num_leaves': 167, 'max_depth': 6, 'min_data_in_leaf': 68, 'feature_fraction': 0.8988082540886079, 'bagging_fraction': 0.989582886878285, 'bagging_freq': 8}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:16:57,788] Trial 17 finished with value: 149.9724694442751 and parameters: {'learning_rate': 0.11839873541027252, 'num_leaves': 118, 'max_depth': 8, 'min_data_in_leaf': 197, 'feature_fraction': 0.8396225351052968, 'bagging_fraction': 0.9288188169142536, 'bagging_freq': 4}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:16:59,891] Trial 18 finished with value: 177.51417701022228 and parameters: {'learning_rate': 0.06964280210031616, 'num_leaves': 77, 'max_depth': 9, 'min_data_in_leaf': 141, 'feature_fraction': 0.902689309354207, 'bagging_fraction': 0.9425651391474841, 'bagging_freq': 5}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:17:02,373] Trial 19 finished with value: 180.46973221473618 and parameters: {'learning_rate': 0.031730901317003325, 'num_leaves': 133, 'max_depth': 9, 'min_data_in_leaf': 173, 'feature_fraction': 0.6012500563370582, 'bagging_fraction': 0.9455965857351764, 'bagging_freq': 8}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:17:03,321] Trial 20 finished with value: 152.76961941932123 and parameters: {'learning_rate': 0.12832601076569827, 'num_leaves': 162, 'max_depth': 5, 'min_data_in_leaf': 135, 'feature_fraction': 0.9392633593537129, 'bagging_fraction': 0.8721643593578642, 'bagging_freq': 7}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:17:04,984] Trial 21 finished with value: 138.459223177474 and parameters: {'learning_rate': 0.13606561108744733, 'num_leaves': 144, 'max_depth': 7, 'min_data_in_leaf': 22, 'feature_fraction': 0.9370065657580854, 'bagging_fraction': 0.9893576157832356, 'bagging_freq': 3}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:17:06,602] Trial 22 finished with value: 186.1624301984787 and parameters: {'learning_rate': 0.0719780443252475, 'num_leaves': 168, 'max_depth': 6, 'min_data_in_leaf': 20, 'feature_fraction': 0.8200080419998368, 'bagging_fraction': 0.9190825847165434, 'bagging_freq': 5}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:17:07,923] Trial 23 finished with value: 131.7288370148884 and parameters: {'learning_rate': 0.14997789045072185, 'num_leaves': 134, 'max_depth': 8, 'min_data_in_leaf': 44, 'feature_fraction': 0.9345713746559271, 'bagging_fraction': 0.6002424288397304, 'bagging_freq': 2}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:17:09,226] Trial 24 finished with value: 129.60747874981112 and parameters: {'learning_rate': 0.1421028665599527, 'num_leaves': 100, 'max_depth': 8, 'min_data_in_leaf': 45, 'feature_fraction': 0.8833825308885062, 'bagging_fraction': 0.853125053486187, 'bagging_freq': 5}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:17:10,481] Trial 25 finished with value: 137.79807643188963 and parameters: {'learning_rate': 0.1484071575835852, 'num_leaves': 93, 'max_depth': 8, 'min_data_in_leaf': 42, 'feature_fraction': 0.8748052376182684, 'bagging_fraction': 0.8407827050967236, 'bagging_freq': 2}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:17:12,582] Trial 26 finished with value: 126.40940100023144 and parameters: {'learning_rate': 0.08312225695137945, 'num_leaves': 57, 'max_depth': 9, 'min_data_in_leaf': 66, 'feature_fraction': 0.8079333406454079, 'bagging_fraction': 0.7597552181986413, 'bagging_freq': 4}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:17:14,516] Trial 27 finished with value: 133.60848618509894 and parameters: {'learning_rate': 0.07764786678773418, 'num_leaves': 43, 'max_depth': 9, 'min_data_in_leaf': 67, 'feature_fraction': 0.8010328087619379, 'bagging_fraction': 0.7639214453285931, 'bagging_freq': 4}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:17:17,318] Trial 28 finished with value: 129.91206234713533 and parameters: {'learning_rate': 0.05083400092988006, 'num_leaves': 64, 'max_depth': 10, 'min_data_in_leaf': 81, 'feature_fraction': 0.8321332445569103, 'bagging_fraction': 0.7242566605809437, 'bagging_freq': 6}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:17:19,349] Trial 29 finished with value: 139.82602546793902 and parameters: {'learning_rate': 0.05693860237531967, 'num_leaves': 49, 'max_depth': 9, 'min_data_in_leaf': 64, 'feature_fraction': 0.8031691847795669, 'bagging_fraction': 0.843871995917985, 'bagging_freq': 5}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:17:21,955] Trial 30 finished with value: 126.08418221789248 and parameters: {'learning_rate': 0.08675259842377087, 'num_leaves': 82, 'max_depth': 10, 'min_data_in_leaf': 52, 'feature_fraction': 0.8698872810572416, 'bagging_fraction': 0.7944796935327689, 'bagging_freq': 8}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:17:24,698] Trial 31 finished with value: 135.3842216010408 and parameters: {'learning_rate': 0.08996360120672975, 'num_leaves': 77, 'max_depth': 10, 'min_data_in_leaf': 52, 'feature_fraction': 0.8774358032758119, 'bagging_fraction': 0.7934770467470931, 'bagging_freq': 8}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:17:26,857] Trial 32 finished with value: 128.85723976160529 and parameters: {'learning_rate': 0.08386753482601429, 'num_leaves': 91, 'max_depth': 9, 'min_data_in_leaf': 36, 'feature_fraction': 0.8635752433293993, 'bagging_fraction': 0.7911582489099226, 'bagging_freq': 7}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:17:28,624] Trial 33 finished with value: 134.5092889813437 and parameters: {'learning_rate': 0.0822351061136265, 'num_leaves': 60, 'max_depth': 9, 'min_data_in_leaf': 33, 'feature_fraction': 0.8571927578240435, 'bagging_fraction': 0.7802445407504808, 'bagging_freq': 9}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:17:31,225] Trial 34 finished with value: 132.6616288982592 and parameters: {'learning_rate': 0.040176685507777594, 'num_leaves': 78, 'max_depth': 10, 'min_data_in_leaf': 91, 'feature_fraction': 0.773221652834083, 'bagging_fraction': 0.8194523291691999, 'bagging_freq': 7}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:17:33,888] Trial 35 finished with value: 158.99354132694705 and parameters: {'learning_rate': 0.03491815680405754, 'num_leaves': 89, 'max_depth': 9, 'min_data_in_leaf': 77, 'feature_fraction': 0.8172577989801949, 'bagging_fraction': 0.7438960803788032, 'bagging_freq': 9}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:17:37,086] Trial 36 finished with value: 185.11773657887028 and parameters: {'learning_rate': 0.027402975606484477, 'num_leaves': 109, 'max_depth': 10, 'min_data_in_leaf': 34, 'feature_fraction': 0.7763427425684744, 'bagging_fraction': 0.8172484259306813, 'bagging_freq': 11}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:17:38,597] Trial 37 finished with value: 138.2264823792201 and parameters: {'learning_rate': 0.06291567411309468, 'num_leaves': 31, 'max_depth': 9, 'min_data_in_leaf': 95, 'feature_fraction': 0.6851421693555938, 'bagging_fraction': 0.7823453568083578, 'bagging_freq': 8}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:17:40,472] Trial 38 finished with value: 134.78762776851147 and parameters: {'learning_rate': 0.04581147426404358, 'num_leaves': 56, 'max_depth': 8, 'min_data_in_leaf': 53, 'feature_fraction': 0.8577650993413459, 'bagging_fraction': 0.7281587674635109, 'bagging_freq': 7}. Best is trial 14 with value: 121.43824185611422.\n",
      "[I 2025-11-24 02:17:42,446] Trial 39 finished with value: 121.2480772507516 and parameters: {'learning_rate': 0.08467121809214785, 'num_leaves': 126, 'max_depth': 10, 'min_data_in_leaf': 37, 'feature_fraction': 0.9087335999405393, 'bagging_fraction': 0.8014058624539285, 'bagging_freq': 10}. Best is trial 39 with value: 121.2480772507516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: model saved to D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\lgbm_full_clusters_tweedie_noleak\\models\\lgbm_full_cluster_0.txt\n",
      "\n",
      "====================================\n",
      "TRAINING CLUSTER 1\n",
      "====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-24 02:17:45,759] A new study created in memory with name: no-name-a5c66818-9aa5-4186-8213-261ab728b76e\n",
      "[I 2025-11-24 02:18:08,283] Trial 0 finished with value: 35.63993085063561 and parameters: {'learning_rate': 0.021923099845827587, 'num_leaves': 66, 'max_depth': 5, 'min_data_in_leaf': 103, 'feature_fraction': 0.7284002162080668, 'bagging_fraction': 0.8073571282390148, 'bagging_freq': 4}. Best is trial 0 with value: 35.63993085063561.\n",
      "[I 2025-11-24 02:18:21,219] Trial 1 finished with value: 42.70448914025789 and parameters: {'learning_rate': 0.18617280148093396, 'num_leaves': 195, 'max_depth': 3, 'min_data_in_leaf': 89, 'feature_fraction': 0.8514004718158846, 'bagging_fraction': 0.6500231705342397, 'bagging_freq': 12}. Best is trial 0 with value: 35.63993085063561.\n",
      "[I 2025-11-24 02:18:50,119] Trial 2 finished with value: 26.735313936919482 and parameters: {'learning_rate': 0.03772670263489984, 'num_leaves': 208, 'max_depth': 9, 'min_data_in_leaf': 85, 'feature_fraction': 0.7664415758283992, 'bagging_fraction': 0.8337032512441286, 'bagging_freq': 10}. Best is trial 2 with value: 26.735313936919482.\n",
      "[I 2025-11-24 02:19:16,411] Trial 3 finished with value: 30.12946211207873 and parameters: {'learning_rate': 0.017552717730729438, 'num_leaves': 95, 'max_depth': 8, 'min_data_in_leaf': 110, 'feature_fraction': 0.6714274708654108, 'bagging_fraction': 0.7652565205698636, 'bagging_freq': 3}. Best is trial 2 with value: 26.735313936919482.\n",
      "[I 2025-11-24 02:19:29,474] Trial 4 finished with value: 39.49236234995039 and parameters: {'learning_rate': 0.04917641586078737, 'num_leaves': 218, 'max_depth': 4, 'min_data_in_leaf': 193, 'feature_fraction': 0.7701658660578067, 'bagging_fraction': 0.8016028156645749, 'bagging_freq': 7}. Best is trial 2 with value: 26.735313936919482.\n",
      "[I 2025-11-24 02:19:59,724] Trial 5 finished with value: 25.30034568771706 and parameters: {'learning_rate': 0.010484437931803238, 'num_leaves': 195, 'max_depth': 10, 'min_data_in_leaf': 49, 'feature_fraction': 0.650653911876335, 'bagging_fraction': 0.7499336738320284, 'bagging_freq': 9}. Best is trial 5 with value: 25.30034568771706.\n",
      "[I 2025-11-24 02:20:11,005] Trial 6 finished with value: 68.07338696959042 and parameters: {'learning_rate': 0.010087285835579165, 'num_leaves': 114, 'max_depth': 3, 'min_data_in_leaf': 162, 'feature_fraction': 0.7399076850799927, 'bagging_fraction': 0.8810094878855033, 'bagging_freq': 6}. Best is trial 5 with value: 25.30034568771706.\n",
      "[I 2025-11-24 02:20:15,634] Trial 7 finished with value: 33.081046226617026 and parameters: {'learning_rate': 0.18438945603419024, 'num_leaves': 219, 'max_depth': 7, 'min_data_in_leaf': 122, 'feature_fraction': 0.9989556572883548, 'bagging_fraction': 0.7018896545783523, 'bagging_freq': 1}. Best is trial 5 with value: 25.30034568771706.\n",
      "[I 2025-11-24 02:20:42,557] Trial 8 finished with value: 24.872888129301053 and parameters: {'learning_rate': 0.013057207427597006, 'num_leaves': 242, 'max_depth': 10, 'min_data_in_leaf': 108, 'feature_fraction': 0.7363743886612995, 'bagging_fraction': 0.8891430471738933, 'bagging_freq': 1}. Best is trial 8 with value: 24.872888129301053.\n",
      "[I 2025-11-24 02:20:51,913] Trial 9 finished with value: 42.95181133695545 and parameters: {'learning_rate': 0.09743654578334514, 'num_leaves': 182, 'max_depth': 4, 'min_data_in_leaf': 140, 'feature_fraction': 0.9644489606241253, 'bagging_fraction': 0.6648469703039904, 'bagging_freq': 11}. Best is trial 8 with value: 24.872888129301053.\n",
      "[I 2025-11-24 02:21:19,620] Trial 10 finished with value: 20.62316050519757 and parameters: {'learning_rate': 0.03866567677927556, 'num_leaves': 248, 'max_depth': 10, 'min_data_in_leaf': 26, 'feature_fraction': 0.8731441472741235, 'bagging_fraction': 0.9346681200663051, 'bagging_freq': 1}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:22:05,602] Trial 11 finished with value: 20.77896907765418 and parameters: {'learning_rate': 0.04104330069206297, 'num_leaves': 253, 'max_depth': 10, 'min_data_in_leaf': 24, 'feature_fraction': 0.8685011728765828, 'bagging_fraction': 0.9861211916036627, 'bagging_freq': 1}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:22:34,676] Trial 12 finished with value: 24.099359883346274 and parameters: {'learning_rate': 0.04516895018189831, 'num_leaves': 250, 'max_depth': 8, 'min_data_in_leaf': 23, 'feature_fraction': 0.8721199633776775, 'bagging_fraction': 0.9725146472856079, 'bagging_freq': 3}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:22:57,237] Trial 13 finished with value: 22.594714393723706 and parameters: {'learning_rate': 0.07509878854731755, 'num_leaves': 151, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.9008043525004048, 'bagging_fraction': 0.9931500703170151, 'bagging_freq': 5}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:23:17,543] Trial 14 finished with value: 31.39843139854892 and parameters: {'learning_rate': 0.026452371192692038, 'num_leaves': 153, 'max_depth': 6, 'min_data_in_leaf': 57, 'feature_fraction': 0.8397583926954, 'bagging_fraction': 0.9320561058751814, 'bagging_freq': 1}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:23:52,530] Trial 15 finished with value: 24.269940439997413 and parameters: {'learning_rate': 0.0723333699820115, 'num_leaves': 255, 'max_depth': 9, 'min_data_in_leaf': 53, 'feature_fraction': 0.9347475791738303, 'bagging_fraction': 0.9365428793749967, 'bagging_freq': 3}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:24:18,249] Trial 16 finished with value: 25.232249265363528 and parameters: {'learning_rate': 0.035053453123187125, 'num_leaves': 34, 'max_depth': 8, 'min_data_in_leaf': 40, 'feature_fraction': 0.8164394419584702, 'bagging_fraction': 0.8775496853387972, 'bagging_freq': 8}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:24:57,082] Trial 17 finished with value: 25.5417888533042 and parameters: {'learning_rate': 0.05540656891481538, 'num_leaves': 170, 'max_depth': 9, 'min_data_in_leaf': 70, 'feature_fraction': 0.9056139819885901, 'bagging_fraction': 0.9302643657202617, 'bagging_freq': 2}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:25:23,202] Trial 18 finished with value: 26.627200361333912 and parameters: {'learning_rate': 0.11407814491966922, 'num_leaves': 230, 'max_depth': 7, 'min_data_in_leaf': 34, 'feature_fraction': 0.8133698035986466, 'bagging_fraction': 0.9983485379389582, 'bagging_freq': 5}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:25:58,187] Trial 19 finished with value: 24.82231581111596 and parameters: {'learning_rate': 0.02744250432484762, 'num_leaves': 133, 'max_depth': 10, 'min_data_in_leaf': 72, 'feature_fraction': 0.6012500563370582, 'bagging_fraction': 0.9561606377073089, 'bagging_freq': 2}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:26:19,462] Trial 20 finished with value: 32.21164572083767 and parameters: {'learning_rate': 0.017892549432402313, 'num_leaves': 234, 'max_depth': 6, 'min_data_in_leaf': 67, 'feature_fraction': 0.8904696480593849, 'bagging_fraction': 0.84570713102999, 'bagging_freq': 4}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:26:44,035] Trial 21 finished with value: 22.884342608200974 and parameters: {'learning_rate': 0.07560857374256537, 'num_leaves': 155, 'max_depth': 10, 'min_data_in_leaf': 22, 'feature_fraction': 0.918961444472928, 'bagging_fraction': 0.9942504660382027, 'bagging_freq': 5}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:27:17,289] Trial 22 finished with value: 23.162930475501778 and parameters: {'learning_rate': 0.0644610907522618, 'num_leaves': 94, 'max_depth': 9, 'min_data_in_leaf': 20, 'feature_fraction': 0.9477807272382016, 'bagging_fraction': 0.9124214759914888, 'bagging_freq': 2}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:27:30,661] Trial 23 finished with value: 25.989650583137895 and parameters: {'learning_rate': 0.10288626790322956, 'num_leaves': 173, 'max_depth': 10, 'min_data_in_leaf': 39, 'feature_fraction': 0.865274798892481, 'bagging_fraction': 0.604880886884489, 'bagging_freq': 7}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:28:07,025] Trial 24 finished with value: 22.747279217985362 and parameters: {'learning_rate': 0.033825869441417425, 'num_leaves': 202, 'max_depth': 9, 'min_data_in_leaf': 37, 'feature_fraction': 0.8948492800435393, 'bagging_fraction': 0.969146997402819, 'bagging_freq': 5}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:28:34,122] Trial 25 finished with value: 23.913341714354992 and parameters: {'learning_rate': 0.05909089497657208, 'num_leaves': 129, 'max_depth': 8, 'min_data_in_leaf': 50, 'feature_fraction': 0.9790629275779342, 'bagging_fraction': 0.9976550066630094, 'bagging_freq': 1}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:29:10,270] Trial 26 finished with value: 22.563285536824914 and parameters: {'learning_rate': 0.08803189707675933, 'num_leaves': 228, 'max_depth': 10, 'min_data_in_leaf': 29, 'feature_fraction': 0.8374774157554532, 'bagging_fraction': 0.9538070178638116, 'bagging_freq': 4}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:29:49,682] Trial 27 finished with value: 25.697128339136174 and parameters: {'learning_rate': 0.13240642335865618, 'num_leaves': 227, 'max_depth': 9, 'min_data_in_leaf': 61, 'feature_fraction': 0.7874398037092529, 'bagging_fraction': 0.8997877911356889, 'bagging_freq': 2}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:30:51,375] Trial 28 finished with value: 25.20270435414917 and parameters: {'learning_rate': 0.040736423763965614, 'num_leaves': 254, 'max_depth': 10, 'min_data_in_leaf': 85, 'feature_fraction': 0.8301978980268321, 'bagging_fraction': 0.851901101974025, 'bagging_freq': 4}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:31:37,197] Trial 29 finished with value: 25.969125727287462 and parameters: {'learning_rate': 0.02281019047188558, 'num_leaves': 240, 'max_depth': 7, 'min_data_in_leaf': 35, 'feature_fraction': 0.7918373176052272, 'bagging_fraction': 0.9536368158499369, 'bagging_freq': 3}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:31:58,390] Trial 30 finished with value: 33.62798915902536 and parameters: {'learning_rate': 0.029782697096478974, 'num_leaves': 213, 'max_depth': 5, 'min_data_in_leaf': 125, 'feature_fraction': 0.8698872810572416, 'bagging_fraction': 0.9216563867255417, 'bagging_freq': 4}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:32:29,031] Trial 31 finished with value: 23.024651813305727 and parameters: {'learning_rate': 0.09110229271593588, 'num_leaves': 233, 'max_depth': 10, 'min_data_in_leaf': 28, 'feature_fraction': 0.9207536192324713, 'bagging_fraction': 0.9649673055085027, 'bagging_freq': 6}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:32:49,269] Trial 32 finished with value: 22.064043165124428 and parameters: {'learning_rate': 0.14480104814620032, 'num_leaves': 52, 'max_depth': 9, 'min_data_in_leaf': 44, 'feature_fraction': 0.8380482637648734, 'bagging_fraction': 0.9759080754257281, 'bagging_freq': 5}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:33:08,002] Trial 33 finished with value: 26.58849651630825 and parameters: {'learning_rate': 0.1407279356170933, 'num_leaves': 31, 'max_depth': 9, 'min_data_in_leaf': 45, 'feature_fraction': 0.8460505333548323, 'bagging_fraction': 0.9461328953337838, 'bagging_freq': 4}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:33:23,493] Trial 34 finished with value: 21.65564361138568 and parameters: {'learning_rate': 0.16154392547790916, 'num_leaves': 68, 'max_depth': 9, 'min_data_in_leaf': 82, 'feature_fraction': 0.8516643258723287, 'bagging_fraction': 0.9738669729763672, 'bagging_freq': 2}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:33:34,328] Trial 35 finished with value: 27.635530458228654 and parameters: {'learning_rate': 0.18303078058966832, 'num_leaves': 57, 'max_depth': 8, 'min_data_in_leaf': 95, 'feature_fraction': 0.8745306683924156, 'bagging_fraction': 0.9767247650460392, 'bagging_freq': 2}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:33:44,545] Trial 36 finished with value: 28.760258425146404 and parameters: {'learning_rate': 0.14608010643572772, 'num_leaves': 78, 'max_depth': 9, 'min_data_in_leaf': 96, 'feature_fraction': 0.8042326392096499, 'bagging_fraction': 0.9026387275461172, 'bagging_freq': 1}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:34:08,493] Trial 37 finished with value: 27.38827635763259 and parameters: {'learning_rate': 0.04558459348797334, 'num_leaves': 66, 'max_depth': 8, 'min_data_in_leaf': 79, 'feature_fraction': 0.7658353923316013, 'bagging_fraction': 0.7902324270888865, 'bagging_freq': 3}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:34:27,910] Trial 38 finished with value: 28.772377670378695 and parameters: {'learning_rate': 0.16307784052943197, 'num_leaves': 44, 'max_depth': 9, 'min_data_in_leaf': 46, 'feature_fraction': 0.8577650993413459, 'bagging_fraction': 0.8647030807734803, 'bagging_freq': 9}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:35:07,324] Trial 39 finished with value: 24.740905652489154 and parameters: {'learning_rate': 0.019157117113125642, 'num_leaves': 101, 'max_depth': 9, 'min_data_in_leaf': 62, 'feature_fraction': 0.6988464585544988, 'bagging_fraction': 0.8313662928286008, 'bagging_freq': 12}. Best is trial 10 with value: 20.62316050519757.\n",
      "[I 2025-11-24 02:35:15,427] A new study created in memory with name: no-name-a66260bc-1d61-4e83-836d-75826503d83f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1: model saved to D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\lgbm_full_clusters_tweedie_noleak\\models\\lgbm_full_cluster_1.txt\n",
      "\n",
      "====================================\n",
      "TRAINING CLUSTER 2\n",
      "====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-24 02:35:16,228] Trial 0 finished with value: 1087.0862007958247 and parameters: {'learning_rate': 0.021923099845827587, 'num_leaves': 66, 'max_depth': 5, 'min_data_in_leaf': 103, 'feature_fraction': 0.7284002162080668, 'bagging_fraction': 0.8073571282390148, 'bagging_freq': 4}. Best is trial 0 with value: 1087.0862007958247.\n",
      "[I 2025-11-24 02:35:16,407] Trial 1 finished with value: 1324.0815780783455 and parameters: {'learning_rate': 0.18617280148093396, 'num_leaves': 195, 'max_depth': 3, 'min_data_in_leaf': 89, 'feature_fraction': 0.8514004718158846, 'bagging_fraction': 0.6500231705342397, 'bagging_freq': 12}. Best is trial 0 with value: 1087.0862007958247.\n",
      "[I 2025-11-24 02:35:17,172] Trial 2 finished with value: 973.772697085323 and parameters: {'learning_rate': 0.03772670263489984, 'num_leaves': 208, 'max_depth': 9, 'min_data_in_leaf': 85, 'feature_fraction': 0.7664415758283992, 'bagging_fraction': 0.8337032512441286, 'bagging_freq': 10}. Best is trial 2 with value: 973.772697085323.\n",
      "[I 2025-11-24 02:35:18,484] Trial 3 finished with value: 1066.2499674955573 and parameters: {'learning_rate': 0.017552717730729438, 'num_leaves': 95, 'max_depth': 8, 'min_data_in_leaf': 110, 'feature_fraction': 0.6714274708654108, 'bagging_fraction': 0.7652565205698636, 'bagging_freq': 3}. Best is trial 2 with value: 973.772697085323.\n",
      "[I 2025-11-24 02:35:18,903] Trial 4 finished with value: 1436.5814762794896 and parameters: {'learning_rate': 0.04917641586078737, 'num_leaves': 218, 'max_depth': 4, 'min_data_in_leaf': 193, 'feature_fraction': 0.7701658660578067, 'bagging_fraction': 0.8016028156645749, 'bagging_freq': 7}. Best is trial 2 with value: 973.772697085323.\n",
      "[I 2025-11-24 02:35:20,926] Trial 5 finished with value: 1003.9333842482722 and parameters: {'learning_rate': 0.010484437931803238, 'num_leaves': 195, 'max_depth': 10, 'min_data_in_leaf': 49, 'feature_fraction': 0.650653911876335, 'bagging_fraction': 0.7499336738320284, 'bagging_freq': 9}. Best is trial 2 with value: 973.772697085323.\n",
      "[I 2025-11-24 02:35:21,780] Trial 6 finished with value: 1386.5741332668997 and parameters: {'learning_rate': 0.010087285835579165, 'num_leaves': 114, 'max_depth': 3, 'min_data_in_leaf': 162, 'feature_fraction': 0.7399076850799927, 'bagging_fraction': 0.8810094878855033, 'bagging_freq': 6}. Best is trial 2 with value: 973.772697085323.\n",
      "[I 2025-11-24 02:35:22,019] Trial 7 finished with value: 1081.421372368812 and parameters: {'learning_rate': 0.18438945603419024, 'num_leaves': 219, 'max_depth': 7, 'min_data_in_leaf': 122, 'feature_fraction': 0.9989556572883548, 'bagging_fraction': 0.7018896545783523, 'bagging_freq': 1}. Best is trial 2 with value: 973.772697085323.\n",
      "[I 2025-11-24 02:35:23,944] Trial 8 finished with value: 1024.282171869245 and parameters: {'learning_rate': 0.013057207427597006, 'num_leaves': 242, 'max_depth': 10, 'min_data_in_leaf': 108, 'feature_fraction': 0.7363743886612995, 'bagging_fraction': 0.8891430471738933, 'bagging_freq': 1}. Best is trial 2 with value: 973.772697085323.\n",
      "[I 2025-11-24 02:35:24,180] Trial 9 finished with value: 1382.1625034036622 and parameters: {'learning_rate': 0.09743654578334514, 'num_leaves': 182, 'max_depth': 4, 'min_data_in_leaf': 140, 'feature_fraction': 0.9644489606241253, 'bagging_fraction': 0.6648469703039904, 'bagging_freq': 11}. Best is trial 2 with value: 973.772697085323.\n",
      "[I 2025-11-24 02:35:25,180] Trial 10 finished with value: 882.2015413112362 and parameters: {'learning_rate': 0.03608224558766931, 'num_leaves': 150, 'max_depth': 8, 'min_data_in_leaf': 26, 'feature_fraction': 0.8530834863107196, 'bagging_fraction': 0.9346681200663051, 'bagging_freq': 9}. Best is trial 10 with value: 882.2015413112362.\n",
      "[I 2025-11-24 02:35:25,971] Trial 11 finished with value: 1080.3501259284606 and parameters: {'learning_rate': 0.03728779107707359, 'num_leaves': 151, 'max_depth': 8, 'min_data_in_leaf': 23, 'feature_fraction': 0.8591617204722812, 'bagging_fraction': 0.9723351352588018, 'bagging_freq': 9}. Best is trial 10 with value: 882.2015413112362.\n",
      "[I 2025-11-24 02:35:28,807] Trial 12 finished with value: 876.9192502015775 and parameters: {'learning_rate': 0.043156642132442705, 'num_leaves': 142, 'max_depth': 9, 'min_data_in_leaf': 67, 'feature_fraction': 0.8402546251281662, 'bagging_fraction': 0.9590350061125075, 'bagging_freq': 10}. Best is trial 12 with value: 876.9192502015775.\n",
      "[I 2025-11-24 02:35:30,422] Trial 13 finished with value: 910.0186052699189 and parameters: {'learning_rate': 0.06732467269901733, 'num_leaves': 151, 'max_depth': 6, 'min_data_in_leaf': 53, 'feature_fraction': 0.8801717639695966, 'bagging_fraction': 0.9931500703170151, 'bagging_freq': 7}. Best is trial 12 with value: 876.9192502015775.\n",
      "[I 2025-11-24 02:35:32,699] Trial 14 finished with value: 881.772505692677 and parameters: {'learning_rate': 0.025417546590970952, 'num_leaves': 112, 'max_depth': 8, 'min_data_in_leaf': 20, 'feature_fraction': 0.9313551783159139, 'bagging_fraction': 0.9312547355867189, 'bagging_freq': 9}. Best is trial 12 with value: 876.9192502015775.\n",
      "[I 2025-11-24 02:35:34,436] Trial 15 finished with value: 883.788262088428 and parameters: {'learning_rate': 0.024214687715781346, 'num_leaves': 45, 'max_depth': 9, 'min_data_in_leaf': 57, 'feature_fraction': 0.9342868272089234, 'bagging_fraction': 0.9176530142771471, 'bagging_freq': 12}. Best is trial 12 with value: 876.9192502015775.\n",
      "[I 2025-11-24 02:35:36,301] Trial 16 finished with value: 1013.7992318696014 and parameters: {'learning_rate': 0.08272845321887419, 'num_leaves': 108, 'max_depth': 7, 'min_data_in_leaf': 71, 'feature_fraction': 0.9136936400627178, 'bagging_fraction': 0.9508946266216388, 'bagging_freq': 8}. Best is trial 12 with value: 876.9192502015775.\n",
      "[I 2025-11-24 02:35:38,279] Trial 17 finished with value: 883.5758037984357 and parameters: {'learning_rate': 0.027191252514231868, 'num_leaves': 81, 'max_depth': 9, 'min_data_in_leaf': 38, 'feature_fraction': 0.8154969417770326, 'bagging_fraction': 0.8783534931492161, 'bagging_freq': 10}. Best is trial 12 with value: 876.9192502015775.\n",
      "[I 2025-11-24 02:35:40,674] Trial 18 finished with value: 1052.9287656303177 and parameters: {'learning_rate': 0.058217190776789496, 'num_leaves': 125, 'max_depth': 6, 'min_data_in_leaf': 73, 'feature_fraction': 0.9088419241462452, 'bagging_fraction': 0.9969368285548397, 'bagging_freq': 5}. Best is trial 12 with value: 876.9192502015775.\n",
      "[I 2025-11-24 02:35:42,326] Trial 19 finished with value: 973.7200474515761 and parameters: {'learning_rate': 0.10166635725943858, 'num_leaves': 173, 'max_depth': 10, 'min_data_in_leaf': 35, 'feature_fraction': 0.6012500563370582, 'bagging_fraction': 0.8391499910635799, 'bagging_freq': 11}. Best is trial 12 with value: 876.9192502015775.\n",
      "[I 2025-11-24 02:35:43,471] Trial 20 finished with value: 938.884243732542 and parameters: {'learning_rate': 0.018290314094879336, 'num_leaves': 131, 'max_depth': 7, 'min_data_in_leaf': 67, 'feature_fraction': 0.8133256466020756, 'bagging_fraction': 0.9151957249060965, 'bagging_freq': 8}. Best is trial 12 with value: 876.9192502015775.\n",
      "[I 2025-11-24 02:35:45,942] Trial 21 finished with value: 824.2461850976152 and parameters: {'learning_rate': 0.03314080989497029, 'num_leaves': 162, 'max_depth': 8, 'min_data_in_leaf': 22, 'feature_fraction': 0.8368308764555914, 'bagging_fraction': 0.9425823412449589, 'bagging_freq': 9}. Best is trial 21 with value: 824.2461850976152.\n",
      "[I 2025-11-24 02:35:46,939] Trial 22 finished with value: 854.2029253228407 and parameters: {'learning_rate': 0.0300383181188831, 'num_leaves': 161, 'max_depth': 8, 'min_data_in_leaf': 20, 'feature_fraction': 0.948342584898018, 'bagging_fraction': 0.9585140683746503, 'bagging_freq': 10}. Best is trial 21 with value: 824.2461850976152.\n",
      "[I 2025-11-24 02:35:49,831] Trial 23 finished with value: 932.653909081645 and parameters: {'learning_rate': 0.033062804904013574, 'num_leaves': 169, 'max_depth': 9, 'min_data_in_leaf': 43, 'feature_fraction': 0.9798901094885986, 'bagging_fraction': 0.9671317183536928, 'bagging_freq': 11}. Best is trial 21 with value: 824.2461850976152.\n",
      "[I 2025-11-24 02:35:51,333] Trial 24 finished with value: 965.4308224739583 and parameters: {'learning_rate': 0.053138646428339674, 'num_leaves': 162, 'max_depth': 8, 'min_data_in_leaf': 33, 'feature_fraction': 0.8914195960901091, 'bagging_fraction': 0.847932634742513, 'bagging_freq': 10}. Best is trial 21 with value: 824.2461850976152.\n",
      "[I 2025-11-24 02:35:52,141] Trial 25 finished with value: 937.5627966986095 and parameters: {'learning_rate': 0.0288919159259117, 'num_leaves': 135, 'max_depth': 9, 'min_data_in_leaf': 56, 'feature_fraction': 0.8098878271632862, 'bagging_fraction': 0.6078406875997995, 'bagging_freq': 8}. Best is trial 21 with value: 824.2461850976152.\n",
      "[I 2025-11-24 02:35:52,758] Trial 26 finished with value: 1106.7745224840498 and parameters: {'learning_rate': 0.04421785605329304, 'num_leaves': 188, 'max_depth': 7, 'min_data_in_leaf': 90, 'feature_fraction': 0.9488748272851436, 'bagging_fraction': 0.9061534773342647, 'bagging_freq': 10}. Best is trial 21 with value: 824.2461850976152.\n",
      "[I 2025-11-24 02:35:55,753] Trial 27 finished with value: 958.7039148999042 and parameters: {'learning_rate': 0.016943634524440587, 'num_leaves': 248, 'max_depth': 6, 'min_data_in_leaf': 40, 'feature_fraction': 0.8369906545015682, 'bagging_fraction': 0.9680894967815709, 'bagging_freq': 12}. Best is trial 21 with value: 824.2461850976152.\n",
      "[I 2025-11-24 02:35:57,003] Trial 28 finished with value: 884.4968069848932 and parameters: {'learning_rate': 0.0444227742724817, 'num_leaves': 159, 'max_depth': 8, 'min_data_in_leaf': 20, 'feature_fraction': 0.77613013006276, 'bagging_fraction': 0.8639045966888675, 'bagging_freq': 6}. Best is trial 21 with value: 824.2461850976152.\n",
      "[I 2025-11-24 02:35:58,082] Trial 29 finished with value: 1072.8204050187526 and parameters: {'learning_rate': 0.020797382492178232, 'num_leaves': 62, 'max_depth': 5, 'min_data_in_leaf': 131, 'feature_fraction': 0.6841913546909171, 'bagging_fraction': 0.9522121107255378, 'bagging_freq': 11}. Best is trial 21 with value: 824.2461850976152.\n",
      "[I 2025-11-24 02:36:01,067] Trial 30 finished with value: 1015.0689640284385 and parameters: {'learning_rate': 0.07684873592886365, 'num_leaves': 136, 'max_depth': 10, 'min_data_in_leaf': 66, 'feature_fraction': 0.8743368322114428, 'bagging_fraction': 0.9961491537272591, 'bagging_freq': 8}. Best is trial 21 with value: 824.2461850976152.\n",
      "[I 2025-11-24 02:36:02,756] Trial 31 finished with value: 805.2741885067212 and parameters: {'learning_rate': 0.02930563828988517, 'num_leaves': 115, 'max_depth': 8, 'min_data_in_leaf': 20, 'feature_fraction': 0.9248455886481614, 'bagging_fraction': 0.9399554492290959, 'bagging_freq': 9}. Best is trial 31 with value: 805.2741885067212.\n",
      "[I 2025-11-24 02:36:03,982] Trial 32 finished with value: 887.3868613338071 and parameters: {'learning_rate': 0.032175937414046014, 'num_leaves': 94, 'max_depth': 9, 'min_data_in_leaf': 30, 'feature_fraction': 0.9080227912005187, 'bagging_fraction': 0.9382779034130206, 'bagging_freq': 10}. Best is trial 31 with value: 805.2741885067212.\n",
      "[I 2025-11-24 02:36:04,919] Trial 33 finished with value: 1012.0035373426875 and parameters: {'learning_rate': 0.02149106483634207, 'num_leaves': 126, 'max_depth': 7, 'min_data_in_leaf': 83, 'feature_fraction': 0.8389655691726094, 'bagging_fraction': 0.8982165420364844, 'bagging_freq': 9}. Best is trial 31 with value: 805.2741885067212.\n",
      "[I 2025-11-24 02:36:05,665] Trial 34 finished with value: 978.1749898798034 and parameters: {'learning_rate': 0.04181568773788521, 'num_leaves': 94, 'max_depth': 8, 'min_data_in_leaf': 97, 'feature_fraction': 0.9496959285500665, 'bagging_fraction': 0.9737423267382759, 'bagging_freq': 7}. Best is trial 31 with value: 805.2741885067212.\n",
      "[I 2025-11-24 02:36:06,876] Trial 35 finished with value: 920.6070707483977 and parameters: {'learning_rate': 0.03145238553881645, 'num_leaves': 202, 'max_depth': 9, 'min_data_in_leaf': 43, 'feature_fraction': 0.8901442544629199, 'bagging_fraction': 0.8213304668554293, 'bagging_freq': 12}. Best is trial 31 with value: 805.2741885067212.\n",
      "[I 2025-11-24 02:36:07,705] Trial 36 finished with value: 953.0568824841855 and parameters: {'learning_rate': 0.06138450100815646, 'num_leaves': 176, 'max_depth': 8, 'min_data_in_leaf': 50, 'feature_fraction': 0.9997353864171341, 'bagging_fraction': 0.7492401197497842, 'bagging_freq': 10}. Best is trial 31 with value: 805.2741885067212.\n",
      "[I 2025-11-24 02:36:09,484] Trial 37 finished with value: 960.8226927056602 and parameters: {'learning_rate': 0.014698719924986173, 'num_leaves': 141, 'max_depth': 9, 'min_data_in_leaf': 29, 'feature_fraction': 0.7878266059848089, 'bagging_fraction': 0.9247655885600532, 'bagging_freq': 3}. Best is trial 31 with value: 805.2741885067212.\n",
      "[I 2025-11-24 02:36:10,192] Trial 38 finished with value: 923.5004431414014 and parameters: {'learning_rate': 0.04942436374366994, 'num_leaves': 72, 'max_depth': 7, 'min_data_in_leaf': 59, 'feature_fraction': 0.8301022855624978, 'bagging_fraction': 0.7903037345936285, 'bagging_freq': 9}. Best is trial 31 with value: 805.2741885067212.\n",
      "[I 2025-11-24 02:36:11,096] Trial 39 finished with value: 1112.8248605354927 and parameters: {'learning_rate': 0.03893358687752273, 'num_leaves': 216, 'max_depth': 10, 'min_data_in_leaf': 167, 'feature_fraction': 0.8648629647530109, 'bagging_fraction': 0.9520104849864063, 'bagging_freq': 11}. Best is trial 31 with value: 805.2741885067212.\n",
      "[I 2025-11-24 02:36:11,767] A new study created in memory with name: no-name-49fa5c11-5b5d-4019-ab35-3061214d1534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 2: model saved to D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\lgbm_full_clusters_tweedie_noleak\\models\\lgbm_full_cluster_2.txt\n",
      "\n",
      "====================================\n",
      "TRAINING CLUSTER 3\n",
      "====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-24 02:36:16,237] Trial 0 finished with value: 57.01806957753861 and parameters: {'learning_rate': 0.021923099845827587, 'num_leaves': 66, 'max_depth': 5, 'min_data_in_leaf': 103, 'feature_fraction': 0.7284002162080668, 'bagging_fraction': 0.8073571282390148, 'bagging_freq': 4}. Best is trial 0 with value: 57.01806957753861.\n",
      "[I 2025-11-24 02:36:16,964] Trial 1 finished with value: 61.18928751999034 and parameters: {'learning_rate': 0.18617280148093396, 'num_leaves': 195, 'max_depth': 3, 'min_data_in_leaf': 89, 'feature_fraction': 0.8514004718158846, 'bagging_fraction': 0.6500231705342397, 'bagging_freq': 12}. Best is trial 0 with value: 57.01806957753861.\n",
      "[I 2025-11-24 02:36:20,298] Trial 2 finished with value: 53.30257546124513 and parameters: {'learning_rate': 0.03772670263489984, 'num_leaves': 208, 'max_depth': 9, 'min_data_in_leaf': 85, 'feature_fraction': 0.7664415758283992, 'bagging_fraction': 0.8337032512441286, 'bagging_freq': 10}. Best is trial 2 with value: 53.30257546124513.\n",
      "[I 2025-11-24 02:36:22,409] Trial 3 finished with value: 58.51255023355993 and parameters: {'learning_rate': 0.017552717730729438, 'num_leaves': 95, 'max_depth': 8, 'min_data_in_leaf': 110, 'feature_fraction': 0.6714274708654108, 'bagging_fraction': 0.7652565205698636, 'bagging_freq': 3}. Best is trial 2 with value: 53.30257546124513.\n",
      "[I 2025-11-24 02:36:23,657] Trial 4 finished with value: 58.426247923020085 and parameters: {'learning_rate': 0.04917641586078737, 'num_leaves': 218, 'max_depth': 4, 'min_data_in_leaf': 193, 'feature_fraction': 0.7701658660578067, 'bagging_fraction': 0.8016028156645749, 'bagging_freq': 7}. Best is trial 2 with value: 53.30257546124513.\n",
      "[I 2025-11-24 02:36:27,187] Trial 5 finished with value: 62.23173487101718 and parameters: {'learning_rate': 0.010484437931803238, 'num_leaves': 195, 'max_depth': 10, 'min_data_in_leaf': 49, 'feature_fraction': 0.650653911876335, 'bagging_fraction': 0.7499336738320284, 'bagging_freq': 9}. Best is trial 2 with value: 53.30257546124513.\n",
      "[I 2025-11-24 02:36:31,123] Trial 6 finished with value: 56.34121306143786 and parameters: {'learning_rate': 0.010087285835579165, 'num_leaves': 114, 'max_depth': 3, 'min_data_in_leaf': 162, 'feature_fraction': 0.7399076850799927, 'bagging_fraction': 0.8810094878855033, 'bagging_freq': 6}. Best is trial 2 with value: 53.30257546124513.\n",
      "[I 2025-11-24 02:36:31,686] Trial 7 finished with value: 53.423106228557806 and parameters: {'learning_rate': 0.18438945603419024, 'num_leaves': 219, 'max_depth': 7, 'min_data_in_leaf': 122, 'feature_fraction': 0.9989556572883548, 'bagging_fraction': 0.7018896545783523, 'bagging_freq': 1}. Best is trial 2 with value: 53.30257546124513.\n",
      "[I 2025-11-24 02:36:37,511] Trial 8 finished with value: 51.85564627877287 and parameters: {'learning_rate': 0.013057207427597006, 'num_leaves': 242, 'max_depth': 10, 'min_data_in_leaf': 108, 'feature_fraction': 0.7363743886612995, 'bagging_fraction': 0.8891430471738933, 'bagging_freq': 1}. Best is trial 8 with value: 51.85564627877287.\n",
      "[I 2025-11-24 02:36:38,287] Trial 9 finished with value: 55.083776720567755 and parameters: {'learning_rate': 0.09743654578334514, 'num_leaves': 182, 'max_depth': 4, 'min_data_in_leaf': 140, 'feature_fraction': 0.9644489606241253, 'bagging_fraction': 0.6648469703039904, 'bagging_freq': 11}. Best is trial 8 with value: 51.85564627877287.\n",
      "[I 2025-11-24 02:36:41,418] Trial 10 finished with value: 46.570518110699815 and parameters: {'learning_rate': 0.03866567677927556, 'num_leaves': 248, 'max_depth': 10, 'min_data_in_leaf': 26, 'feature_fraction': 0.8731441472741235, 'bagging_fraction': 0.9346681200663051, 'bagging_freq': 1}. Best is trial 10 with value: 46.570518110699815.\n",
      "[I 2025-11-24 02:36:46,387] Trial 11 finished with value: 41.31387256390664 and parameters: {'learning_rate': 0.04104330069206297, 'num_leaves': 253, 'max_depth': 10, 'min_data_in_leaf': 24, 'feature_fraction': 0.8685011728765828, 'bagging_fraction': 0.9861211916036627, 'bagging_freq': 1}. Best is trial 11 with value: 41.31387256390664.\n",
      "[I 2025-11-24 02:36:49,162] Trial 12 finished with value: 42.041716211050975 and parameters: {'learning_rate': 0.04516895018189831, 'num_leaves': 250, 'max_depth': 8, 'min_data_in_leaf': 23, 'feature_fraction': 0.8721199633776775, 'bagging_fraction': 0.9725146472856079, 'bagging_freq': 3}. Best is trial 11 with value: 41.31387256390664.\n",
      "[I 2025-11-24 02:36:51,641] Trial 13 finished with value: 42.107510467880374 and parameters: {'learning_rate': 0.06732467269901733, 'num_leaves': 151, 'max_depth': 8, 'min_data_in_leaf': 20, 'feature_fraction': 0.9032590468854201, 'bagging_fraction': 0.9962355108590564, 'bagging_freq': 4}. Best is trial 11 with value: 41.31387256390664.\n",
      "[I 2025-11-24 02:36:57,460] Trial 14 finished with value: 44.590405646448076 and parameters: {'learning_rate': 0.025417546590970952, 'num_leaves': 253, 'max_depth': 6, 'min_data_in_leaf': 56, 'feature_fraction': 0.8360603613701695, 'bagging_fraction': 0.9881965727625822, 'bagging_freq': 3}. Best is trial 11 with value: 41.31387256390664.\n",
      "[I 2025-11-24 02:36:59,936] Trial 15 finished with value: 49.69087580407125 and parameters: {'learning_rate': 0.08405018716410038, 'num_leaves': 159, 'max_depth': 8, 'min_data_in_leaf': 54, 'feature_fraction': 0.9321271651853785, 'bagging_fraction': 0.9373304863101004, 'bagging_freq': 6}. Best is trial 11 with value: 41.31387256390664.\n",
      "[I 2025-11-24 02:37:07,208] Trial 16 finished with value: 45.46244663133878 and parameters: {'learning_rate': 0.030173645940999243, 'num_leaves': 173, 'max_depth': 9, 'min_data_in_leaf': 40, 'feature_fraction': 0.8126367301869766, 'bagging_fraction': 0.9396918561579976, 'bagging_freq': 3}. Best is trial 11 with value: 41.31387256390664.\n",
      "[I 2025-11-24 02:37:08,805] Trial 17 finished with value: 51.255121870131376 and parameters: {'learning_rate': 0.05540656891481538, 'num_leaves': 133, 'max_depth': 7, 'min_data_in_leaf': 74, 'feature_fraction': 0.8932757106248989, 'bagging_fraction': 0.8783534931492161, 'bagging_freq': 2}. Best is trial 11 with value: 41.31387256390664.\n",
      "[I 2025-11-24 02:37:10,588] Trial 18 finished with value: 51.18245172081864 and parameters: {'learning_rate': 0.11902041347209515, 'num_leaves': 230, 'max_depth': 9, 'min_data_in_leaf': 67, 'feature_fraction': 0.9302927450031265, 'bagging_fraction': 0.9664019259584639, 'bagging_freq': 5}. Best is trial 11 with value: 41.31387256390664.\n",
      "[I 2025-11-24 02:37:12,825] Trial 19 finished with value: 62.908841780948784 and parameters: {'learning_rate': 0.06463480777094302, 'num_leaves': 60, 'max_depth': 6, 'min_data_in_leaf': 35, 'feature_fraction': 0.6012500563370582, 'bagging_fraction': 0.9157240533480357, 'bagging_freq': 8}. Best is trial 11 with value: 41.31387256390664.\n",
      "[I 2025-11-24 02:37:14,760] Trial 20 finished with value: 57.38738040671413 and parameters: {'learning_rate': 0.034326680614322445, 'num_leaves': 34, 'max_depth': 9, 'min_data_in_leaf': 199, 'feature_fraction': 0.8071779010198779, 'bagging_fraction': 0.9970373990654688, 'bagging_freq': 2}. Best is trial 11 with value: 41.31387256390664.\n",
      "[I 2025-11-24 02:37:17,070] Trial 21 finished with value: 48.356245415132854 and parameters: {'learning_rate': 0.07051158096837794, 'num_leaves': 144, 'max_depth': 8, 'min_data_in_leaf': 22, 'feature_fraction': 0.8998000642497963, 'bagging_fraction': 0.9974011469886152, 'bagging_freq': 4}. Best is trial 11 with value: 41.31387256390664.\n",
      "[I 2025-11-24 02:37:18,676] Trial 22 finished with value: 39.433128411659666 and parameters: {'learning_rate': 0.12058546057293824, 'num_leaves': 233, 'max_depth': 8, 'min_data_in_leaf': 20, 'feature_fraction': 0.922186354572538, 'bagging_fraction': 0.9607857583414905, 'bagging_freq': 5}. Best is trial 22 with value: 39.433128411659666.\n",
      "[I 2025-11-24 02:37:19,664] Trial 23 finished with value: 50.170055386270406 and parameters: {'learning_rate': 0.11804689001814095, 'num_leaves': 234, 'max_depth': 7, 'min_data_in_leaf': 38, 'feature_fraction': 0.9471302210860161, 'bagging_fraction': 0.8452040633113092, 'bagging_freq': 5}. Best is trial 22 with value: 39.433128411659666.\n",
      "[I 2025-11-24 02:37:20,920] Trial 24 finished with value: 47.77484928040978 and parameters: {'learning_rate': 0.14274254078004453, 'num_leaves': 255, 'max_depth': 9, 'min_data_in_leaf': 63, 'feature_fraction': 0.8563782843023743, 'bagging_fraction': 0.9521567188031277, 'bagging_freq': 2}. Best is trial 22 with value: 39.433128411659666.\n",
      "[I 2025-11-24 02:37:24,209] Trial 25 finished with value: 27.886653238775427 and parameters: {'learning_rate': 0.049939066752630185, 'num_leaves': 226, 'max_depth': 10, 'min_data_in_leaf': 35, 'feature_fraction': 0.9844541671318907, 'bagging_fraction': 0.6078406875997995, 'bagging_freq': 5}. Best is trial 25 with value: 27.886653238775427.\n",
      "[I 2025-11-24 02:37:28,748] Trial 26 finished with value: 41.76263380562387 and parameters: {'learning_rate': 0.019107070448849264, 'num_leaves': 207, 'max_depth': 10, 'min_data_in_leaf': 41, 'feature_fraction': 0.9857947647097516, 'bagging_fraction': 0.6031161845052188, 'bagging_freq': 7}. Best is trial 25 with value: 27.886653238775427.\n",
      "[I 2025-11-24 02:37:30,883] Trial 27 finished with value: 53.30026548982493 and parameters: {'learning_rate': 0.02851735717639408, 'num_leaves': 227, 'max_depth': 10, 'min_data_in_leaf': 77, 'feature_fraction': 0.966548597872688, 'bagging_fraction': 0.6029328196333478, 'bagging_freq': 8}. Best is trial 25 with value: 27.886653238775427.\n",
      "[I 2025-11-24 02:37:32,138] Trial 28 finished with value: 51.0107732237395 and parameters: {'learning_rate': 0.08732038727495234, 'num_leaves': 175, 'max_depth': 9, 'min_data_in_leaf': 51, 'feature_fraction': 0.912827013362053, 'bagging_fraction': 0.7366833283857146, 'bagging_freq': 5}. Best is trial 25 with value: 27.886653238775427.\n",
      "[I 2025-11-24 02:37:35,385] Trial 29 finished with value: 43.691600750247915 and parameters: {'learning_rate': 0.024902683580975808, 'num_leaves': 200, 'max_depth': 10, 'min_data_in_leaf': 35, 'feature_fraction': 0.9715823071090404, 'bagging_fraction': 0.8312887848695087, 'bagging_freq': 5}. Best is trial 25 with value: 27.886653238775427.\n",
      "[I 2025-11-24 02:37:36,662] Trial 30 finished with value: 54.711756302595624 and parameters: {'learning_rate': 0.05184981717015665, 'num_leaves': 234, 'max_depth': 5, 'min_data_in_leaf': 99, 'feature_fraction': 0.9302222315389646, 'bagging_fraction': 0.9090098647456399, 'bagging_freq': 8}. Best is trial 25 with value: 27.886653238775427.\n",
      "[I 2025-11-24 02:37:41,056] Trial 31 finished with value: 40.92166085098562 and parameters: {'learning_rate': 0.01788810790088758, 'num_leaves': 212, 'max_depth': 10, 'min_data_in_leaf': 42, 'feature_fraction': 0.9870193061968227, 'bagging_fraction': 0.6212135700493223, 'bagging_freq': 7}. Best is trial 25 with value: 27.886653238775427.\n",
      "[I 2025-11-24 02:37:46,457] Trial 32 finished with value: 43.906820770207204 and parameters: {'learning_rate': 0.015191379618350185, 'num_leaves': 214, 'max_depth': 10, 'min_data_in_leaf': 30, 'feature_fraction': 0.9523130420618838, 'bagging_fraction': 0.6393019690894939, 'bagging_freq': 6}. Best is trial 25 with value: 27.886653238775427.\n",
      "[I 2025-11-24 02:37:51,740] Trial 33 finished with value: 45.266027209079496 and parameters: {'learning_rate': 0.02093744562051025, 'num_leaves': 189, 'max_depth': 9, 'min_data_in_leaf': 47, 'feature_fraction': 0.9857758642164628, 'bagging_fraction': 0.6830781180038503, 'bagging_freq': 9}. Best is trial 25 with value: 27.886653238775427.\n",
      "[I 2025-11-24 02:37:55,303] Trial 34 finished with value: 42.78911746630424 and parameters: {'learning_rate': 0.040176685507777594, 'num_leaves': 238, 'max_depth': 10, 'min_data_in_leaf': 58, 'feature_fraction': 0.9419516697448563, 'bagging_fraction': 0.6238803350876083, 'bagging_freq': 7}. Best is trial 25 with value: 27.886653238775427.\n",
      "[I 2025-11-24 02:37:56,031] Trial 35 finished with value: 53.432092949813516 and parameters: {'learning_rate': 0.17363729210243137, 'num_leaves': 222, 'max_depth': 9, 'min_data_in_leaf': 87, 'feature_fraction': 0.8385189663835728, 'bagging_fraction': 0.7177865777841838, 'bagging_freq': 4}. Best is trial 25 with value: 27.886653238775427.\n",
      "[I 2025-11-24 02:37:59,502] Trial 36 finished with value: 47.414069147368174 and parameters: {'learning_rate': 0.015495909225301403, 'num_leaves': 206, 'max_depth': 8, 'min_data_in_leaf': 31, 'feature_fraction': 0.9998470595276775, 'bagging_fraction': 0.659418325083594, 'bagging_freq': 10}. Best is trial 25 with value: 27.886653238775427.\n",
      "[I 2025-11-24 02:38:00,588] Trial 37 finished with value: 48.9248788945153 and parameters: {'learning_rate': 0.05816972703448773, 'num_leaves': 89, 'max_depth': 10, 'min_data_in_leaf': 45, 'feature_fraction': 0.8792314227013327, 'bagging_fraction': 0.6396840769533728, 'bagging_freq': 6}. Best is trial 25 with value: 27.886653238775427.\n",
      "[I 2025-11-24 02:38:05,137] Trial 38 finished with value: 50.11458606228301 and parameters: {'learning_rate': 0.012323314238750641, 'num_leaves': 215, 'max_depth': 9, 'min_data_in_leaf': 69, 'feature_fraction': 0.9144734012808156, 'bagging_fraction': 0.7903037345936285, 'bagging_freq': 9}. Best is trial 25 with value: 27.886653238775427.\n",
      "[I 2025-11-24 02:38:05,892] Trial 39 finished with value: 54.952065922907764 and parameters: {'learning_rate': 0.149074784328384, 'num_leaves': 240, 'max_depth': 10, 'min_data_in_leaf': 121, 'feature_fraction': 0.6988464585544988, 'bagging_fraction': 0.6858299407143598, 'bagging_freq': 12}. Best is trial 25 with value: 27.886653238775427.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 3: model saved to D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\lgbm_full_clusters_tweedie_noleak\\models\\lgbm_full_cluster_3.txt\n",
      "\n",
      "[STEP 10] Prediksi penuh (train + test) per cluster...\n",
      "Saved full panel with predictions to: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\lgbm_full_clusters_tweedie_noleak\\panel_with_predictions.csv\n",
      "\n",
      "[STEP 11] Global metrics train/test...\n",
      "Saved global metrics to: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\lgbm_full_clusters_tweedie_noleak\\metrics\\global_metrics_clusters_tweedie_full_noleak.csv\n",
      "split  n_obs          MSE        RMSE        MAE         MAPE     sMAPE\n",
      "train 158803 6.398103e+03   79.988145  11.512020 5.877468e+07 38.497883\n",
      " test     45 1.218703e+06 1103.948951 614.911569 1.426396e+01 14.458012\n",
      "\n",
      "[STEP 12] Metrics per cabangSKU...\n",
      "Saved metrics per series to: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\lgbm_full_clusters_tweedie_noleak\\metrics\\metrics_by_series_clusters_tweedie_full_noleak.csv\n",
      "cabang         sku  cluster  n_train  n_test  train_mae  train_mse  train_rmse   train_mape  train_smape  test_mae  test_mse  test_rmse  test_mape  test_smape  gap_RMSE  ratio_RMSE\n",
      "   02A APQR005K102        3       41       0   0.191462   0.242387    0.492328 4.759074e+06    96.606840       NaN       NaN        NaN        NaN         NaN       NaN         NaN\n",
      "   02A APQR005K104        0       41       0   0.183797   0.120679    0.347389 5.527174e+06    90.489073       NaN       NaN        NaN        NaN         NaN       NaN         NaN\n",
      "   02A APQR005K405        0       40       0   0.163583   0.119579    0.345802 5.399235e+06    86.977262       NaN       NaN        NaN        NaN         NaN       NaN         NaN\n",
      "   02A APQR005K503        1       41       0   1.227197   2.640285    1.624895 4.316028e+05    15.804893       NaN       NaN        NaN        NaN         NaN       NaN         NaN\n",
      "   02A APQR005K504        1       41       0   0.443798   0.399495    0.632056 5.029362e+05    25.438392       NaN       NaN        NaN        NaN         NaN       NaN         NaN\n",
      "   02A APQR005K602        0       41       0   0.477914   0.759251    0.871350 2.994221e+06    58.879076       NaN       NaN        NaN        NaN         NaN       NaN         NaN\n",
      "   02A APQR005K603        0       41       0   0.247649   0.169057    0.411166 3.892421e+06    66.682560       NaN       NaN        NaN        NaN         NaN       NaN         NaN\n",
      "   02A APQR005K801        0       41       0   0.264756   0.242988    0.492939 3.620548e+06    81.293616       NaN       NaN        NaN        NaN         NaN       NaN         NaN\n",
      "   02A  APQR005KBA        1       41       0   6.747131  77.961100    8.829558 6.338979e+00     6.326181       NaN       NaN        NaN        NaN         NaN       NaN         NaN\n",
      "   02A  APQR005KBB        1       41       0   6.841481  85.024752    9.220887 6.035073e+00     5.960426       NaN       NaN        NaN        NaN         NaN       NaN         NaN\n",
      "\n",
      "[STEP 13] Plot actual vs pred TEST per seri ke: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\lgbm_full_clusters_tweedie_noleak\\plots_per_series\n",
      "\n",
      "[STEP 14] Diagnostics ke: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\lgbm_full_clusters_tweedie_noleak\\diagnostics\n",
      "Saved top outliers train to: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\lgbm_full_clusters_tweedie_noleak\\diagnostics\\top_outliers_train_full.csv\n",
      "\n",
      "Seri dengan ratio_RMSE > 1.3 (indikasi sulit di test / overfit lokal):\n",
      "cabang         sku  cluster  train_rmse  test_rmse  ratio_RMSE\n",
      "   16C DOPQ001K009        2  302.796720 469.440710    1.550349\n",
      "   02A  BUVW001KSW        2  684.739043 952.137886    1.390512\n",
      "\n",
      "Seri dengan ratio_RMSE < 0.8 (train lebih jelek dari test):\n",
      "cabang         sku  cluster  train_rmse  test_rmse  ratio_RMSE\n",
      "   23A  BUVW001KSW        2  946.900828 450.831565    0.476113\n",
      "   17A DOPQ001K002        2  201.833194 117.228416    0.580818\n",
      "   05A  BUVW001KSW        2  857.005291 623.531539    0.727570\n",
      "   13A DOPQ001K002        2  844.675545 674.706589    0.798776\n",
      "\n",
      "SELESAI: A+B+C+D+E (NO LEAK, DATASET FULL) + diagnostics lengkap.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==============================\n",
    "# METRIC FUNCTIONS\n",
    "# ==============================\n",
    "def mae(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mse(y_true, y_pred))\n",
    "\n",
    "\n",
    "def mape(y_true, y_pred, eps=1e-8):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    denom = np.maximum(np.abs(y_true), eps)\n",
    "    return np.mean(np.abs(y_true - y_pred) / denom) * 100.0\n",
    "\n",
    "\n",
    "def smape(y_true, y_pred, eps=1e-8):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    denom = np.maximum(np.abs(y_true) + np.abs(y_pred), eps)\n",
    "    return np.mean(2.0 * np.abs(y_true - y_pred) / denom) * 100.0\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# PATH CONFIG\n",
    "# ==============================\n",
    "PROJECT_ROOT    = Path(r\"D:\\Documents\\Skripsi\\demand-forecasting\")\n",
    "DATASETFULL_DIR = PROJECT_ROOT / \"data\" / \"dataset_full\"\n",
    "\n",
    "# PAKAI DATASET FULL\n",
    "DATA_PATH = DATASETFULL_DIR / \"lgbm_dataset_full_fullfeat.csv\"\n",
    "\n",
    "OUT_ROOT  = PROJECT_ROOT / \"outputs\" / \"lgbm_full_clusters_tweedie_noleak\"\n",
    "MODEL_DIR = OUT_ROOT / \"models\"\n",
    "METRIC_DIR = OUT_ROOT / \"metrics\"\n",
    "PLOT_DIR  = OUT_ROOT / \"plots_per_series\"\n",
    "DIAG_DIR  = OUT_ROOT / \"diagnostics\"\n",
    "\n",
    "for d in [OUT_ROOT, MODEL_DIR, METRIC_DIR, PLOT_DIR, DIAG_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"====================================\")\n",
    "    print(\"RUN FULL TRAINING (NO LEAK): A+B+C+D+E - DATASET FULL\")\n",
    "    print(\"====================================\")\n",
    "    print(\"Load data:\", DATA_PATH)\n",
    "\n",
    "    df = pd.read_csv(DATA_PATH, parse_dates=[\"periode\"])\n",
    "    print(\"Rows:\", len(df))\n",
    "\n",
    "    df[\"qty\"] = df[\"qty\"].astype(float)\n",
    "    df = df.sort_values([\"cabang\", \"sku\", \"periode\"]).reset_index(drop=True)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 2: build SKU profile dari TRAIN\n",
    "    # ----------------------------------\n",
    "    print(\"\\n[STEP 2] Build SKU profile dari TRAIN...\")\n",
    "    df_train = df[df[\"is_train\"] == 1].copy()\n",
    "    profile = build_sku_profile(df_train)\n",
    "\n",
    "    PROFILE_PATH = DATASETFULL_DIR / \"cluster_profiles_raw_train_only.csv\"\n",
    "    profile.to_csv(PROFILE_PATH, index=False)\n",
    "    print(\"Saved raw train profile to:\", PROFILE_PATH)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 3: clustering (A) dari TRAIN\n",
    "    # ----------------------------------\n",
    "    print(\"\\n[STEP 3] Clustering SKU (TRAIN only)...\")\n",
    "    profile_clustered = run_sku_clustering(profile, n_clusters=4)\n",
    "\n",
    "    PROFILE_CLUSTER_PATH = DATASETFULL_DIR / \"cluster_profiles_full_train_only.csv\"\n",
    "    profile_clustered.to_csv(PROFILE_CLUSTER_PATH, index=False)\n",
    "    print(\"Saved clustered profile to:\", PROFILE_CLUSTER_PATH)\n",
    "    print(\"Cluster summary (train stats):\")\n",
    "    print(\n",
    "        profile_clustered.groupby(\"cluster\")[[\"qty_mean\", \"cv\", \"zero_ratio\", \"total_qty\"]]\n",
    "        .mean()\n",
    "        .round(2)\n",
    "        .to_string()\n",
    "    )\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 4: merge cluster + demand_level ke panel penuh\n",
    "    # ----------------------------------\n",
    "    print(\"\\n[STEP 4] Merge cluster dan demand_level ke panel (train+test)...\")\n",
    "    df = df.merge(\n",
    "        profile_clustered[[\"cabang\", \"sku\", \"cluster\", \"demand_level\"]],\n",
    "        on=[\"cabang\", \"sku\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    df[\"cluster\"] = df[\"cluster\"].fillna(-1).astype(int)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 5: add hierarchy features (E)\n",
    "    # ----------------------------------\n",
    "    print(\"\\n[STEP 5] Tambah hierarchy features (family)...\")\n",
    "    df = add_hierarchy_features(df)\n",
    "\n",
    "    # Encode family -> family_idx (numeric)\n",
    "    if \"family\" in df.columns:\n",
    "        family_map = {\n",
    "            fam: idx for idx, fam in enumerate(sorted(df[\"family\"].astype(str).unique()))\n",
    "        }\n",
    "        df[\"family_idx\"] = df[\"family\"].astype(str).map(family_map).astype(\"int16\")\n",
    "        print(\"Family mapping:\", family_map)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 6: add stabilizer features (B) - pakai stats TRAIN\n",
    "    # ----------------------------------\n",
    "    print(\"\\n[STEP 6] Tambah stabilizer features (no leak)...\")\n",
    "    df = add_stabilizer_features(df)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 7: outlier treatment (C) - quantile dari TRAIN\n",
    "    # ----------------------------------\n",
    "    print(\"\\n[STEP 7] Winsorize outliers per SKU (no leak)...\")\n",
    "    df = winsorize_outliers(df)\n",
    "\n",
    "    # backup log1p original qty juga, kalau mau analisis\n",
    "    df[\"log_qty\"] = np.log1p(df[\"qty\"])\n",
    "    df[\"log_qty_wins\"] = np.log1p(df[\"qty_wins\"])\n",
    "\n",
    "    df = df.sort_values([\"cabang\", \"sku\", \"periode\"]).reset_index(drop=True)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 8: feature columns\n",
    "    # ----------------------------------\n",
    "    drop_cols = [\n",
    "        \"area\",\n",
    "        \"cabang\",\n",
    "        \"sku\",\n",
    "        \"periode\",\n",
    "        \"qty\",\n",
    "        \"qty_wins\",\n",
    "        \"log_qty\",\n",
    "        \"log_qty_wins\",\n",
    "        \"is_train\",\n",
    "        \"is_test\",\n",
    "        \"sample_weight\",\n",
    "        \"family\",\n",
    "    ]\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "    print(\"\\n[STEP 8] Num features:\", len(feature_cols))\n",
    "    print(\"Contoh fitur:\", feature_cols[:20])\n",
    "\n",
    "    obj_cols = df[feature_cols].select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "    if obj_cols:\n",
    "        print(\"WARNING: Masih ada kolom object di feature_cols:\", obj_cols)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 9: train per cluster\n",
    "    # ----------------------------------\n",
    "    print(\"\\n[STEP 9] Training LGBM per cluster (Tweedie, no leak)...\")\n",
    "    cluster_ids = sorted(df[\"cluster\"].dropna().unique())\n",
    "    models: Dict[int, lgb.Booster] = {}\n",
    "\n",
    "    for cid in cluster_ids:\n",
    "        if cid == -1:\n",
    "            print(f\"Cluster {cid} = -1 (unknown), skip training.\")\n",
    "            continue\n",
    "\n",
    "        print(\"\\n====================================\")\n",
    "        print(f\"TRAINING CLUSTER {cid}\")\n",
    "        print(\"====================================\")\n",
    "\n",
    "        model = train_lgbm_per_cluster(\n",
    "            df=df,\n",
    "            cluster_id=int(cid),\n",
    "            feature_cols=feature_cols,\n",
    "            log_target=True,   # kalau fungsi kamu tidak pakai arg ini, hapus saja\n",
    "            n_trials=40,\n",
    "        )\n",
    "\n",
    "        if model is None:\n",
    "            print(f\"Cluster {cid}: model is None, skip saving.\")\n",
    "            continue\n",
    "\n",
    "        models[cid] = model\n",
    "\n",
    "        model_path = MODEL_DIR / f\"lgbm_full_cluster_{cid}.txt\"\n",
    "        model.save_model(str(model_path))\n",
    "        print(f\"Cluster {cid}: model saved to {model_path}\")\n",
    "\n",
    "    if not models:\n",
    "        raise RuntimeError(\"Tidak ada model yang berhasil dilatih. Cek cluster atau flag is_train.\")\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 10: prediksi penuh\n",
    "    # ----------------------------------\n",
    "    print(\"\\n[STEP 10] Prediksi penuh (train + test) per cluster...\")\n",
    "    df_pred_list = []\n",
    "\n",
    "    for cid, model in models.items():\n",
    "        df_c = df[df[\"cluster\"] == cid].copy()\n",
    "        if df_c.empty:\n",
    "            continue\n",
    "\n",
    "        X_c = df_c[feature_cols]\n",
    "        pred_log = model.predict(X_c)\n",
    "        pred_qty = np.expm1(pred_log)\n",
    "\n",
    "        df_c[\"pred_qty\"] = pred_qty\n",
    "        df_pred_list.append(df_c)\n",
    "\n",
    "    df_pred = pd.concat(df_pred_list, axis=0).sort_index()\n",
    "    PRED_PATH = OUT_ROOT / \"panel_with_predictions.csv\"\n",
    "    df_pred.to_csv(PRED_PATH, index=False)\n",
    "    print(\"Saved full panel with predictions to:\", PRED_PATH)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 11: GLOBAL METRICS\n",
    "    # ----------------------------------\n",
    "    print(\"\\n[STEP 11] Global metrics train/test...\")\n",
    "    metrics_global = []\n",
    "\n",
    "    for split_name, mask in [\n",
    "        (\"train\", df_pred[\"is_train\"] == 1),\n",
    "        (\"test\", df_pred[\"is_test\"] == 1),\n",
    "    ]:\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        yt = df_pred.loc[mask, \"qty\"].values\n",
    "        yp = df_pred.loc[mask, \"pred_qty\"].values\n",
    "\n",
    "        metrics_global.append({\n",
    "            \"split\": split_name,\n",
    "            \"n_obs\": int(len(yt)),\n",
    "            \"MSE\": mse(yt, yp),\n",
    "            \"RMSE\": rmse(yt, yp),\n",
    "            \"MAE\": mae(yt, yp),\n",
    "            \"MAPE\": mape(yt, yp),\n",
    "            \"sMAPE\": smape(yt, yp),\n",
    "        })\n",
    "\n",
    "    global_df = pd.DataFrame(metrics_global)\n",
    "    GLOBAL_METRIC_PATH = METRIC_DIR / \"global_metrics_clusters_tweedie_full_noleak.csv\"\n",
    "    global_df.to_csv(GLOBAL_METRIC_PATH, index=False)\n",
    "    print(\"Saved global metrics to:\", GLOBAL_METRIC_PATH)\n",
    "    print(global_df.to_string(index=False))\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 12: METRICS PER SERIES\n",
    "    # ----------------------------------\n",
    "    print(\"\\n[STEP 12] Metrics per cabangSKU...\")\n",
    "    rows = []\n",
    "\n",
    "    for (cab, sku), g in df_pred.groupby([\"cabang\", \"sku\"], sort=False):\n",
    "        g_tr = g[g[\"is_train\"] == 1]\n",
    "        g_te = g[g[\"is_test\"] == 1]\n",
    "\n",
    "        row = {\n",
    "            \"cabang\": cab,\n",
    "            \"sku\": sku,\n",
    "            \"cluster\": g[\"cluster\"].iloc[0],\n",
    "            \"n_train\": int(len(g_tr)),\n",
    "            \"n_test\": int(len(g_te)),\n",
    "        }\n",
    "\n",
    "        if len(g_tr) > 0:\n",
    "            yt_tr = g_tr[\"qty\"].values\n",
    "            yp_tr = g_tr[\"pred_qty\"].values\n",
    "            row.update({\n",
    "                \"train_mae\": mae(yt_tr, yp_tr),\n",
    "                \"train_mse\": mse(yt_tr, yp_tr),\n",
    "                \"train_rmse\": rmse(yt_tr, yp_tr),\n",
    "                \"train_mape\": mape(yt_tr, yp_tr),\n",
    "                \"train_smape\": smape(yt_tr, yp_tr),\n",
    "            })\n",
    "        else:\n",
    "            row.update({\n",
    "                \"train_mae\": np.nan,\n",
    "                \"train_mse\": np.nan,\n",
    "                \"train_rmse\": np.nan,\n",
    "                \"train_mape\": np.nan,\n",
    "                \"train_smape\": np.nan,\n",
    "            })\n",
    "\n",
    "        if len(g_te) > 0:\n",
    "            yt_te = g_te[\"qty\"].values\n",
    "            yp_te = g_te[\"pred_qty\"].values\n",
    "            row.update({\n",
    "                \"test_mae\": mae(yt_te, yp_te),\n",
    "                \"test_mse\": mse(yt_te, yp_te),\n",
    "                \"test_rmse\": rmse(yt_te, yp_te),\n",
    "                \"test_mape\": mape(yt_te, yp_te),\n",
    "                \"test_smape\": smape(yt_te, yp_te),\n",
    "            })\n",
    "        else:\n",
    "            row.update({\n",
    "                \"test_mae\": np.nan,\n",
    "                \"test_mse\": np.nan,\n",
    "                \"test_rmse\": np.nan,\n",
    "                \"test_mape\": np.nan,\n",
    "                \"test_smape\": np.nan,\n",
    "            })\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    metrics_series = pd.DataFrame(rows)\n",
    "    metrics_series[\"gap_RMSE\"] = metrics_series[\"test_rmse\"] - metrics_series[\"train_rmse\"]\n",
    "    metrics_series[\"ratio_RMSE\"] = metrics_series[\"test_rmse\"] / metrics_series[\"train_rmse\"]\n",
    "\n",
    "    SERIES_METRIC_PATH = METRIC_DIR / \"metrics_by_series_clusters_tweedie_full_noleak.csv\"\n",
    "    metrics_series.to_csv(SERIES_METRIC_PATH, index=False)\n",
    "    print(\"Saved metrics per series to:\", SERIES_METRIC_PATH)\n",
    "    print(metrics_series.head(10).to_string(index=False))\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 13: PLOT ACTUAL vs PRED (TEST)\n",
    "    # ----------------------------------\n",
    "    print(f\"\\n[STEP 13] Plot actual vs pred TEST per seri ke: {PLOT_DIR}\")\n",
    "\n",
    "    test_only = df_pred[df_pred[\"is_test\"] == 1].copy()\n",
    "\n",
    "    for (cab, sku), g in test_only.groupby([\"cabang\", \"sku\"], sort=False):\n",
    "        g = g.sort_values(\"periode\")\n",
    "\n",
    "        if g[\"qty\"].notna().sum() == 0:\n",
    "            continue\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(g[\"periode\"], g[\"qty\"], marker=\"o\", label=\"Actual qty\")\n",
    "        plt.plot(g[\"periode\"], g[\"pred_qty\"], marker=\"x\", label=\"Predicted qty\")\n",
    "        plt.xlabel(\"Periode\")\n",
    "        plt.ylabel(\"Qty\")\n",
    "        plt.title(f\"Actual vs Predicted - TEST\\nCabang {cab}, SKU {sku}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        fname = f\"{cab}_{sku}_test_actual_vs_pred.png\".replace(\"/\", \"-\")\n",
    "        plt.savefig(PLOT_DIR / fname, dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Step 14: DIAGNOSTICS (residual, overfit, dll)\n",
    "    # ----------------------------------\n",
    "    print(f\"\\n[STEP 14] Diagnostics ke: {DIAG_DIR}\")\n",
    "\n",
    "    df_resid = df_pred.copy()\n",
    "    df_resid[\"resid\"] = df_resid[\"qty\"].astype(float) - df_resid[\"pred_qty\"].astype(float)\n",
    "    df_resid[\"abs_resid\"] = df_resid[\"resid\"].abs()\n",
    "\n",
    "    # Histogram residual global\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(df_resid[\"resid\"], bins=80)\n",
    "    plt.xlabel(\"Residual (qty - pred_qty)\")\n",
    "    plt.ylabel(\"Frekuensi\")\n",
    "    plt.title(\"Histogram residual global (train + test)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(DIAG_DIR / \"hist_residual_global.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # Residual vs predicted\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.scatter(df_resid[\"pred_qty\"], df_resid[\"resid\"], alpha=0.3)\n",
    "    plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
    "    plt.xlabel(\"Predicted qty\")\n",
    "    plt.ylabel(\"Residual\")\n",
    "    plt.title(\"Residual vs predicted qty\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(DIAG_DIR / \"scatter_resid_vs_pred.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # Top outliers (train)\n",
    "    TOP_N = 50\n",
    "    top_outliers = (\n",
    "        df_resid[df_resid[\"is_train\"] == 1]\n",
    "        .sort_values(\"abs_resid\", ascending=False)\n",
    "        .head(TOP_N)\n",
    "        [[\"area\", \"cabang\", \"sku\", \"periode\", \"qty\", \"pred_qty\", \"resid\", \"abs_resid\"]]\n",
    "    )\n",
    "    OUTLIER_PATH = DIAG_DIR / \"top_outliers_train_full.csv\"\n",
    "    top_outliers.to_csv(OUTLIER_PATH, index=False)\n",
    "    print(\"Saved top outliers train to:\", OUTLIER_PATH)\n",
    "\n",
    "    # Hist ratio_RMSE\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(metrics_series[\"ratio_RMSE\"].dropna(), bins=30)\n",
    "    plt.xlabel(\"ratio_RMSE = test_rmse / train_rmse\")\n",
    "    plt.ylabel(\"Jumlah seri\")\n",
    "    plt.title(\"Distribusi ratio_RMSE antar seri\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(DIAG_DIR / \"hist_ratio_RMSE.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # Scatter train vs test RMSE\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(metrics_series[\"train_rmse\"], metrics_series[\"test_rmse\"], alpha=0.7)\n",
    "    max_val = np.nanmax([\n",
    "        metrics_series[\"train_rmse\"].max(),\n",
    "        metrics_series[\"test_rmse\"].max()\n",
    "    ])\n",
    "    plt.plot([0, max_val], [0, max_val], \"r--\")\n",
    "    plt.xlabel(\"Train RMSE\")\n",
    "    plt.ylabel(\"Test RMSE\")\n",
    "    plt.title(\"Train vs Test RMSE per cabangSKU\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(DIAG_DIR / \"scatter_train_vs_test_RMSE.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # Seri overfit / underfit\n",
    "    overfit_series = metrics_series[metrics_series[\"ratio_RMSE\"] > 1.3].copy()\n",
    "    under_series   = metrics_series[metrics_series[\"ratio_RMSE\"] < 0.8].copy()\n",
    "\n",
    "    print(\"\\nSeri dengan ratio_RMSE > 1.3 (indikasi sulit di test / overfit lokal):\")\n",
    "    if len(overfit_series) > 0:\n",
    "        print(\n",
    "            overfit_series[[\"cabang\", \"sku\", \"cluster\", \"train_rmse\", \"test_rmse\", \"ratio_RMSE\"]]\n",
    "            .sort_values(\"ratio_RMSE\", ascending=False)\n",
    "            .head(20)\n",
    "            .to_string(index=False)\n",
    "        )\n",
    "    else:\n",
    "        print(\"Tidak ada.\")\n",
    "\n",
    "    print(\"\\nSeri dengan ratio_RMSE < 0.8 (train lebih jelek dari test):\")\n",
    "    if len(under_series) > 0:\n",
    "        print(\n",
    "            under_series[[\"cabang\", \"sku\", \"cluster\", \"train_rmse\", \"test_rmse\", \"ratio_RMSE\"]]\n",
    "            .sort_values(\"ratio_RMSE\")\n",
    "            .head(20)\n",
    "            .to_string(index=False)\n",
    "        )\n",
    "    else:\n",
    "        print(\"Tidak ada.\")\n",
    "\n",
    "    print(\"\\nSELESAI: A+B+C+D+E (NO LEAK, DATASET FULL) + diagnostics lengkap.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
