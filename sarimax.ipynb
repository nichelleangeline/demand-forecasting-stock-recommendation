{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0c1f02c",
   "metadata": {},
   "source": [
    "15 sku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bd43742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Total baris TEST: 45\n",
      "\n",
      "=== RINGKASAN HASIL (DATASET 15) - BEBERAPA BARIS ===\n",
      "cabang          sku       variant                exog_used     order seasonal_order  RMSE_train   RMSE_test       LB_p12\n",
      "   02A  BNOP400CHAR         event               event_flag (2, 1, 1)  (0, 0, 0, 12)  665.621129         NaN 9.622454e-01\n",
      "   02A  BNOP400CPOX         event               event_flag (2, 1, 1)  (0, 0, 0, 12)  665.621129         NaN 9.622454e-01\n",
      "   02A  BUVW001K194     event_hol event_flag,holiday_count (2, 0, 1)  (0, 0, 0, 12)  383.261847         NaN 3.380048e-01\n",
      "   02A   BUVW001KSB     event_hol event_flag,holiday_count (2, 0, 1)  (0, 0, 0, 12)  547.539115         NaN 8.157573e-01\n",
      "   02A  BUVW001KSBM          none                   (none) (2, 0, 1)  (0, 0, 0, 12)  348.688982         NaN 8.415164e-01\n",
      "   02A   BUVW001KSW event_hol+log event_flag,holiday_count (1, 1, 0)  (1, 1, 1, 12) 4286.438241 1551.313761 2.157863e-01\n",
      "   02A  BUVW100C192          none                   (none) (2, 0, 1)  (0, 0, 0, 12)  414.259315         NaN 2.549868e-01\n",
      "   02A   BUVW100CSB          none                   (none) (2, 0, 1)  (0, 0, 0, 12)  784.690117         NaN 4.433888e-01\n",
      "   02A   BUVW100CSW          none                   (none) (2, 0, 1)  (0, 0, 0, 12)  820.471264         NaN 6.881307e-01\n",
      "   02A CKLM001KS607     event_hol event_flag,holiday_count (2, 0, 2)  (0, 0, 0, 12)  407.316529         NaN 7.581454e-01\n",
      "   02A CKLM001KSPOL          none                   (none) (2, 0, 2)  (0, 0, 0, 12)  225.497921         NaN 7.296821e-01\n",
      "   02A  DOPQ001K001         event               event_flag (1, 0, 1)  (0, 0, 0, 12)  509.435413         NaN 3.262960e-01\n",
      "   02A  DOPQ001K009          none                   (none) (2, 0, 1)  (0, 0, 0, 12)  995.390652         NaN 1.026268e-01\n",
      "   02A   FSTU001KSB     event_hol event_flag,holiday_count (2, 1, 1)  (0, 0, 0, 12)  334.532003         NaN 5.964841e-01\n",
      "   02A   FSTU001KSW     event_hol event_flag,holiday_count (2, 1, 1)  (0, 0, 0, 12)  455.853130         NaN 4.393651e-01\n",
      "   05A   BBCD005KSW         event               event_flag (1, 1, 2)  (1, 0, 1, 12)  589.279252         NaN 9.367274e-02\n",
      "   05A  BUVW001K194         event               event_flag (1, 0, 1)  (0, 0, 0, 12)  275.371236         NaN 9.265624e-01\n",
      "   05A   BUVW001KSB          none                   (none) (1, 0, 1)  (0, 0, 0, 12)  467.801576         NaN 7.803547e-01\n",
      "   05A   BUVW001KSW          none                   (none) (2, 0, 1)  (0, 1, 1, 12) 4472.670341  462.413930 2.908748e-21\n",
      "   05A  BUVW100C192          none                   (none) (2, 0, 2)  (0, 1, 0, 12)  338.531210         NaN 1.397992e-01\n",
      "\n",
      "Saved metrics  -> D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_selected15\\sarimax_selected15_metrics.csv\n",
      "Saved preds    -> D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_selected15\\sarimax_selected15_predictions.csv\n",
      "Saved charts   -> D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_selected15\\charts\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# SARIMAX BASELINE (DATASET 15) - EVENT / HOLIDAY / RAINFALL\n",
    "# Grid search:\n",
    "#   - order, seasonal_order\n",
    "#   - kombinasi exog:\n",
    "#       (1) none\n",
    "#       (2) event_flag\n",
    "#       (3) event_flag + holiday_count\n",
    "#       (4) event_flag + holiday_count + rainfall_lag1\n",
    "#   - versi log1p vs level\n",
    "# d_suggest diambil dari model_profiles_selected15.csv\n",
    "# =========================================================\n",
    "import itertools\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------------- PATH ----------------\n",
    "PROJECT_ROOT = Path(r\"D:\\Documents\\Skripsi\\demand-forecasting\")\n",
    "\n",
    "DATA_PATH    = PROJECT_ROOT / \"data\" / \"dataset_15\" / \"sarimax_selected15_series.csv\"\n",
    "PROFILE_PATH = PROJECT_ROOT / \"data\" / \"dataset_15\" / \"model_profiles_selected15.csv\"\n",
    "\n",
    "OUT_DIR   = PROJECT_ROOT / \"outputs\" / \"sarimax_selected15\"\n",
    "CHART_DIR = OUT_DIR / \"charts\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CHART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------- LOAD ----------------\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=[\"periode\"]).sort_values(\n",
    "    [\"cabang\", \"sku\", \"periode\"]\n",
    ")\n",
    "\n",
    "profiles = pd.read_csv(PROFILE_PATH)\n",
    "\n",
    "# map d_suggest per (cabang, sku) dari model_profiles\n",
    "if \"sarimax_d_sug\" in profiles.columns:\n",
    "    d_suggest_map = dict(\n",
    "        zip(\n",
    "            zip(profiles[\"cabang\"], profiles[\"sku\"]),\n",
    "            profiles[\"sarimax_d_sug\"].astype(int),\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(\"[WARN] Kolom sarimax_d_sug tidak ada di model_profiles. Pakai d=1 semua.\")\n",
    "    d_suggest_map = {}\n",
    "\n",
    "# ---------------- QUICK SANITY ----------------\n",
    "expected_cols = [\n",
    "    \"cabang\",\n",
    "    \"sku\",\n",
    "    \"periode\",\n",
    "    \"qty\",\n",
    "    \"event_flag\",\n",
    "    \"is_train\",\n",
    "    \"is_test\",\n",
    "]\n",
    "missing = [c for c in expected_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Kolom wajib hilang: {missing}\")\n",
    "\n",
    "dups = df.duplicated(subset=[\"cabang\", \"sku\", \"periode\"]).sum()\n",
    "if dups:\n",
    "    raise ValueError(f\"Duplikat (cabang, sku, periode): {dups} baris\")\n",
    "\n",
    "test_total = int((df[\"is_test\"] == 1).sum())\n",
    "print(f\"[INFO] Total baris TEST: {test_total}\")\n",
    "\n",
    "for c in [\"qty\", \"event_flag\", \"holiday_count\", \"rainfall_lag1\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# ---------------- HELPERS ----------------\n",
    "def mape(a, f):\n",
    "    a, f = np.asarray(a, float), np.asarray(f, float)\n",
    "    mask = a != 0\n",
    "    return float(np.mean(np.abs((a[mask] - f[mask]) / a[mask])) * 100) if mask.any() else np.nan\n",
    "\n",
    "def smape(a, f):\n",
    "    a, f = np.asarray(a, float), np.asarray(f, float)\n",
    "    denom = (np.abs(a) + np.abs(f)) / 2.0\n",
    "    mask = denom != 0\n",
    "    return float(np.mean(np.abs(a[mask] - f[mask]) / denom[mask]) * 100) if mask.any() else np.nan\n",
    "\n",
    "def param_grid_small(d_fix=None):\n",
    "    \"\"\"\n",
    "    Grid kecil untuk (p,d,q) dan (P,D,Q,12).\n",
    "    Kalau d_fix tidak None, pakai hanya d_fix.\n",
    "    \"\"\"\n",
    "    yielded = set()\n",
    "    d_values = [0, 1] if d_fix is None else [int(d_fix)]\n",
    "\n",
    "    for p, d, q in itertools.product([0, 1, 2], d_values, [0, 1, 2]):\n",
    "        for P, D, Q in itertools.product([0, 1], [0, 1], [0, 1]):\n",
    "            if (p + q + P + Q) <= 6:\n",
    "                od, sod = (p, d, q), (P, D, Q, 12)\n",
    "                if (od, sod) in yielded:\n",
    "                    continue\n",
    "                yielded.add((od, sod))\n",
    "                yield od, sod\n",
    "\n",
    "def fit_eval(y_tr, X_tr, y_te, X_te, order, sorder, use_log=False):\n",
    "    # transform target (opsional)\n",
    "    ytr = np.log1p(np.clip(y_tr, a_min=0, a_max=None)) if use_log else y_tr\n",
    "\n",
    "    model = SARIMAX(\n",
    "        ytr,\n",
    "        exog=X_tr,\n",
    "        order=order,\n",
    "        seasonal_order=sorder,\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False,\n",
    "    )\n",
    "    res = model.fit(disp=False)\n",
    "\n",
    "    # fitted (train)\n",
    "    fitted_tr = res.fittedvalues\n",
    "    # jaga panjang kalau trimming karena NaN awal\n",
    "    n_tr = min(len(y_tr), len(fitted_tr))\n",
    "    y_tr_cut = y_tr[-n_tr:]\n",
    "    fitted_tr = np.asarray(fitted_tr[-n_tr:], float)\n",
    "\n",
    "    rmse_train = float(np.sqrt(np.mean((y_tr_cut - fitted_tr) ** 2)))\n",
    "    mae_train  = float(np.mean(np.abs(y_tr_cut - fitted_tr)))\n",
    "    mape_train = mape(y_tr_cut, fitted_tr)\n",
    "    smape_train = smape(y_tr_cut, fitted_tr)\n",
    "\n",
    "    # forecast untuk test (kalau ada)\n",
    "    if y_te is not None and len(y_te) > 0:\n",
    "        fh = len(y_te)\n",
    "        pred_t = res.get_forecast(steps=fh, exog=X_te).predicted_mean\n",
    "        yhat = np.expm1(pred_t) if use_log else np.asarray(pred_t, float)\n",
    "\n",
    "        rmse_test = float(np.sqrt(np.mean((y_te - yhat) ** 2)))\n",
    "        mae_test  = float(np.mean(np.abs(y_te - yhat)))\n",
    "        mape_test = mape(y_te, yhat)\n",
    "        smape_test = smape(y_te, yhat)\n",
    "    else:\n",
    "        yhat = np.array([], float)\n",
    "        rmse_test = np.nan\n",
    "        mae_test  = np.nan\n",
    "        mape_test = np.nan\n",
    "        smape_test = np.nan\n",
    "\n",
    "    resid = res.resid\n",
    "    try:\n",
    "        lb_p = float(\n",
    "            acorr_ljungbox(resid, lags=[12], return_df=True)[\"lb_pvalue\"].iloc[-1]\n",
    "        )\n",
    "    except Exception:\n",
    "        lb_p = np.nan\n",
    "\n",
    "    return dict(\n",
    "        order=order,\n",
    "        seasonal_order=sorder,\n",
    "        AIC_train=float(res.aic),\n",
    "\n",
    "        RMSE_train=rmse_train,\n",
    "        MAE_train=mae_train,\n",
    "        MAPE_train=mape_train,\n",
    "        sMAPE_train=smape_train,\n",
    "\n",
    "        RMSE_test=rmse_test,\n",
    "        MAE_test=mae_test,\n",
    "        MAPE_test=mape_test,\n",
    "        sMAPE_test=smape_test,\n",
    "\n",
    "        LB_p12=lb_p,\n",
    "        yhat=yhat,\n",
    "    )\n",
    "\n",
    "def grid_fit_series(g, exog_cols=None, use_log=False, d_fix=None):\n",
    "    g = g.sort_values(\"periode\").copy()\n",
    "    y = g[\"qty\"].astype(float).values\n",
    "    X = g[exog_cols].astype(float).values if exog_cols else None\n",
    "\n",
    "    m_tr = g[\"is_train\"].astype(bool).values\n",
    "    m_te = g[\"is_test\"].astype(bool).values\n",
    "\n",
    "    y_tr = y[m_tr]\n",
    "    y_te = y[m_te]\n",
    "    X_tr = X[m_tr] if X is not None else None\n",
    "    X_te = X[m_te] if X is not None else None\n",
    "\n",
    "    # bersihkan NaN di train\n",
    "    if X_tr is not None:\n",
    "        ok = ~np.isnan(y_tr)\n",
    "        y_tr, X_tr = y_tr[ok], X_tr[ok]\n",
    "        ok = ~np.isnan(X_tr).any(axis=1)\n",
    "        y_tr, X_tr = y_tr[ok], X_tr[ok]\n",
    "    else:\n",
    "        y_tr = y_tr[~np.isnan(y_tr)]\n",
    "\n",
    "    if len(y_tr) < 24:\n",
    "        return None, pd.DataFrame()\n",
    "\n",
    "    # untuk test, kalau tidak ada, biarkan kosong saja\n",
    "    if X_te is not None and len(X_te) > 0:\n",
    "        # buang baris NaN di exog test (harusnya sudah rapi)\n",
    "        ok_te = ~np.isnan(X_te).any(axis=1)\n",
    "        y_te = y_te[ok_te]\n",
    "        X_te = X_te[ok_te]\n",
    "\n",
    "    tried, best = [], None\n",
    "    for od, sod in param_grid_small(d_fix=d_fix):\n",
    "        try:\n",
    "            rec = fit_eval(y_tr, X_tr, y_te, X_te, od, sod, use_log=use_log)\n",
    "            tried.append(\n",
    "                {\n",
    "                    k: rec[k]\n",
    "                    for k in [\n",
    "                        \"order\",\n",
    "                        \"seasonal_order\",\n",
    "                        \"AIC_train\",\n",
    "                        \"RMSE_train\",\n",
    "                        \"MAE_train\",\n",
    "                        \"MAPE_train\",\n",
    "                        \"sMAPE_train\",\n",
    "                        \"RMSE_test\",\n",
    "                        \"MAE_test\",\n",
    "                        \"MAPE_test\",\n",
    "                        \"sMAPE_test\",\n",
    "                        \"LB_p12\",\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "            # ranking:\n",
    "            # 1) kalau ada test → pakai RMSE_test + AIC_train\n",
    "            # 2) kalau tidak ada test → pakai RMSE_train + AIC_train\n",
    "            if best is None:\n",
    "                best = rec\n",
    "            else:\n",
    "                if not np.isnan(rec[\"RMSE_test\"]) and not np.isnan(best[\"RMSE_test\"]):\n",
    "                    better = (rec[\"RMSE_test\"] < best[\"RMSE_test\"]) or (\n",
    "                        rec[\"RMSE_test\"] == best[\"RMSE_test\"]\n",
    "                        and rec[\"AIC_train\"] < best[\"AIC_train\"]\n",
    "                    )\n",
    "                elif np.isnan(rec[\"RMSE_test\"]) and np.isnan(best[\"RMSE_test\"]):\n",
    "                    better = (rec[\"RMSE_train\"] < best[\"RMSE_train\"]) or (\n",
    "                        rec[\"RMSE_train\"] == best[\"RMSE_train\"]\n",
    "                        and rec[\"AIC_train\"] < best[\"AIC_train\"]\n",
    "                    )\n",
    "                else:\n",
    "                    # kalau salah satu tidak punya test, prioritaskan yang punya test\n",
    "                    better = not np.isnan(rec[\"RMSE_test\"]) and np.isnan(best[\"RMSE_test\"])\n",
    "\n",
    "                if better:\n",
    "                    best = rec\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    tried_df = (\n",
    "        pd.DataFrame(tried)\n",
    "        .sort_values([\"RMSE_test\", \"AIC_train\"])\n",
    "        .reset_index(drop=True)\n",
    "        if tried\n",
    "        else pd.DataFrame()\n",
    "    )\n",
    "    return best, tried_df\n",
    "\n",
    "def plot_test_series(preds_df, cabang, sku, out_dir: Path):\n",
    "    d = preds_df[(preds_df[\"cabang\"] == cabang) & (preds_df[\"sku\"] == sku)].copy()\n",
    "    if d.empty:\n",
    "        return\n",
    "    d = d.sort_values(\"periode\")\n",
    "    d[\"periode\"] = pd.to_datetime(d[\"periode\"])\n",
    "    rmse_val = float(np.sqrt(np.mean((d[\"qty\"].values - d[\"pred\"].values) ** 2)))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10.5, 3.6))\n",
    "    locator = mdates.MonthLocator(interval=1)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(mdates.ConciseDateFormatter(locator))\n",
    "    ax.plot(d[\"periode\"], d[\"qty\"], lw=1.8, marker=\"o\", label=\"Actual\")\n",
    "    ax.plot(d[\"periode\"], d[\"pred\"], lw=1.8, marker=\"s\", label=\"Pred\")\n",
    "    ax.set_title(f\"{cabang}-{sku} | RMSE_test={rmse_val:.1f}\")\n",
    "    ax.set_xlabel(\"Periode\")\n",
    "    ax.set_ylabel(\"Qty\")\n",
    "    ax.grid(True, axis=\"y\", alpha=0.25)\n",
    "    ax.legend(loc=\"center left\", bbox_to_anchor=(1.02, 0.5), frameon=False)\n",
    "    fig.tight_layout(rect=[0, 0, 0.82, 1])\n",
    "    fpath = out_dir / f\"test_plot__{cabang}__{sku}.png\"\n",
    "    fig.savefig(fpath, dpi=160)\n",
    "    plt.close(fig)\n",
    "\n",
    "# ---------------- LOOP PER SERI ----------------\n",
    "records, preds = [], []\n",
    "\n",
    "# DI SINI BEDANYA:\n",
    "# bukan hanya sku yang punya is_test, tapi semua sku di dataset 15\n",
    "pairs = (\n",
    "    df[[\"cabang\", \"sku\"]]\n",
    "    .drop_duplicates()\n",
    "    .itertuples(index=False, name=None)\n",
    ")\n",
    "\n",
    "for cab, sku in pairs:\n",
    "    g = df[(df[\"cabang\"] == cab) & (df[\"sku\"] == sku)].copy()\n",
    "\n",
    "    d_val = int(d_suggest_map.get((cab, sku), 1))\n",
    "\n",
    "    exog_candidates = []\n",
    "    exog_candidates.append((\"none\", []))\n",
    "    if \"event_flag\" in g.columns:\n",
    "        exog_candidates.append((\"event\", [\"event_flag\"]))\n",
    "    if {\"event_flag\", \"holiday_count\"}.issubset(g.columns):\n",
    "        exog_candidates.append((\"event_hol\", [\"event_flag\", \"holiday_count\"]))\n",
    "    if {\"event_flag\", \"holiday_count\", \"rainfall_lag1\"}.issubset(g.columns):\n",
    "        exog_candidates.append(\n",
    "            (\n",
    "                \"event_hol_rain\",\n",
    "                [\"event_flag\", \"holiday_count\", \"rainfall_lag1\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    best_var = None\n",
    "    best_rec = None\n",
    "    best_exog_cols = []\n",
    "\n",
    "    # cari kombinasi exog terbaik (tanpa log dulu)\n",
    "    for tag, cols in exog_candidates:\n",
    "        b, _ = grid_fit_series(\n",
    "            g,\n",
    "            exog_cols=cols if cols else None,\n",
    "            use_log=False,\n",
    "            d_fix=d_val,\n",
    "        )\n",
    "        if not b:\n",
    "            continue\n",
    "        if best_rec is None:\n",
    "            best_var = tag\n",
    "            best_rec = b\n",
    "            best_exog_cols = cols\n",
    "        else:\n",
    "            if not np.isnan(b[\"RMSE_test\"]) and not np.isnan(best_rec[\"RMSE_test\"]):\n",
    "                better = (b[\"RMSE_test\"] < best_rec[\"RMSE_test\"]) or (\n",
    "                    b[\"RMSE_test\"] == best_rec[\"RMSE_test\"]\n",
    "                    and b[\"AIC_train\"] < best_rec[\"AIC_train\"]\n",
    "                )\n",
    "            elif np.isnan(b[\"RMSE_test\"]) and np.isnan(best_rec[\"RMSE_test\"]):\n",
    "                better = (b[\"RMSE_train\"] < best_rec[\"RMSE_train\"]) or (\n",
    "                    b[\"RMSE_train\"] == best_rec[\"RMSE_train\"]\n",
    "                    and b[\"AIC_train\"] < best_rec[\"AIC_train\"]\n",
    "                )\n",
    "            else:\n",
    "                better = not np.isnan(b[\"RMSE_test\"]) and np.isnan(best_rec[\"RMSE_test\"])\n",
    "\n",
    "            if better:\n",
    "                best_var = tag\n",
    "                best_rec = b\n",
    "                best_exog_cols = cols\n",
    "\n",
    "    if best_rec is None:\n",
    "        print(f\"[SKIP] {cab}-{sku}: gagal fit (train terlalu pendek atau error).\")\n",
    "        continue\n",
    "\n",
    "    # coba versi log1p dengan exog terbaik\n",
    "    blog, _ = grid_fit_series(\n",
    "        g,\n",
    "        exog_cols=best_exog_cols if best_exog_cols else None,\n",
    "        use_log=True,\n",
    "        d_fix=d_val,\n",
    "    )\n",
    "    use_log = False\n",
    "    cur = best_rec\n",
    "    variant_tag = best_var\n",
    "\n",
    "    if blog and (\n",
    "        (not np.isnan(blog[\"RMSE_test\"]) and not np.isnan(cur[\"RMSE_test\"]) and blog[\"RMSE_test\"] < cur[\"RMSE_test\"])\n",
    "        or (\n",
    "            np.isnan(blog[\"RMSE_test\"]) and np.isnan(cur[\"RMSE_test\"])\n",
    "            and blog[\"RMSE_train\"] < cur[\"RMSE_train\"]\n",
    "        )\n",
    "    ):\n",
    "        cur = blog\n",
    "        use_log = True\n",
    "        variant_tag = best_var + \"+log\"\n",
    "\n",
    "    records.append(\n",
    "        {\n",
    "            \"cabang\": cab,\n",
    "            \"sku\": sku,\n",
    "            \"variant\": variant_tag,\n",
    "            \"exog_used\": \",\".join(best_exog_cols) if best_exog_cols else \"(none)\",\n",
    "            \"use_log\": use_log,\n",
    "\n",
    "            \"order\": cur[\"order\"],\n",
    "            \"seasonal_order\": cur[\"seasonal_order\"],\n",
    "            \"AIC_train\": cur[\"AIC_train\"],\n",
    "\n",
    "            \"RMSE_train\": cur[\"RMSE_train\"],\n",
    "            \"MAE_train\": cur[\"MAE_train\"],\n",
    "            \"MAPE%_train\": cur[\"MAPE_train\"],\n",
    "            \"sMAPE%_train\": cur[\"sMAPE_train\"],\n",
    "\n",
    "            \"RMSE_test\": cur[\"RMSE_test\"],\n",
    "            \"MAE_test\": cur[\"MAE_test\"],\n",
    "            \"MAPE%_test\": cur[\"MAPE_test\"],\n",
    "            \"sMAPE%_test\": cur[\"sMAPE_test\"],\n",
    "\n",
    "            \"LB_p12\": cur[\"LB_p12\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # pred hanya buat seri yang punya test\n",
    "    m_te = g[\"is_test\"] == 1\n",
    "    if m_te.any() and len(cur[\"yhat\"]) > 0:\n",
    "        preds.append(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"periode\": g.loc[m_te, \"periode\"].values,\n",
    "                    \"qty\": g.loc[m_te, \"qty\"].values,\n",
    "                    \"pred\": np.asarray(cur[\"yhat\"], float),\n",
    "                    \"cabang\": cab,\n",
    "                    \"sku\": sku,\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "# ---------------- OUTPUT & SAVE ----------------\n",
    "results_df = (\n",
    "    pd.DataFrame(records)\n",
    "    .sort_values([\"cabang\", \"sku\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "forecasts_df = (\n",
    "    pd.concat(preds, ignore_index=True) if len(preds) else pd.DataFrame()\n",
    ")\n",
    "\n",
    "print(\"\\n=== RINGKASAN HASIL (DATASET 15) - BEBERAPA BARIS ===\")\n",
    "if not results_df.empty:\n",
    "    print(\n",
    "        results_df[\n",
    "            [\n",
    "                \"cabang\",\n",
    "                \"sku\",\n",
    "                \"variant\",\n",
    "                \"exog_used\",\n",
    "                \"order\",\n",
    "                \"seasonal_order\",\n",
    "                \"RMSE_train\",\n",
    "                \"RMSE_test\",\n",
    "                \"LB_p12\",\n",
    "            ]\n",
    "        ].head(20).to_string(index=False)\n",
    "    )\n",
    "else:\n",
    "    print(\"Tidak ada hasil. Seri terlalu pendek atau split bermasalah.\")\n",
    "\n",
    "METRICS_PATH = OUT_DIR / \"sarimax_selected15_metrics.csv\"\n",
    "PREDS_PATH   = OUT_DIR / \"sarimax_selected15_predictions.csv\"\n",
    "results_df.to_csv(METRICS_PATH, index=False)\n",
    "forecasts_df.to_csv(PREDS_PATH, index=False)\n",
    "print(f\"\\nSaved metrics  -> {METRICS_PATH}\")\n",
    "print(f\"Saved preds    -> {PREDS_PATH}\")\n",
    "\n",
    "# CHARTS (hanya seri dengan test)\n",
    "if not forecasts_df.empty:\n",
    "    for cab, sk in (\n",
    "        forecasts_df[[\"cabang\", \"sku\"]].drop_duplicates().itertuples(\n",
    "            index=False, name=None\n",
    "        )\n",
    "    ):\n",
    "        plot_test_series(forecasts_df, cab, sk, CHART_DIR)\n",
    "    print(f\"Saved charts   -> {CHART_DIR}\")\n",
    "else:\n",
    "    print(\"Tidak ada prediksi test untuk digambar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1376cc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Total baris TEST: 45\n",
      "\n",
      "=== RINGKASAN HASIL (DATASET 15) - BEBERAPA BARIS ===\n",
      "cabang          sku   variant                exog_used     order seasonal_order  RMSE_train   RMSE_test   LB_p12\n",
      "   02A  BNOP400CHAR     event               event_flag (2, 1, 1)  (0, 0, 0, 12)  665.621129         NaN 0.962245\n",
      "   02A  BNOP400CPOX     event               event_flag (2, 1, 1)  (0, 0, 0, 12)  665.621129         NaN 0.962245\n",
      "   02A  BUVW001K194 event_hol event_flag,holiday_count (2, 0, 1)  (0, 0, 0, 12)  383.261847         NaN 0.338005\n",
      "   02A   BUVW001KSB event_hol event_flag,holiday_count (2, 0, 1)  (0, 0, 0, 12)  547.539115         NaN 0.815757\n",
      "   02A  BUVW001KSBM      none                   (none) (2, 0, 1)  (0, 0, 0, 12)  348.688982         NaN 0.841516\n",
      "   02A   BUVW001KSW event_hol event_flag,holiday_count (1, 1, 1)  (0, 0, 0, 12) 1724.321914 2071.670881 0.364555\n",
      "   02A  BUVW100C192      none                   (none) (2, 0, 1)  (0, 0, 0, 12)  414.259315         NaN 0.254987\n",
      "   02A   BUVW100CSB      none                   (none) (2, 0, 1)  (0, 0, 0, 12)  784.690117         NaN 0.443389\n",
      "   02A   BUVW100CSW      none                   (none) (2, 0, 1)  (0, 0, 0, 12)  820.471264         NaN 0.688131\n",
      "   02A CKLM001KS607 event_hol event_flag,holiday_count (2, 0, 2)  (0, 0, 0, 12)  407.316529         NaN 0.758145\n",
      "   02A CKLM001KSPOL      none                   (none) (2, 0, 2)  (0, 0, 0, 12)  225.497921         NaN 0.729682\n",
      "   02A  DOPQ001K001     event               event_flag (1, 0, 1)  (0, 0, 0, 12)  509.435413         NaN 0.326296\n",
      "   02A  DOPQ001K009      none                   (none) (2, 0, 1)  (0, 0, 0, 12)  995.390652         NaN 0.102627\n",
      "   02A   FSTU001KSB event_hol event_flag,holiday_count (2, 1, 1)  (0, 0, 0, 12)  334.532003         NaN 0.596484\n",
      "   02A   FSTU001KSW event_hol event_flag,holiday_count (2, 1, 1)  (0, 0, 0, 12)  455.853130         NaN 0.439365\n",
      "   05A   BBCD005KSW     event               event_flag (1, 1, 2)  (1, 0, 1, 12)  589.279252         NaN 0.093673\n",
      "   05A  BUVW001K194     event               event_flag (1, 0, 1)  (0, 0, 0, 12)  275.371236         NaN 0.926562\n",
      "   05A   BUVW001KSB      none                   (none) (1, 0, 1)  (0, 0, 0, 12)  467.801576         NaN 0.780355\n",
      "   05A   BUVW001KSW     event               event_flag (1, 0, 2)  (0, 0, 0, 12) 1808.071046  993.868677 0.511619\n",
      "   05A  BUVW100C192      none                   (none) (2, 0, 2)  (0, 1, 0, 12)  338.531210         NaN 0.139799\n",
      "\n",
      "Saved metrics  -> D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_selected15\\sarimax_selected15_metrics.csv\n",
      "Saved preds    -> D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_selected15\\sarimax_selected15_predictions.csv\n",
      "Saved charts   -> D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_selected15\\charts\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# SARIMAX BASELINE (DATASET 15) - EVENT / HOLIDAY / RAINFALL\n",
    "# Grid search:\n",
    "#   - order, seasonal_order\n",
    "#   - kombinasi exog:\n",
    "#       (1) none\n",
    "#       (2) event_flag\n",
    "#       (3) event_flag + holiday_count\n",
    "#       (4) event_flag + holiday_count + rainfall_lag1\n",
    "#   - versi log1p vs level\n",
    "# d_suggest diambil dari model_profiles_selected15.csv\n",
    "# =========================================================\n",
    "import itertools\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------------- PATH ----------------\n",
    "PROJECT_ROOT = Path(r\"D:\\Documents\\Skripsi\\demand-forecasting\")\n",
    "\n",
    "DATA_PATH    = PROJECT_ROOT / \"data\" / \"dataset_15\" / \"sarimax_selected15_series.csv\"\n",
    "PROFILE_PATH = PROJECT_ROOT / \"data\" / \"dataset_15\" / \"model_profiles_selected15.csv\"\n",
    "\n",
    "OUT_DIR   = PROJECT_ROOT / \"outputs\" / \"sarimax_selected15\"\n",
    "CHART_DIR = OUT_DIR / \"charts\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CHART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------- LOAD ----------------\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=[\"periode\"]).sort_values(\n",
    "    [\"cabang\", \"sku\", \"periode\"]\n",
    ")\n",
    "\n",
    "profiles = pd.read_csv(PROFILE_PATH)\n",
    "\n",
    "# map d_suggest per (cabang, sku) dari model_profiles\n",
    "if \"sarimax_d_sug\" in profiles.columns:\n",
    "    d_suggest_map = dict(\n",
    "        zip(\n",
    "            zip(profiles[\"cabang\"], profiles[\"sku\"]),\n",
    "            profiles[\"sarimax_d_sug\"].astype(int),\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(\"[WARN] Kolom sarimax_d_sug tidak ada di model_profiles. Pakai d=1 semua.\")\n",
    "    d_suggest_map = {}\n",
    "\n",
    "# ---------------- QUICK SANITY ----------------\n",
    "expected_cols = [\n",
    "    \"cabang\",\n",
    "    \"sku\",\n",
    "    \"periode\",\n",
    "    \"qty\",\n",
    "    \"event_flag\",\n",
    "    \"is_train\",\n",
    "    \"is_test\",\n",
    "]\n",
    "missing = [c for c in expected_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Kolom wajib hilang: {missing}\")\n",
    "\n",
    "dups = df.duplicated(subset=[\"cabang\", \"sku\", \"periode\"]).sum()\n",
    "if dups:\n",
    "    raise ValueError(f\"Duplikat (cabang, sku, periode): {dups} baris\")\n",
    "\n",
    "test_total = int((df[\"is_test\"] == 1).sum())\n",
    "print(f\"[INFO] Total baris TEST: {test_total}\")\n",
    "\n",
    "for c in [\"qty\", \"event_flag\", \"holiday_count\", \"rainfall_lag1\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# ---------------- HELPERS ----------------\n",
    "def mape(a, f):\n",
    "    a, f = np.asarray(a, float), np.asarray(f, float)\n",
    "    mask = a != 0\n",
    "    return float(np.mean(np.abs((a[mask] - f[mask]) / a[mask])) * 100) if mask.any() else np.nan\n",
    "\n",
    "def smape(a, f):\n",
    "    a, f = np.asarray(a, float), np.asarray(f, float)\n",
    "    denom = (np.abs(a) + np.abs(f)) / 2.0\n",
    "    mask = denom != 0\n",
    "    return float(np.mean(np.abs(a[mask] - f[mask]) / denom[mask]) * 100) if mask.any() else np.nan\n",
    "\n",
    "def param_grid_small(d_fix=None):\n",
    "    \"\"\"\n",
    "    Grid kecil untuk (p,d,q) dan (P,D,Q,12).\n",
    "    Kalau d_fix tidak None, pakai hanya d_fix.\n",
    "    \"\"\"\n",
    "    yielded = set()\n",
    "    d_values = [0, 1] if d_fix is None else [int(d_fix)]\n",
    "\n",
    "    for p, d, q in itertools.product([0, 1, 2], d_values, [0, 1, 2]):\n",
    "        for P, D, Q in itertools.product([0, 1], [0, 1], [0, 1]):\n",
    "            if (p + q + P + Q) <= 6:\n",
    "                od, sod = (p, d, q), (P, D, Q, 12)\n",
    "                if (od, sod) in yielded:\n",
    "                    continue\n",
    "                yielded.add((od, sod))\n",
    "                yield od, sod\n",
    "\n",
    "def fit_eval(y_tr, X_tr, y_te, X_te, order, sorder, use_log=False):\n",
    "    # transform target (opsional)\n",
    "    ytr = np.log1p(np.clip(y_tr, a_min=0, a_max=None)) if use_log else y_tr\n",
    "\n",
    "    model = SARIMAX(\n",
    "        ytr,\n",
    "        exog=X_tr,\n",
    "        order=order,\n",
    "        seasonal_order=sorder,\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False,\n",
    "    )\n",
    "    res = model.fit(disp=False)\n",
    "\n",
    "    # fitted (train)\n",
    "    fitted_tr = res.fittedvalues\n",
    "    n_tr = min(len(y_tr), len(fitted_tr))\n",
    "    y_tr_cut = y_tr[-n_tr:]\n",
    "    fitted_tr = np.asarray(fitted_tr[-n_tr:], float)\n",
    "\n",
    "    rmse_train = float(np.sqrt(np.mean((y_tr_cut - fitted_tr) ** 2)))\n",
    "    mae_train  = float(np.mean(np.abs(y_tr_cut - fitted_tr)))\n",
    "    mape_train = mape(y_tr_cut, fitted_tr)\n",
    "    sMAPE_train = smape(y_tr_cut, fitted_tr)\n",
    "\n",
    "    # forecast untuk test (kalau ada)\n",
    "    if y_te is not None and len(y_te) > 0:\n",
    "        fh = len(y_te)\n",
    "        pred_t = res.get_forecast(steps=fh, exog=X_te).predicted_mean\n",
    "        yhat = np.expm1(pred_t) if use_log else np.asarray(pred_t, float)\n",
    "\n",
    "        rmse_test = float(np.sqrt(np.mean((y_te - yhat) ** 2)))\n",
    "        mae_test  = float(np.mean(np.abs(y_te - yhat)))\n",
    "        mape_test = mape(y_te, yhat)\n",
    "        sMAPE_test = smape(y_te, yhat)\n",
    "    else:\n",
    "        yhat = np.array([], float)\n",
    "        rmse_test = np.nan\n",
    "        mae_test  = np.nan\n",
    "        mape_test = np.nan\n",
    "        sMAPE_test = np.nan\n",
    "\n",
    "    resid = res.resid\n",
    "    try:\n",
    "        lb_p = float(\n",
    "            acorr_ljungbox(resid, lags=[12], return_df=True)[\"lb_pvalue\"].iloc[-1]\n",
    "        )\n",
    "    except Exception:\n",
    "        lb_p = np.nan\n",
    "\n",
    "    return dict(\n",
    "        order=order,\n",
    "        seasonal_order=sorder,\n",
    "        AIC_train=float(res.aic),\n",
    "\n",
    "        RMSE_train=rmse_train,\n",
    "        MAE_train=mae_train,\n",
    "        MAPE_train=mape_train,\n",
    "        sMAPE_train=sMAPE_train,\n",
    "\n",
    "        RMSE_test=rmse_test,\n",
    "        MAE_test=mae_test,\n",
    "        MAPE_test=mape_test,\n",
    "        sMAPE_test=sMAPE_test,\n",
    "\n",
    "        LB_p12=lb_p,\n",
    "        yhat=yhat,\n",
    "    )\n",
    "\n",
    "def _better_by_train(rec, best):\n",
    "    \"\"\"\n",
    "    Bandingkan dua kandidat pakai:\n",
    "      1) RMSE_train (lebih kecil lebih baik)\n",
    "      2) AIC_train sebagai tie-break\n",
    "    \"\"\"\n",
    "    if best is None:\n",
    "        return True\n",
    "\n",
    "    r1 = rec[\"RMSE_train\"]\n",
    "    r2 = best[\"RMSE_train\"]\n",
    "\n",
    "    if np.isnan(r2):\n",
    "        return True\n",
    "    if np.isnan(r1):\n",
    "        return False\n",
    "\n",
    "    if r1 < r2:\n",
    "        return True\n",
    "    if r1 > r2:\n",
    "        return False\n",
    "\n",
    "    # tie di RMSE_train, pakai AIC_train\n",
    "    return rec[\"AIC_train\"] < best[\"AIC_train\"]\n",
    "\n",
    "def grid_fit_series(g, exog_cols=None, use_log=False, d_fix=None):\n",
    "    g = g.sort_values(\"periode\").copy()\n",
    "    y = g[\"qty\"].astype(float).values\n",
    "    X = g[exog_cols].astype(float).values if exog_cols else None\n",
    "\n",
    "    m_tr = g[\"is_train\"].astype(bool).values\n",
    "    m_te = g[\"is_test\"].astype(bool).values\n",
    "\n",
    "    y_tr = y[m_tr]\n",
    "    y_te = y[m_te]\n",
    "    X_tr = X[m_tr] if X is not None else None\n",
    "    X_te = X[m_te] if X is not None else None\n",
    "\n",
    "    # bersihkan NaN di train\n",
    "    if X_tr is not None:\n",
    "        ok = ~np.isnan(y_tr)\n",
    "        y_tr, X_tr = y_tr[ok], X_tr[ok]\n",
    "        ok = ~np.isnan(X_tr).any(axis=1)\n",
    "        y_tr, X_tr = y_tr[ok], X_tr[ok]\n",
    "    else:\n",
    "        y_tr = y_tr[~np.isnan(y_tr)]\n",
    "\n",
    "    if len(y_tr) < 24:\n",
    "        return None, pd.DataFrame()\n",
    "\n",
    "    if X_te is not None and len(X_te) > 0:\n",
    "        ok_te = ~np.isnan(X_te).any(axis=1)\n",
    "        y_te = y_te[ok_te]\n",
    "        X_te = X_te[ok_te]\n",
    "\n",
    "    tried, best = [], None\n",
    "    for od, sod in param_grid_small(d_fix=d_fix):\n",
    "        try:\n",
    "            rec = fit_eval(y_tr, X_tr, y_te, X_te, od, sod, use_log=use_log)\n",
    "            tried.append(\n",
    "                {\n",
    "                    k: rec[k]\n",
    "                    for k in [\n",
    "                        \"order\",\n",
    "                        \"seasonal_order\",\n",
    "                        \"AIC_train\",\n",
    "                        \"RMSE_train\",\n",
    "                        \"MAE_train\",\n",
    "                        \"MAPE_train\",\n",
    "                        \"sMAPE_train\",\n",
    "                        \"RMSE_test\",\n",
    "                        \"MAE_test\",\n",
    "                        \"MAPE_test\",\n",
    "                        \"sMAPE_test\",\n",
    "                        \"LB_p12\",\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "\n",
    "            if _better_by_train(rec, best):\n",
    "                best = rec\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    tried_df = (\n",
    "        pd.DataFrame(tried)\n",
    "        .sort_values([\"RMSE_train\", \"AIC_train\"])\n",
    "        .reset_index(drop=True)\n",
    "        if tried\n",
    "        else pd.DataFrame()\n",
    "    )\n",
    "    return best, tried_df\n",
    "\n",
    "def plot_test_series(preds_df, cabang, sku, out_dir: Path):\n",
    "    d = preds_df[(preds_df[\"cabang\"] == cabang) & (preds_df[\"sku\"] == sku)].copy()\n",
    "    if d.empty:\n",
    "        return\n",
    "    d = d.sort_values(\"periode\")\n",
    "    d[\"periode\"] = pd.to_datetime(d[\"periode\"])\n",
    "    rmse_val = float(np.sqrt(np.mean((d[\"qty\"].values - d[\"pred\"].values) ** 2)))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10.5, 3.6))\n",
    "    locator = mdates.MonthLocator(interval=1)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(mdates.ConciseDateFormatter(locator))\n",
    "    ax.plot(d[\"periode\"], d[\"qty\"], lw=1.8, marker=\"o\", label=\"Actual\")\n",
    "    ax.plot(d[\"periode\"], d[\"pred\"], lw=1.8, marker=\"s\", label=\"Pred\")\n",
    "    ax.set_title(f\"{cabang}-{sku} | RMSE_test={rmse_val:.1f}\")\n",
    "    ax.set_xlabel(\"Periode\")\n",
    "    ax.set_ylabel(\"Qty\")\n",
    "    ax.grid(True, axis=\"y\", alpha=0.25)\n",
    "    ax.legend(loc=\"center left\", bbox_to_anchor=(1.02, 0.5), frameon=False)\n",
    "    fig.tight_layout(rect=[0, 0, 0.82, 1])\n",
    "    fpath = out_dir / f\"test_plot__{cabang}__{sku}.png\"\n",
    "    fig.savefig(fpath, dpi=160)\n",
    "    plt.close(fig)\n",
    "\n",
    "# ---------------- LOOP PER SERI ----------------\n",
    "records, preds = [], []\n",
    "\n",
    "pairs = (\n",
    "    df[[\"cabang\", \"sku\"]]\n",
    "    .drop_duplicates()\n",
    "    .itertuples(index=False, name=None)\n",
    ")\n",
    "\n",
    "for cab, sku in pairs:\n",
    "    g = df[(df[\"cabang\"] == cab) & (df[\"sku\"] == sku)].copy()\n",
    "\n",
    "    d_val = int(d_suggest_map.get((cab, sku), 1))\n",
    "\n",
    "    exog_candidates = []\n",
    "    exog_candidates.append((\"none\", []))\n",
    "    if \"event_flag\" in g.columns:\n",
    "        exog_candidates.append((\"event\", [\"event_flag\"]))\n",
    "    if {\"event_flag\", \"holiday_count\"}.issubset(g.columns):\n",
    "        exog_candidates.append((\"event_hol\", [\"event_flag\", \"holiday_count\"]))\n",
    "    if {\"event_flag\", \"holiday_count\", \"rainfall_lag1\"}.issubset(g.columns):\n",
    "        exog_candidates.append(\n",
    "            (\n",
    "                \"event_hol_rain\",\n",
    "                [\"event_flag\", \"holiday_count\", \"rainfall_lag1\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    best_var = None\n",
    "    best_rec = None\n",
    "    best_exog_cols = []\n",
    "\n",
    "    # cari kombinasi exog terbaik (pakai RMSE_train + AIC_train)\n",
    "    for tag, cols in exog_candidates:\n",
    "        b, _ = grid_fit_series(\n",
    "            g,\n",
    "            exog_cols=cols if cols else None,\n",
    "            use_log=False,\n",
    "            d_fix=d_val,\n",
    "        )\n",
    "        if not b:\n",
    "            continue\n",
    "        if _better_by_train(b, best_rec):\n",
    "            best_var = tag\n",
    "            best_rec = b\n",
    "            best_exog_cols = cols\n",
    "\n",
    "    if best_rec is None:\n",
    "        print(f\"[SKIP] {cab}-{sku}: gagal fit (train terlalu pendek atau error).\")\n",
    "        continue\n",
    "\n",
    "    # coba versi log1p dengan exog terbaik\n",
    "    blog, _ = grid_fit_series(\n",
    "        g,\n",
    "        exog_cols=best_exog_cols if best_exog_cols else None,\n",
    "        use_log=True,\n",
    "        d_fix=d_val,\n",
    "    )\n",
    "    use_log = False\n",
    "    cur = best_rec\n",
    "    variant_tag = best_var\n",
    "\n",
    "    if blog and _better_by_train(blog, cur):\n",
    "        cur = blog\n",
    "        use_log = True\n",
    "        variant_tag = best_var + \"+log\"\n",
    "\n",
    "    records.append(\n",
    "        {\n",
    "            \"cabang\": cab,\n",
    "            \"sku\": sku,\n",
    "            \"variant\": variant_tag,\n",
    "            \"exog_used\": \",\".join(best_exog_cols) if best_exog_cols else \"(none)\",\n",
    "            \"use_log\": use_log,\n",
    "\n",
    "            \"order\": cur[\"order\"],\n",
    "            \"seasonal_order\": cur[\"seasonal_order\"],\n",
    "            \"AIC_train\": cur[\"AIC_train\"],\n",
    "\n",
    "            \"RMSE_train\": cur[\"RMSE_train\"],\n",
    "            \"MAE_train\": cur[\"MAE_train\"],\n",
    "            \"MAPE%_train\": cur[\"MAPE_train\"],\n",
    "            \"sMAPE%_train\": cur[\"sMAPE_train\"],\n",
    "\n",
    "            \"RMSE_test\": cur[\"RMSE_test\"],\n",
    "            \"MAE_test\": cur[\"MAE_test\"],\n",
    "            \"MAPE%_test\": cur[\"MAPE_test\"],\n",
    "            \"sMAPE%_test\": cur[\"sMAPE_test\"],\n",
    "\n",
    "            \"LB_p12\": cur[\"LB_p12\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # pred hanya buat seri yang punya test\n",
    "    m_te = g[\"is_test\"] == 1\n",
    "    if m_te.any() and len(cur[\"yhat\"]) > 0:\n",
    "        preds.append(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"periode\": g.loc[m_te, \"periode\"].values,\n",
    "                    \"qty\": g.loc[m_te, \"qty\"].values,\n",
    "                    \"pred\": np.asarray(cur[\"yhat\"], float),\n",
    "                    \"cabang\": cab,\n",
    "                    \"sku\": sku,\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "# ---------------- OUTPUT & SAVE ----------------\n",
    "results_df = (\n",
    "    pd.DataFrame(records)\n",
    "    .sort_values([\"cabang\", \"sku\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "forecasts_df = (\n",
    "    pd.concat(preds, ignore_index=True) if len(preds) else pd.DataFrame()\n",
    ")\n",
    "\n",
    "print(\"\\n=== RINGKASAN HASIL (DATASET 15) - BEBERAPA BARIS ===\")\n",
    "if not results_df.empty:\n",
    "    print(\n",
    "        results_df[\n",
    "            [\n",
    "                \"cabang\",\n",
    "                \"sku\",\n",
    "                \"variant\",\n",
    "                \"exog_used\",\n",
    "                \"order\",\n",
    "                \"seasonal_order\",\n",
    "                \"RMSE_train\",\n",
    "                \"RMSE_test\",\n",
    "                \"LB_p12\",\n",
    "            ]\n",
    "        ].head(20).to_string(index=False)\n",
    "    )\n",
    "else:\n",
    "    print(\"Tidak ada hasil. Seri terlalu pendek atau split bermasalah.\")\n",
    "\n",
    "METRICS_PATH = OUT_DIR / \"sarimax_selected15_metrics.csv\"\n",
    "PREDS_PATH   = OUT_DIR / \"sarimax_selected15_predictions.csv\"\n",
    "results_df.to_csv(METRICS_PATH, index=False)\n",
    "forecasts_df.to_csv(PREDS_PATH, index=False)\n",
    "print(f\"\\nSaved metrics  -> {METRICS_PATH}\")\n",
    "print(f\"Saved preds    -> {PREDS_PATH}\")\n",
    "\n",
    "# CHARTS (hanya seri dengan test)\n",
    "if not forecasts_df.empty:\n",
    "    for cab, sk in (\n",
    "        forecasts_df[[\"cabang\", \"sku\"]].drop_duplicates().itertuples(\n",
    "            index=False, name=None\n",
    "        )\n",
    "    ):\n",
    "        plot_test_series(forecasts_df, cab, sk, CHART_DIR)\n",
    "    print(f\"Saved charts   -> {CHART_DIR}\")\n",
    "else:\n",
    "    print(\"Tidak ada prediksi test untuk digambar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d81c9efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Total baris TEST: 45\n",
      "\n",
      "=== RINGKASAN HASIL (DATASET 15, LOG1P TARGET, TRAIN-ONLY SELECTION) - BEBERAPA BARIS ===\n",
      "cabang          sku       variant                exog_used  RMSE_train    MSE_train   MAE_train  MAPE%_train  sMAPE%_train   RMSE_test     MSE_test    MAE_test  MAPE%_test  sMAPE%_test   LB_p12\n",
      "   02A  BNOP400CHAR     event+log               event_flag  626.648831 3.926888e+05  477.690362   106.334518     80.326581         NaN          NaN         NaN         NaN          NaN 0.808845\n",
      "   02A  BNOP400CPOX     event+log               event_flag  626.648831 3.926888e+05  477.690362   106.334518     80.326581         NaN          NaN         NaN         NaN          NaN 0.808845\n",
      "   02A  BUVW001K194 event_hol+log event_flag,holiday_count  367.585462 1.351191e+05  287.621412    42.624603     42.670006         NaN          NaN         NaN         NaN          NaN 0.998066\n",
      "   02A   BUVW001KSB     event+log               event_flag  526.190981 2.768769e+05  413.571270    42.185478     43.376968         NaN          NaN         NaN         NaN          NaN 0.645902\n",
      "   02A  BUVW001KSBM event_hol+log event_flag,holiday_count  344.749376 1.188521e+05  252.495070    39.218296     37.993209         NaN          NaN         NaN         NaN          NaN 0.996711\n",
      "   02A   BUVW001KSW event_hol+log event_flag,holiday_count 1732.555022 3.001747e+06 1394.204640    44.276637     39.382238 1959.400426 3.839250e+06 1584.019127   76.249231    52.633184 0.999901\n",
      "   02A  BUVW100C192 event_hol+log event_flag,holiday_count  412.246511 1.699472e+05  303.573131    36.918606     35.564613         NaN          NaN         NaN         NaN          NaN 0.999738\n",
      "   02A   BUVW100CSB event_hol+log event_flag,holiday_count  827.895709 6.854113e+05  612.214217    29.483996     30.517080         NaN          NaN         NaN         NaN          NaN 0.999795\n",
      "   02A   BUVW100CSW     event+log               event_flag  852.590211 7.269101e+05  631.462867    34.051698     36.455487         NaN          NaN         NaN         NaN          NaN 0.857493\n",
      "   02A CKLM001KS607     event+log               event_flag  407.764228 1.662717e+05  305.732616    32.410877     33.338846         NaN          NaN         NaN         NaN          NaN 0.999922\n",
      "   02A CKLM001KSPOL     event+log               event_flag  226.133436 5.113633e+04  184.675591    33.425972     33.631598         NaN          NaN         NaN         NaN          NaN 0.998683\n",
      "   02A  DOPQ001K001 event_hol+log event_flag,holiday_count  488.293116 2.384302e+05  362.678499    44.708118     41.296117         NaN          NaN         NaN         NaN          NaN 0.975079\n",
      "   02A  DOPQ001K009 event_hol+log event_flag,holiday_count  955.145802 9.123035e+05  754.675118    45.970170     40.631244         NaN          NaN         NaN         NaN          NaN 0.987930\n",
      "   02A   FSTU001KSB event_hol+log event_flag,holiday_count  332.918799 1.108349e+05  238.838692    41.110762     39.510725         NaN          NaN         NaN         NaN          NaN 0.878282\n",
      "   02A   FSTU001KSW event_hol+log event_flag,holiday_count  465.445029 2.166391e+05  374.593930    39.777820     36.666059         NaN          NaN         NaN         NaN          NaN 0.989338\n",
      "   05A   BBCD005KSW event_hol+log event_flag,holiday_count  618.200186 3.821715e+05  462.252175    24.586215     25.515240         NaN          NaN         NaN         NaN          NaN 1.000000\n",
      "   05A  BUVW001K194 event_hol+log event_flag,holiday_count  260.744355 6.798762e+04  181.115850    20.345435     22.432837         NaN          NaN         NaN         NaN          NaN 1.000000\n",
      "   05A   BUVW001KSB event_hol+log event_flag,holiday_count  435.633350 1.897764e+05  310.838438    20.297905     22.653164         NaN          NaN         NaN         NaN          NaN 0.999999\n",
      "   05A   BUVW001KSW event_hol+log event_flag,holiday_count 1769.988435 3.132859e+06 1211.172810    21.194620     23.031350  898.738516 8.077309e+05  677.524943   14.808880    16.619433 1.000000\n",
      "   05A  BUVW100C192 event_hol+log event_flag,holiday_count  471.079920 2.219163e+05  275.092146    33.399487     35.500740         NaN          NaN         NaN         NaN          NaN 0.999695\n",
      "\n",
      "Saved metrics  -> D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_selected15_log_trainselect\\sarimax_selected15_log_trainselect_metrics.csv\n",
      "Saved preds    -> D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_selected15_log_trainselect\\sarimax_selected15_log_trainselect_predictions.csv\n",
      "Saved charts   -> D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_selected15_log_trainselect\\charts\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# SARIMAX BASELINE (DATASET 15) - LOG1P(QTY)\n",
    "# Pemilihan model:\n",
    "#   - HANYA pakai RMSE_train (utama) + AIC_train (tie-break)\n",
    "#   - Test metrics (RMSE_test, MSE_test, dst) murni untuk evaluasi\n",
    "#\n",
    "# Kombinasi exog yang dicoba:\n",
    "#   (1) none\n",
    "#   (2) event_flag\n",
    "#   (3) event_flag + holiday_count\n",
    "#   (4) event_flag + holiday_count + rainfall_lag1\n",
    "#\n",
    "# d_suggest diambil dari model_profiles_selected15.csv\n",
    "# Target SELALU log1p(qty), evaluasi di level qty\n",
    "# =========================================================\n",
    "import itertools\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------------- PATH ----------------\n",
    "PROJECT_ROOT = Path(r\"D:\\Documents\\Skripsi\\demand-forecasting\")\n",
    "\n",
    "DATA_PATH    = PROJECT_ROOT / \"data\" / \"dataset_15\" / \"sarimax_selected15_series.csv\"\n",
    "PROFILE_PATH = PROJECT_ROOT / \"data\" / \"dataset_15\" / \"model_profiles_selected15.csv\"\n",
    "\n",
    "OUT_DIR   = PROJECT_ROOT / \"outputs\" / \"sarimax_selected15_log_trainselect\"\n",
    "CHART_DIR = OUT_DIR / \"charts\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CHART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------- LOAD ----------------\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=[\"periode\"]).sort_values(\n",
    "    [\"cabang\", \"sku\", \"periode\"]\n",
    ")\n",
    "\n",
    "profiles = pd.read_csv(PROFILE_PATH)\n",
    "\n",
    "# map d_suggest per (cabang, sku) dari model_profiles\n",
    "if \"sarimax_d_sug\" in profiles.columns:\n",
    "    d_suggest_map = dict(\n",
    "        zip(\n",
    "            zip(profiles[\"cabang\"], profiles[\"sku\"]),\n",
    "            profiles[\"sarimax_d_sug\"].astype(int),\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(\"[WARN] Kolom sarimax_d_sug tidak ada di model_profiles. Pakai d=1 semua.\")\n",
    "    d_suggest_map = {}\n",
    "\n",
    "# ---------------- QUICK SANITY ----------------\n",
    "expected_cols = [\n",
    "    \"cabang\",\n",
    "    \"sku\",\n",
    "    \"periode\",\n",
    "    \"qty\",\n",
    "    \"event_flag\",\n",
    "    \"is_train\",\n",
    "    \"is_test\",\n",
    "]\n",
    "missing = [c for c in expected_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Kolom wajib hilang: {missing}\")\n",
    "\n",
    "dups = df.duplicated(subset=[\"cabang\", \"sku\", \"periode\"]).sum()\n",
    "if dups:\n",
    "    raise ValueError(f\"Duplikat (cabang, sku, periode): {dups} baris\")\n",
    "\n",
    "test_total = int((df[\"is_test\"] == 1).sum())\n",
    "print(f\"[INFO] Total baris TEST: {test_total}\")\n",
    "\n",
    "for c in [\"qty\", \"event_flag\", \"holiday_count\", \"rainfall_lag1\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# ---------------- METRICS ----------------\n",
    "def mse(a, f):\n",
    "    a, f = np.asarray(a, float), np.asarray(f, float)\n",
    "    return float(np.mean((a - f) ** 2))\n",
    "\n",
    "def mape(a, f):\n",
    "    a, f = np.asarray(a, float), np.asarray(f, float)\n",
    "    mask = a != 0\n",
    "    return float(np.mean(np.abs((a[mask] - f[mask]) / a[mask])) * 100) if mask.any() else np.nan\n",
    "\n",
    "def smape(a, f):\n",
    "    a, f = np.asarray(a, float), np.asarray(f, float)\n",
    "    denom = (np.abs(a) + np.abs(f)) / 2.0\n",
    "    mask = denom != 0\n",
    "    return float(np.mean(np.abs(a[mask] - f[mask]) / denom[mask]) * 100) if mask.any() else np.nan\n",
    "\n",
    "# ---------------- PARAM GRID ----------------\n",
    "def param_grid_small(d_fix=None):\n",
    "    \"\"\"\n",
    "    Grid kecil untuk (p,d,q) dan (P,D,Q,12).\n",
    "    Kalau d_fix tidak None, pakai hanya d_fix.\n",
    "    \"\"\"\n",
    "    yielded = set()\n",
    "    d_values = [0, 1] if d_fix is None else [int(d_fix)]\n",
    "\n",
    "    for p, d, q in itertools.product([0, 1, 2], d_values, [0, 1, 2]):\n",
    "        for P, D, Q in itertools.product([0, 1], [0, 1], [0, 1]):\n",
    "            if (p + q + P + Q) <= 6:\n",
    "                od, sod = (p, d, q), (P, D, Q, 12)\n",
    "                if (od, sod) in yielded:\n",
    "                    continue\n",
    "                yielded.add((od, sod))\n",
    "                yield od, sod\n",
    "\n",
    "# ---------------- FIT 1 KANDIDAT (SELALU LOG1P) ----------------\n",
    "def fit_eval_log(y_tr, X_tr, y_te, X_te, order, sorder):\n",
    "    \"\"\"\n",
    "    Train SARIMAX dengan target log1p(y), evaluasi di level qty.\n",
    "    \"\"\"\n",
    "    # transform target\n",
    "    ytr_log = np.log1p(np.clip(y_tr, a_min=0, a_max=None))\n",
    "\n",
    "    model = SARIMAX(\n",
    "        ytr_log,\n",
    "        exog=X_tr,\n",
    "        order=order,\n",
    "        seasonal_order=sorder,\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False,\n",
    "    )\n",
    "    res = model.fit(disp=False)\n",
    "\n",
    "    # fitted (train) di log, balik ke level\n",
    "    fitted_tr_log = res.fittedvalues\n",
    "    n_tr = min(len(y_tr), len(fitted_tr_log))\n",
    "    y_tr_cut = y_tr[-n_tr:]\n",
    "    fitted_tr_log = np.asarray(fitted_tr_log[-n_tr:], float)\n",
    "    fitted_tr = np.expm1(fitted_tr_log)\n",
    "\n",
    "    rmse_train = float(np.sqrt(np.mean((y_tr_cut - fitted_tr) ** 2)))\n",
    "    mse_train  = mse(y_tr_cut, fitted_tr)\n",
    "    mae_train  = float(np.mean(np.abs(y_tr_cut - fitted_tr)))\n",
    "    mape_train = mape(y_tr_cut, fitted_tr)\n",
    "    smape_train = smape(y_tr_cut, fitted_tr)\n",
    "\n",
    "    # forecast test (hanya untuk evaluasi, tidak untuk seleksi)\n",
    "    if y_te is not None and len(y_te) > 0:\n",
    "        fh = len(y_te)\n",
    "        pred_log = res.get_forecast(steps=fh, exog=X_te).predicted_mean\n",
    "        yhat = np.expm1(pred_log)\n",
    "\n",
    "        rmse_test = float(np.sqrt(np.mean((y_te - yhat) ** 2)))\n",
    "        mse_test  = mse(y_te, yhat)\n",
    "        mae_test  = float(np.mean(np.abs(y_te - yhat)))\n",
    "        mape_test = mape(y_te, yhat)\n",
    "        smape_test = smape(y_te, yhat)\n",
    "    else:\n",
    "        yhat = np.array([], float)\n",
    "        rmse_test = np.nan\n",
    "        mse_test  = np.nan\n",
    "        mae_test  = np.nan\n",
    "        mape_test = np.nan\n",
    "        smape_test = np.nan\n",
    "\n",
    "    resid = res.resid\n",
    "    try:\n",
    "        lb_p = float(\n",
    "            acorr_ljungbox(resid, lags=[12], return_df=True)[\"lb_pvalue\"].iloc[-1]\n",
    "        )\n",
    "    except Exception:\n",
    "        lb_p = np.nan\n",
    "\n",
    "    return dict(\n",
    "        order=order,\n",
    "        seasonal_order=sorder,\n",
    "        AIC_train=float(res.aic),\n",
    "\n",
    "        RMSE_train=rmse_train,\n",
    "        MSE_train=mse_train,\n",
    "        MAE_train=mae_train,\n",
    "        MAPE_train=mape_train,\n",
    "        sMAPE_train=smape_train,\n",
    "\n",
    "        RMSE_test=rmse_test,\n",
    "        MSE_test=mse_test,\n",
    "        MAE_test=mae_test,\n",
    "        MAPE_test=mape_test,\n",
    "        sMAPE_test=smape_test,\n",
    "\n",
    "        LB_p12=lb_p,\n",
    "        yhat=yhat,\n",
    "    )\n",
    "\n",
    "# ---------------- GRID 1 SERI + 1 VARIAN EXOG ----------------\n",
    "def grid_fit_series_log(g, exog_cols=None, d_fix=None):\n",
    "    \"\"\"\n",
    "    Grid search untuk 1 seri (cabang, sku) dan 1 set exog_cols tertentu.\n",
    "    Target selalu log1p.\n",
    "\n",
    "    PEMILIHAN MODEL:\n",
    "      - Utama: RMSE_train (lebih kecil lebih baik)\n",
    "      - Tie-break: AIC_train (lebih kecil lebih baik)\n",
    "    \"\"\"\n",
    "    g = g.sort_values(\"periode\").copy()\n",
    "    y = g[\"qty\"].astype(float).values\n",
    "    X = g[exog_cols].astype(float).values if exog_cols else None\n",
    "\n",
    "    m_tr = g[\"is_train\"].astype(bool).values\n",
    "    m_te = g[\"is_test\"].astype(bool).values\n",
    "\n",
    "    y_tr = y[m_tr]\n",
    "    y_te = y[m_te]\n",
    "    X_tr = X[m_tr] if X is not None else None\n",
    "    X_te = X[m_te] if X is not None else None\n",
    "\n",
    "    # bersihkan NaN di train\n",
    "    if X_tr is not None:\n",
    "        ok = ~np.isnan(y_tr)\n",
    "        y_tr, X_tr = y_tr[ok], X_tr[ok]\n",
    "        ok = ~np.isnan(X_tr).any(axis=1)\n",
    "        y_tr, X_tr = y_tr[ok], X_tr[ok]\n",
    "    else:\n",
    "        y_tr = y_tr[~np.isnan(y_tr)]\n",
    "\n",
    "    if len(y_tr) < 24:\n",
    "        return None, pd.DataFrame()\n",
    "\n",
    "    # bersihkan test exog kalau ada (cuma untuk evaluasi)\n",
    "    if X_te is not None and len(X_te) > 0:\n",
    "        ok_te = ~np.isnan(X_te).any(axis=1)\n",
    "        y_te = y_te[ok_te]\n",
    "        X_te = X_te[ok_te]\n",
    "\n",
    "    tried, best = [], None\n",
    "    for od, sod in param_grid_small(d_fix=d_fix):\n",
    "        try:\n",
    "            rec = fit_eval_log(y_tr, X_tr, y_te, X_te, od, sod)\n",
    "            tried.append(\n",
    "                {\n",
    "                    k: rec[k]\n",
    "                    for k in [\n",
    "                        \"order\",\n",
    "                        \"seasonal_order\",\n",
    "                        \"AIC_train\",\n",
    "                        \"RMSE_train\",\n",
    "                        \"MSE_train\",\n",
    "                        \"MAE_train\",\n",
    "                        \"MAPE_train\",\n",
    "                        \"sMAPE_train\",\n",
    "                        \"RMSE_test\",\n",
    "                        \"MSE_test\",\n",
    "                        \"MAE_test\",\n",
    "                        \"MAPE_test\",\n",
    "                        \"sMAPE_test\",\n",
    "                        \"LB_p12\",\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # SELEKSI model: hanya pakai RMSE_train + AIC_train\n",
    "            if best is None:\n",
    "                best = rec\n",
    "            else:\n",
    "                better = (\n",
    "                    (rec[\"RMSE_train\"] < best[\"RMSE_train\"]) or\n",
    "                    (\n",
    "                        rec[\"RMSE_train\"] == best[\"RMSE_train\"]\n",
    "                        and rec[\"AIC_train\"] < best[\"AIC_train\"]\n",
    "                    )\n",
    "                )\n",
    "                if better:\n",
    "                    best = rec\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    tried_df = (\n",
    "        pd.DataFrame(tried)\n",
    "        .sort_values([\"RMSE_train\", \"AIC_train\"])\n",
    "        .reset_index(drop=True)\n",
    "        if tried\n",
    "        else pd.DataFrame()\n",
    "    )\n",
    "    return best, tried_df\n",
    "\n",
    "# ---------------- PLOT TEST ----------------\n",
    "def plot_test_series(preds_df, cabang, sku, out_dir: Path):\n",
    "    d = preds_df[(preds_df[\"cabang\"] == cabang) & (preds_df[\"sku\"] == sku)].copy()\n",
    "    if d.empty:\n",
    "        return\n",
    "    d = d.sort_values(\"periode\")\n",
    "    d[\"periode\"] = pd.to_datetime(d[\"periode\"])\n",
    "    rmse_val = float(np.sqrt(np.mean((d[\"qty\"].values - d[\"pred\"].values) ** 2)))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10.5, 3.6))\n",
    "    locator = mdates.MonthLocator(interval=1)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(mdates.ConciseDateFormatter(locator))\n",
    "    ax.plot(d[\"periode\"], d[\"qty\"], lw=1.8, marker=\"o\", label=\"Actual\")\n",
    "    ax.plot(d[\"periode\"], d[\"pred\"], lw=1.8, marker=\"s\", label=\"Pred\")\n",
    "    ax.set_title(f\"{cabang}-{sku} | RMSE_test={rmse_val:.1f}\")\n",
    "    ax.set_xlabel(\"Periode\")\n",
    "    ax.set_ylabel(\"Qty\")\n",
    "    ax.grid(True, axis=\"y\", alpha=0.25)\n",
    "    ax.legend(loc=\"center left\", bbox_to_anchor=(1.02, 0.5), frameon=False)\n",
    "    fig.tight_layout(rect=[0, 0, 0.82, 1])\n",
    "    fpath = out_dir / f\"test_plot__{cabang}__{sku}.png\"\n",
    "    fig.savefig(fpath, dpi=160)\n",
    "    plt.close(fig)\n",
    "\n",
    "# ---------------- LOOP PER SERI ----------------\n",
    "records, preds = [], []\n",
    "\n",
    "pairs = (\n",
    "    df[[\"cabang\", \"sku\"]]\n",
    "    .drop_duplicates()\n",
    "    .itertuples(index=False, name=None)\n",
    ")\n",
    "\n",
    "for cab, sku in pairs:\n",
    "    g = df[(df[\"cabang\"] == cab) & (df[\"sku\"] == sku)].copy()\n",
    "\n",
    "    d_val = int(d_suggest_map.get((cab, sku), 1))\n",
    "\n",
    "    exog_candidates = []\n",
    "    exog_candidates.append((\"none\", []))\n",
    "    if \"event_flag\" in g.columns:\n",
    "        exog_candidates.append((\"event\", [\"event_flag\"]))\n",
    "    if {\"event_flag\", \"holiday_count\"}.issubset(g.columns):\n",
    "        exog_candidates.append((\"event_hol\", [\"event_flag\", \"holiday_count\"]))\n",
    "    if {\"event_flag\", \"holiday_count\", \"rainfall_lag1\"}.issubset(g.columns):\n",
    "        exog_candidates.append(\n",
    "            (\n",
    "                \"event_hol_rain\",\n",
    "                [\"event_flag\", \"holiday_count\", \"rainfall_lag1\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    best_tag = None\n",
    "    best_rec = None\n",
    "    best_exog_cols = []\n",
    "\n",
    "    # pilih kombinasi exog terbaik pakai RMSE_train + AIC_train\n",
    "    for tag, cols in exog_candidates:\n",
    "        b, _ = grid_fit_series_log(\n",
    "            g,\n",
    "            exog_cols=cols if cols else None,\n",
    "            d_fix=d_val,\n",
    "        )\n",
    "        if not b:\n",
    "            continue\n",
    "\n",
    "        if best_rec is None:\n",
    "            best_tag = tag\n",
    "            best_rec = b\n",
    "            best_exog_cols = cols\n",
    "        else:\n",
    "            better = (\n",
    "                (b[\"RMSE_train\"] < best_rec[\"RMSE_train\"]) or\n",
    "                (\n",
    "                    b[\"RMSE_train\"] == best_rec[\"RMSE_train\"]\n",
    "                    and b[\"AIC_train\"] < best_rec[\"AIC_train\"]\n",
    "                )\n",
    "            )\n",
    "            if better:\n",
    "                best_tag = tag\n",
    "                best_rec = b\n",
    "                best_exog_cols = cols\n",
    "\n",
    "    if best_rec is None:\n",
    "        print(f\"[SKIP] {cab}-{sku}: gagal fit (train terlalu pendek atau error).\")\n",
    "        continue\n",
    "\n",
    "    records.append(\n",
    "        {\n",
    "            \"cabang\": cab,\n",
    "            \"sku\": sku,\n",
    "            \"variant\": best_tag + \"+log\",  # penanda bahwa target log1p\n",
    "            \"exog_used\": \",\".join(best_exog_cols) if best_exog_cols else \"(none)\",\n",
    "\n",
    "            \"order\": best_rec[\"order\"],\n",
    "            \"seasonal_order\": best_rec[\"seasonal_order\"],\n",
    "            \"AIC_train\": best_rec[\"AIC_train\"],\n",
    "\n",
    "            \"RMSE_train\": best_rec[\"RMSE_train\"],\n",
    "            \"MSE_train\": best_rec[\"MSE_train\"],\n",
    "            \"MAE_train\": best_rec[\"MAE_train\"],\n",
    "            \"MAPE%_train\": best_rec[\"MAPE_train\"],\n",
    "            \"sMAPE%_train\": best_rec[\"sMAPE_train\"],\n",
    "\n",
    "            \"RMSE_test\": best_rec[\"RMSE_test\"],\n",
    "            \"MSE_test\": best_rec[\"MSE_test\"],\n",
    "            \"MAE_test\": best_rec[\"MAE_test\"],\n",
    "            \"MAPE%_test\": best_rec[\"MAPE_test\"],\n",
    "            \"sMAPE%_test\": best_rec[\"sMAPE_test\"],\n",
    "\n",
    "            \"LB_p12\": best_rec[\"LB_p12\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # simpan pred test kalau ada\n",
    "    m_te = g[\"is_test\"] == 1\n",
    "    if m_te.any() and len(best_rec[\"yhat\"]) > 0:\n",
    "        preds.append(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"periode\": g.loc[m_te, \"periode\"].values,\n",
    "                    \"qty\": g.loc[m_te, \"qty\"].values,\n",
    "                    \"pred\": np.asarray(best_rec[\"yhat\"], float),\n",
    "                    \"cabang\": cab,\n",
    "                    \"sku\": sku,\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "# ---------------- OUTPUT & SAVE ----------------\n",
    "results_df = (\n",
    "    pd.DataFrame(records)\n",
    "    .sort_values([\"cabang\", \"sku\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "forecasts_df = (\n",
    "    pd.concat(preds, ignore_index=True) if len(preds) else pd.DataFrame()\n",
    ")\n",
    "\n",
    "print(\"\\n=== RINGKASAN HASIL (DATASET 15, LOG1P TARGET, TRAIN-ONLY SELECTION) - BEBERAPA BARIS ===\")\n",
    "if not results_df.empty:\n",
    "    print(\n",
    "        results_df[\n",
    "            [\n",
    "                \"cabang\",\n",
    "                \"sku\",\n",
    "                \"variant\",\n",
    "                \"exog_used\",\n",
    "                \"RMSE_train\",\n",
    "                \"MSE_train\",\n",
    "                \"MAE_train\",\n",
    "                \"MAPE%_train\",\n",
    "                \"sMAPE%_train\",\n",
    "                \"RMSE_test\",\n",
    "                \"MSE_test\",\n",
    "                \"MAE_test\",\n",
    "                \"MAPE%_test\",\n",
    "                \"sMAPE%_test\",\n",
    "                \"LB_p12\",\n",
    "            ]\n",
    "        ].head(20).to_string(index=False)\n",
    "    )\n",
    "else:\n",
    "    print(\"Tidak ada hasil. Seri terlalu pendek atau split bermasalah.\")\n",
    "\n",
    "METRICS_PATH = OUT_DIR / \"sarimax_selected15_log_trainselect_metrics.csv\"\n",
    "PREDS_PATH   = OUT_DIR / \"sarimax_selected15_log_trainselect_predictions.csv\"\n",
    "results_df.to_csv(METRICS_PATH, index=False)\n",
    "forecasts_df.to_csv(PREDS_PATH, index=False)\n",
    "print(f\"\\nSaved metrics  -> {METRICS_PATH}\")\n",
    "print(f\"Saved preds    -> {PREDS_PATH}\")\n",
    "\n",
    "# CHARTS (hanya seri dengan test)\n",
    "if not forecasts_df.empty:\n",
    "    for cab, sk in (\n",
    "        forecasts_df[[\"cabang\", \"sku\"]].drop_duplicates().itertuples(\n",
    "            index=False, name=None\n",
    "        )\n",
    "    ):\n",
    "        plot_test_series(forecasts_df, cab, sk, CHART_DIR)\n",
    "    print(f\"Saved charts   -> {CHART_DIR}\")\n",
    "else:\n",
    "    print(\"Tidak ada prediksi test untuk digambar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ad23c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cabang</th>\n",
       "      <th>sku</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>gap_RMSE</th>\n",
       "      <th>ratio_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02A</td>\n",
       "      <td>BNOP400CHAR</td>\n",
       "      <td>626.648831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02A</td>\n",
       "      <td>BNOP400CPOX</td>\n",
       "      <td>626.648831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02A</td>\n",
       "      <td>BUVW001K194</td>\n",
       "      <td>367.585462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02A</td>\n",
       "      <td>BUVW001KSB</td>\n",
       "      <td>526.190981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02A</td>\n",
       "      <td>BUVW001KSBM</td>\n",
       "      <td>344.749376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>02A</td>\n",
       "      <td>BUVW001KSW</td>\n",
       "      <td>1732.555022</td>\n",
       "      <td>1959.400426</td>\n",
       "      <td>226.845404</td>\n",
       "      <td>1.130931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>02A</td>\n",
       "      <td>BUVW100C192</td>\n",
       "      <td>412.246511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>02A</td>\n",
       "      <td>BUVW100CSB</td>\n",
       "      <td>827.895709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>02A</td>\n",
       "      <td>BUVW100CSW</td>\n",
       "      <td>852.590211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>02A</td>\n",
       "      <td>CKLM001KS607</td>\n",
       "      <td>407.764228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>02A</td>\n",
       "      <td>CKLM001KSPOL</td>\n",
       "      <td>226.133436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>02A</td>\n",
       "      <td>DOPQ001K001</td>\n",
       "      <td>488.293116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>02A</td>\n",
       "      <td>DOPQ001K009</td>\n",
       "      <td>955.145802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>02A</td>\n",
       "      <td>FSTU001KSB</td>\n",
       "      <td>332.918799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>02A</td>\n",
       "      <td>FSTU001KSW</td>\n",
       "      <td>465.445029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>05A</td>\n",
       "      <td>BBCD005KSW</td>\n",
       "      <td>618.200186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>05A</td>\n",
       "      <td>BUVW001K194</td>\n",
       "      <td>260.744355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>05A</td>\n",
       "      <td>BUVW001KSB</td>\n",
       "      <td>435.633350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>05A</td>\n",
       "      <td>BUVW001KSW</td>\n",
       "      <td>1769.988435</td>\n",
       "      <td>898.738516</td>\n",
       "      <td>-871.249919</td>\n",
       "      <td>0.507765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>05A</td>\n",
       "      <td>BUVW100C192</td>\n",
       "      <td>471.079920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cabang           sku   RMSE_train    RMSE_test    gap_RMSE  ratio_RMSE\n",
       "0     02A   BNOP400CHAR   626.648831          NaN         NaN         NaN\n",
       "1     02A   BNOP400CPOX   626.648831          NaN         NaN         NaN\n",
       "2     02A   BUVW001K194   367.585462          NaN         NaN         NaN\n",
       "3     02A    BUVW001KSB   526.190981          NaN         NaN         NaN\n",
       "4     02A   BUVW001KSBM   344.749376          NaN         NaN         NaN\n",
       "5     02A    BUVW001KSW  1732.555022  1959.400426  226.845404    1.130931\n",
       "6     02A   BUVW100C192   412.246511          NaN         NaN         NaN\n",
       "7     02A    BUVW100CSB   827.895709          NaN         NaN         NaN\n",
       "8     02A    BUVW100CSW   852.590211          NaN         NaN         NaN\n",
       "9     02A  CKLM001KS607   407.764228          NaN         NaN         NaN\n",
       "10    02A  CKLM001KSPOL   226.133436          NaN         NaN         NaN\n",
       "11    02A   DOPQ001K001   488.293116          NaN         NaN         NaN\n",
       "12    02A   DOPQ001K009   955.145802          NaN         NaN         NaN\n",
       "13    02A    FSTU001KSB   332.918799          NaN         NaN         NaN\n",
       "14    02A    FSTU001KSW   465.445029          NaN         NaN         NaN\n",
       "15    05A    BBCD005KSW   618.200186          NaN         NaN         NaN\n",
       "16    05A   BUVW001K194   260.744355          NaN         NaN         NaN\n",
       "17    05A    BUVW001KSB   435.633350          NaN         NaN         NaN\n",
       "18    05A    BUVW001KSW  1769.988435   898.738516 -871.249919    0.507765\n",
       "19    05A   BUVW100C192   471.079920          NaN         NaN         NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[\"gap_RMSE\"] = results_df[\"RMSE_test\"] - results_df[\"RMSE_train\"]\n",
    "results_df[\"ratio_RMSE\"] = results_df[\"RMSE_test\"] / results_df[\"RMSE_train\"]\n",
    "\n",
    "results_df[[\"cabang\",\"sku\",\"RMSE_train\",\"RMSE_test\",\"gap_RMSE\",\"ratio_RMSE\"]].head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48f07aa",
   "metadata": {},
   "source": [
    "ini sdh sesuai eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8fab2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load panel: D:\\Documents\\Skripsi\\demand-forecasting\\data\\dataset_15\\panel_exog_selected15.csv\n",
      "[INFO] Total baris TEST: 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RINGKASAN HASIL (DATASET 15, LOG1P TARGET, TRAIN-ONLY SELECTION) - BEBERAPA BARIS ===\n",
      "cabang          sku       variant                exog_used  RMSE_train    MSE_train   MAE_train  MAPE%_train  sMAPE%_train   RMSE_test     MSE_test    MAE_test  MAPE%_test  sMAPE%_test   LB_p12\n",
      "   02A  BNOP400CHAR     event+log               event_flag  617.176356 3.809067e+05  468.957887   104.223180     79.433353         NaN          NaN         NaN         NaN          NaN 0.782529\n",
      "   02A  BNOP400CPOX     event+log               event_flag  617.176356 3.809067e+05  468.957887   104.223180     79.433353         NaN          NaN         NaN         NaN          NaN 0.782529\n",
      "   02A  BUVW001K194 event_hol+log event_flag,holiday_count  345.822599 1.195933e+05  275.742308    42.007140     42.059290         NaN          NaN         NaN         NaN          NaN 0.998710\n",
      "   02A   BUVW001KSB     event+log               event_flag  509.742497 2.598374e+05  398.974691    40.786020     42.292550         NaN          NaN         NaN         NaN          NaN 0.889407\n",
      "   02A  BUVW001KSBM event_hol+log event_flag,holiday_count  327.471360 1.072375e+05  245.179561    38.851427     37.640848         NaN          NaN         NaN         NaN          NaN 0.997254\n",
      "   02A   BUVW001KSW event_hol+log event_flag,holiday_count 1706.055001 2.910624e+06 1373.047145    43.920015     39.105414 1932.853510 3.735923e+06 1563.258400   75.074765    52.364063 0.999891\n",
      "   02A  BUVW100C192 event_hol+log event_flag,holiday_count  410.357931 1.683936e+05  299.806780    36.321075     35.374408         NaN          NaN         NaN         NaN          NaN 0.999750\n",
      "   02A   BUVW100CSB event_hol+log event_flag,holiday_count  817.402089 6.681462e+05  600.198880    29.025831     30.129466         NaN          NaN         NaN         NaN          NaN 0.999814\n",
      "   02A   BUVW100CSW event_hol+log event_flag,holiday_count  848.862177 7.205670e+05  611.037153    32.868217     35.448513         NaN          NaN         NaN         NaN          NaN 0.884069\n",
      "   02A CKLM001KS607 event_hol+log event_flag,holiday_count  382.524608 1.463251e+05  294.287018    31.498653     32.107107         NaN          NaN         NaN         NaN          NaN 0.999894\n",
      "   02A CKLM001KSPOL     event+log               event_flag  224.226249 5.027741e+04  183.787378    33.398396     33.669403         NaN          NaN         NaN         NaN          NaN 0.998754\n",
      "   02A  DOPQ001K001 event_hol+log event_flag,holiday_count  472.642046 2.233905e+05  348.557423    43.907619     40.179060         NaN          NaN         NaN         NaN          NaN 0.979337\n",
      "   02A  DOPQ001K009 event_hol+log event_flag,holiday_count  953.485059 9.091338e+05  744.677505    46.172369     40.952375         NaN          NaN         NaN         NaN          NaN 0.981417\n",
      "   02A   FSTU001KSB event_hol+log event_flag,holiday_count  332.541596 1.105839e+05  238.618863    41.281512     39.523587         NaN          NaN         NaN         NaN          NaN 0.874363\n",
      "   02A   FSTU001KSW event_hol+log event_flag,holiday_count  464.545654 2.158027e+05  373.069435    39.715491     36.594535         NaN          NaN         NaN         NaN          NaN 0.990030\n",
      "   05A   BBCD005KSW event_hol+log event_flag,holiday_count  618.296375 3.822904e+05  462.489649    24.611431     25.535423         NaN          NaN         NaN         NaN          NaN 1.000000\n",
      "   05A  BUVW001K194 event_hol+log event_flag,holiday_count  260.374196 6.779472e+04  180.777552    20.012826     22.329970         NaN          NaN         NaN         NaN          NaN 1.000000\n",
      "   05A   BUVW001KSB event_hol+log event_flag,holiday_count  433.559568 1.879739e+05  306.957725    20.028108     22.414969         NaN          NaN         NaN         NaN          NaN 0.999999\n",
      "   05A   BUVW001KSW event_hol+log event_flag,holiday_count 1758.308890 3.091650e+06 1205.518275    21.137154     22.993602  897.885115 8.061977e+05  683.149805   14.958853    16.757981 1.000000\n",
      "   05A  BUVW100C192 event_hol+log event_flag,holiday_count  446.695328 1.995367e+05  287.276685    36.472119     37.194105         NaN          NaN         NaN         NaN          NaN 0.999032\n",
      "\n",
      "Saved metrics  -> D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_log_trainselect\\sarimax_15_log_trainselect_metrics.csv\n",
      "Saved preds    -> D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_log_trainselect\\sarimax_15_log_trainselect_predictions.csv\n",
      "Saved charts   -> D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_log_trainselect\\charts\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# SARIMAX BASELINE (DATASET 15) - LOG1P(QTY) - INI YANG DIPAKE ***\n",
    "# - Dataset: panel_exog_selected15.csv\n",
    "# - Target: log1p(qty), evaluasi di level qty\n",
    "# - Seleksi model:\n",
    "#       Utama  : RMSE_train (lebih kecil lebih baik)\n",
    "#       Tie-break: AIC_train (lebih kecil lebih baik)\n",
    "# - Kombinasi exog:\n",
    "#       (1) none\n",
    "#       (2) event_flag\n",
    "#       (3) event_flag + holiday_count\n",
    "#       (4) event_flag + holiday_count + rainfall_lag1 (kalau ada)\n",
    "# - Tidak ada data test dipakai di training / seleksi\n",
    "# =========================================================\n",
    "import itertools\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------------- PATH ----------------\n",
    "PROJECT_ROOT = Path(r\"D:\\Documents\\Skripsi\\demand-forecasting\")\n",
    "\n",
    "DATA_PATH    = PROJECT_ROOT / \"data\" / \"dataset_15\" / \"panel_exog_selected15.csv\"\n",
    "PROFILE_PATH = PROJECT_ROOT / \"data\" / \"dataset_15\" / \"model_profiles_selected15.csv\"\n",
    "\n",
    "OUT_DIR   = PROJECT_ROOT / \"outputs\" / \"sarimax_15_log_trainselect\"\n",
    "CHART_DIR = OUT_DIR / \"charts\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CHART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------- LOAD ----------------\n",
    "print(\"Load panel:\", DATA_PATH)\n",
    "df = (\n",
    "    pd.read_csv(DATA_PATH, parse_dates=[\"periode\"])\n",
    "      .sort_values([\"cabang\", \"sku\", \"periode\"])\n",
    ")\n",
    "\n",
    "profiles = pd.read_csv(PROFILE_PATH)\n",
    "\n",
    "# map d_suggest per (cabang, sku) dari model_profiles\n",
    "if \"sarimax_d_sug\" in profiles.columns:\n",
    "    d_suggest_map = dict(\n",
    "        zip(\n",
    "            zip(profiles[\"cabang\"], profiles[\"sku\"]),\n",
    "            profiles[\"sarimax_d_sug\"].astype(int),\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(\"[WARN] Kolom sarimax_d_sug tidak ada di model_profiles. Pakai d=1 semua.\")\n",
    "    d_suggest_map = {}\n",
    "\n",
    "# ---------------- QUICK SANITY ----------------\n",
    "expected_cols = [\n",
    "    \"cabang\",\n",
    "    \"sku\",\n",
    "    \"periode\",\n",
    "    \"qty\",\n",
    "    \"event_flag\",\n",
    "    \"holiday_count\",\n",
    "    \"rainfall_lag1\",\n",
    "    \"is_train\",\n",
    "    \"is_test\",\n",
    "]\n",
    "missing = [c for c in expected_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Kolom wajib hilang: {missing}\")\n",
    "\n",
    "dups = df.duplicated(subset=[\"cabang\", \"sku\", \"periode\"]).sum()\n",
    "if dups:\n",
    "    raise ValueError(f\"Duplikat (cabang, sku, periode): {dups} baris\")\n",
    "\n",
    "test_total = int((df[\"is_test\"] == 1).sum())\n",
    "print(f\"[INFO] Total baris TEST: {test_total}\")\n",
    "\n",
    "for c in [\"qty\", \"event_flag\", \"holiday_count\", \"rainfall_lag1\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# ---------------- METRICS ----------------\n",
    "def mse(a, f):\n",
    "    a, f = np.asarray(a, float), np.asarray(f, float)\n",
    "    return float(np.mean((a - f) ** 2))\n",
    "\n",
    "def mape(a, f):\n",
    "    a, f = np.asarray(a, float), np.asarray(f, float)\n",
    "    mask = a != 0\n",
    "    return float(np.mean(np.abs((a[mask] - f[mask]) / a[mask])) * 100) if mask.any() else np.nan\n",
    "\n",
    "def smape(a, f):\n",
    "    a, f = np.asarray(a, float), np.asarray(f, float)\n",
    "    denom = (np.abs(a) + np.abs(f)) / 2.0\n",
    "    mask = denom != 0\n",
    "    return float(np.mean(np.abs(a[mask] - f[mask]) / denom[mask]) * 100) if mask.any() else np.nan\n",
    "\n",
    "# ---------------- PARAM GRID ----------------\n",
    "def param_grid_small(d_fix=None):\n",
    "    \"\"\"\n",
    "    Grid kecil untuk (p,d,q) dan (P,D,Q,12).\n",
    "    Kalau d_fix tidak None, pakai hanya d_fix.\n",
    "    \"\"\"\n",
    "    yielded = set()\n",
    "    d_values = [0, 1] if d_fix is None else [int(d_fix)]\n",
    "\n",
    "    for p, d, q in itertools.product([0, 1, 2], d_values, [0, 1, 2]):\n",
    "        for P, D, Q in itertools.product([0, 1], [0, 1], [0, 1]):\n",
    "            # batasi kompleksitas sedikit supaya nggak barbar\n",
    "            if (p + q + P + Q) <= 6:\n",
    "                od, sod = (p, d, q), (P, D, Q, 12)\n",
    "                if (od, sod) in yielded:\n",
    "                    continue\n",
    "                yielded.add((od, sod))\n",
    "                yield od, sod\n",
    "\n",
    "# ---------------- FIT 1 KANDIDAT (SELALU LOG1P) ----------------\n",
    "def fit_eval_log(y_tr, X_tr, y_te, X_te, order, sorder):\n",
    "    \"\"\"\n",
    "    Train SARIMAX dengan target log1p(y), evaluasi di level qty.\n",
    "    Seleksi pakai RMSE_train + AIC_train, test cuma buat laporan.\n",
    "    \"\"\"\n",
    "    # transform target\n",
    "    ytr_log = np.log1p(np.clip(y_tr, a_min=0, a_max=None))\n",
    "\n",
    "    model = SARIMAX(\n",
    "        ytr_log,\n",
    "        exog=X_tr,\n",
    "        order=order,\n",
    "        seasonal_order=sorder,\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False,\n",
    "    )\n",
    "    res = model.fit(disp=False)\n",
    "\n",
    "    # fitted (train) di log, balik ke level\n",
    "    fitted_tr_log = res.fittedvalues\n",
    "    n_tr = min(len(y_tr), len(fitted_tr_log))\n",
    "    y_tr_cut = y_tr[-n_tr:]\n",
    "    fitted_tr_log = np.asarray(fitted_tr_log[-n_tr:], float)\n",
    "    fitted_tr = np.expm1(fitted_tr_log)\n",
    "\n",
    "    rmse_train = float(np.sqrt(np.mean((y_tr_cut - fitted_tr) ** 2)))\n",
    "    mse_train  = mse(y_tr_cut, fitted_tr)\n",
    "    mae_train  = float(np.mean(np.abs(y_tr_cut - fitted_tr)))\n",
    "    mape_train = mape(y_tr_cut, fitted_tr)\n",
    "    smape_train = smape(y_tr_cut, fitted_tr)\n",
    "\n",
    "    # forecast test (hanya evaluasi, tidak mempengaruhi seleksi)\n",
    "    if y_te is not None and len(y_te) > 0:\n",
    "        fh = len(y_te)\n",
    "        pred_log = res.get_forecast(steps=fh, exog=X_te).predicted_mean\n",
    "        yhat = np.expm1(pred_log)\n",
    "\n",
    "        rmse_test = float(np.sqrt(np.mean((y_te - yhat) ** 2)))\n",
    "        mse_test  = mse(y_te, yhat)\n",
    "        mae_test  = float(np.mean(np.abs(y_te - yhat)))\n",
    "        mape_test = mape(y_te, yhat)\n",
    "        smape_test = smape(y_te, yhat)\n",
    "    else:\n",
    "        yhat = np.array([], float)\n",
    "        rmse_test = np.nan\n",
    "        mse_test  = np.nan\n",
    "        mae_test  = np.nan\n",
    "        mape_test = np.nan\n",
    "        smape_test = np.nan\n",
    "\n",
    "    resid = res.resid\n",
    "    try:\n",
    "        lb_p = float(\n",
    "            acorr_ljungbox(resid, lags=[12], return_df=True)[\"lb_pvalue\"].iloc[-1]\n",
    "        )\n",
    "    except Exception:\n",
    "        lb_p = np.nan\n",
    "\n",
    "    return dict(\n",
    "        order=order,\n",
    "        seasonal_order=sorder,\n",
    "        AIC_train=float(res.aic),\n",
    "\n",
    "        RMSE_train=rmse_train,\n",
    "        MSE_train=mse_train,\n",
    "        MAE_train=mae_train,\n",
    "        MAPE_train=mape_train,\n",
    "        sMAPE_train=smape_train,\n",
    "\n",
    "        RMSE_test=rmse_test,\n",
    "        MSE_test=mse_test,\n",
    "        MAE_test=mae_test,\n",
    "        MAPE_test=mape_test,\n",
    "        sMAPE_test=smape_test,\n",
    "\n",
    "        LB_p12=lb_p,\n",
    "        yhat=yhat,\n",
    "    )\n",
    "\n",
    "# ---------------- GRID 1 SERI + 1 VARIAN EXOG ----------------\n",
    "def grid_fit_series_log(g, exog_cols=None, d_fix=None):\n",
    "    \"\"\"\n",
    "    Grid search untuk 1 seri (cabang, sku) dan 1 set exog_cols tertentu.\n",
    "    Target selalu log1p.\n",
    "\n",
    "    PEMILIHAN MODEL:\n",
    "      - Utama: RMSE_train (lebih kecil lebih baik)\n",
    "      - Tie-break: AIC_train (lebih kecil lebih baik)\n",
    "    \"\"\"\n",
    "    g = g.sort_values(\"periode\").copy()\n",
    "    y = g[\"qty\"].astype(float).values\n",
    "    X = g[exog_cols].astype(float).values if exog_cols else None\n",
    "\n",
    "    m_tr = g[\"is_train\"].astype(bool).values\n",
    "    m_te = g[\"is_test\"].astype(bool).values\n",
    "\n",
    "    y_tr = y[m_tr]\n",
    "    y_te = y[m_te]\n",
    "    X_tr = X[m_tr] if X is not None else None\n",
    "    X_te = X[m_te] if X is not None else None\n",
    "\n",
    "    # bersihkan NaN di train\n",
    "    if X_tr is not None:\n",
    "        ok = ~np.isnan(y_tr)\n",
    "        y_tr, X_tr = y_tr[ok], X_tr[ok]\n",
    "        ok = ~np.isnan(X_tr).any(axis=1)\n",
    "        y_tr, X_tr = y_tr[ok], X_tr[ok]\n",
    "    else:\n",
    "        y_tr = y_tr[~np.isnan(y_tr)]\n",
    "\n",
    "    if len(y_tr) < 24:\n",
    "        return None, pd.DataFrame()\n",
    "\n",
    "    # bersihkan test exog kalau ada (cuma untuk evaluasi)\n",
    "    if X_te is not None and len(X_te) > 0:\n",
    "        ok_te = ~np.isnan(X_te).any(axis=1)\n",
    "        y_te = y_te[ok_te]\n",
    "        X_te = X_te[ok_te]\n",
    "\n",
    "    tried, best = [], None\n",
    "    for od, sod in param_grid_small(d_fix=d_fix):\n",
    "        try:\n",
    "            rec = fit_eval_log(y_tr, X_tr, y_te, X_te, od, sod)\n",
    "            tried.append(\n",
    "                {\n",
    "                    k: rec[k]\n",
    "                    for k in [\n",
    "                        \"order\",\n",
    "                        \"seasonal_order\",\n",
    "                        \"AIC_train\",\n",
    "                        \"RMSE_train\",\n",
    "                        \"MSE_train\",\n",
    "                        \"MAE_train\",\n",
    "                        \"MAPE_train\",\n",
    "                        \"sMAPE_train\",\n",
    "                        \"RMSE_test\",\n",
    "                        \"MSE_test\",\n",
    "                        \"MAE_test\",\n",
    "                        \"MAPE_test\",\n",
    "                        \"sMAPE_test\",\n",
    "                        \"LB_p12\",\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # SELEKSI model: hanya pakai RMSE_train + AIC_train\n",
    "            if best is None:\n",
    "                best = rec\n",
    "            else:\n",
    "                better = (\n",
    "                    (rec[\"RMSE_train\"] < best[\"RMSE_train\"]) or\n",
    "                    (\n",
    "                        rec[\"RMSE_train\"] == best[\"RMSE_train\"]\n",
    "                        and rec[\"AIC_train\"] < best[\"AIC_train\"]\n",
    "                    )\n",
    "                )\n",
    "                if better:\n",
    "                    best = rec\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    tried_df = (\n",
    "        pd.DataFrame(tried)\n",
    "        .sort_values([\"RMSE_train\", \"AIC_train\"])\n",
    "        .reset_index(drop=True)\n",
    "        if tried\n",
    "        else pd.DataFrame()\n",
    "    )\n",
    "    return best, tried_df\n",
    "\n",
    "# ---------------- PLOT TEST ----------------\n",
    "def plot_test_series(preds_df, cabang, sku, out_dir: Path):\n",
    "    d = preds_df[(preds_df[\"cabang\"] == cabang) & (preds_df[\"sku\"] == sku)].copy()\n",
    "    if d.empty:\n",
    "        return\n",
    "    d = d.sort_values(\"periode\")\n",
    "    d[\"periode\"] = pd.to_datetime(d[\"periode\"])\n",
    "    rmse_val = float(np.sqrt(np.mean((d[\"qty\"].values - d[\"pred\"].values) ** 2)))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10.5, 3.6))\n",
    "    locator = mdates.MonthLocator(interval=1)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(mdates.ConciseDateFormatter(locator))\n",
    "    ax.plot(d[\"periode\"], d[\"qty\"], lw=1.8, marker=\"o\", label=\"Actual\")\n",
    "    ax.plot(d[\"periode\"], d[\"pred\"], lw=1.8, marker=\"s\", label=\"Pred\")\n",
    "    ax.set_title(f\"{cabang}-{sku} | RMSE_test={rmse_val:.1f}\")\n",
    "    ax.set_xlabel(\"Periode\")\n",
    "    ax.set_ylabel(\"Qty\")\n",
    "    ax.grid(True, axis=\"y\", alpha=0.25)\n",
    "    ax.legend(loc=\"center left\", bbox_to_anchor=(1.02, 0.5), frameon=False)\n",
    "    fig.tight_layout(rect=[0, 0, 0.82, 1])\n",
    "    fpath = out_dir / f\"test_plot__{cabang}__{sku}.png\"\n",
    "    fig.savefig(fpath, dpi=160)\n",
    "    plt.close(fig)\n",
    "\n",
    "# ---------------- LOOP PER SERI ----------------\n",
    "records, preds = [], []\n",
    "\n",
    "pairs = (\n",
    "    df[[\"cabang\", \"sku\"]]\n",
    "    .drop_duplicates()\n",
    "    .itertuples(index=False, name=None)\n",
    ")\n",
    "\n",
    "for cab, sku in pairs:\n",
    "    g = df[(df[\"cabang\"] == cab) & (df[\"sku\"] == sku)].copy()\n",
    "\n",
    "    d_val = int(d_suggest_map.get((cab, sku), 1))\n",
    "\n",
    "    # kandidat exog persis sesuai spek\n",
    "    exog_candidates = []\n",
    "    exog_candidates.append((\"none\", []))\n",
    "    exog_candidates.append((\"event\", [\"event_flag\"]))\n",
    "    exog_candidates.append((\"event_hol\", [\"event_flag\", \"holiday_count\"]))\n",
    "    exog_candidates.append(\n",
    "        (\"event_hol_rain\", [\"event_flag\", \"holiday_count\", \"rainfall_lag1\"])\n",
    "    )\n",
    "\n",
    "    best_tag = None\n",
    "    best_rec = None\n",
    "    best_exog_cols = []\n",
    "\n",
    "    # pilih kombinasi exog terbaik pakai RMSE_train + AIC_train\n",
    "    for tag, cols in exog_candidates:\n",
    "        # pastikan kolomnya memang ada\n",
    "        if cols and not set(cols).issubset(g.columns):\n",
    "            continue\n",
    "\n",
    "        b, _ = grid_fit_series_log(\n",
    "            g,\n",
    "            exog_cols=cols if cols else None,\n",
    "            d_fix=d_val,\n",
    "        )\n",
    "        if not b:\n",
    "            continue\n",
    "\n",
    "        if best_rec is None:\n",
    "            best_tag = tag\n",
    "            best_rec = b\n",
    "            best_exog_cols = cols\n",
    "        else:\n",
    "            better = (\n",
    "                (b[\"RMSE_train\"] < best_rec[\"RMSE_train\"]) or\n",
    "                (\n",
    "                    b[\"RMSE_train\"] == best_rec[\"RMSE_train\"]\n",
    "                    and b[\"AIC_train\"] < best_rec[\"AIC_train\"]\n",
    "                )\n",
    "            )\n",
    "            if better:\n",
    "                best_tag = tag\n",
    "                best_rec = b\n",
    "                best_exog_cols = cols\n",
    "\n",
    "    if best_rec is None:\n",
    "        print(f\"[SKIP] {cab}-{sku}: gagal fit (train terlalu pendek atau error).\")\n",
    "        continue\n",
    "\n",
    "    records.append(\n",
    "        {\n",
    "            \"cabang\": cab,\n",
    "            \"sku\": sku,\n",
    "            \"variant\": best_tag + \"+log\",  # penanda bahwa target log1p\n",
    "            \"exog_used\": \",\".join(best_exog_cols) if best_exog_cols else \"(none)\",\n",
    "\n",
    "            \"order\": best_rec[\"order\"],\n",
    "            \"seasonal_order\": best_rec[\"seasonal_order\"],\n",
    "            \"AIC_train\": best_rec[\"AIC_train\"],\n",
    "\n",
    "            \"RMSE_train\": best_rec[\"RMSE_train\"],\n",
    "            \"MSE_train\": best_rec[\"MSE_train\"],\n",
    "            \"MAE_train\": best_rec[\"MAE_train\"],\n",
    "            \"MAPE%_train\": best_rec[\"MAPE_train\"],\n",
    "            \"sMAPE%_train\": best_rec[\"sMAPE_train\"],\n",
    "\n",
    "            \"RMSE_test\": best_rec[\"RMSE_test\"],\n",
    "            \"MSE_test\": best_rec[\"MSE_test\"],\n",
    "            \"MAE_test\": best_rec[\"MAE_test\"],\n",
    "            \"MAPE%_test\": best_rec[\"MAPE_test\"],\n",
    "            \"sMAPE%_test\": best_rec[\"sMAPE_test\"],\n",
    "\n",
    "            \"LB_p12\": best_rec[\"LB_p12\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # simpan pred test kalau ada\n",
    "    m_te = g[\"is_test\"] == 1\n",
    "    if m_te.any() and len(best_rec[\"yhat\"]) > 0:\n",
    "        preds.append(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"periode\": g.loc[m_te, \"periode\"].values,\n",
    "                    \"qty\": g.loc[m_te, \"qty\"].values,\n",
    "                    \"pred\": np.asarray(best_rec[\"yhat\"], float),\n",
    "                    \"cabang\": cab,\n",
    "                    \"sku\": sku,\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "# ---------------- OUTPUT & SAVE ----------------\n",
    "results_df = (\n",
    "    pd.DataFrame(records)\n",
    "    .sort_values([\"cabang\", \"sku\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "forecasts_df = (\n",
    "    pd.concat(preds, ignore_index=True) if len(preds) else pd.DataFrame()\n",
    ")\n",
    "\n",
    "print(\"\\n=== RINGKASAN HASIL (DATASET 15, LOG1P TARGET, TRAIN-ONLY SELECTION) - BEBERAPA BARIS ===\")\n",
    "if not results_df.empty:\n",
    "    print(\n",
    "        results_df[\n",
    "            [\n",
    "                \"cabang\",\n",
    "                \"sku\",\n",
    "                \"variant\",\n",
    "                \"exog_used\",\n",
    "                \"RMSE_train\",\n",
    "                \"MSE_train\",\n",
    "                \"MAE_train\",\n",
    "                \"MAPE%_train\",\n",
    "                \"sMAPE%_train\",\n",
    "                \"RMSE_test\",\n",
    "                \"MSE_test\",\n",
    "                \"MAE_test\",\n",
    "                \"MAPE%_test\",\n",
    "                \"sMAPE%_test\",\n",
    "                \"LB_p12\",\n",
    "            ]\n",
    "        ].head(20).to_string(index=False)\n",
    "    )\n",
    "else:\n",
    "    print(\"Tidak ada hasil. Seri terlalu pendek atau split bermasalah.\")\n",
    "\n",
    "METRICS_PATH = OUT_DIR / \"sarimax_15_log_trainselect_metrics.csv\"\n",
    "PREDS_PATH   = OUT_DIR / \"sarimax_15_log_trainselect_predictions.csv\"\n",
    "results_df.to_csv(METRICS_PATH, index=False)\n",
    "forecasts_df.to_csv(PREDS_PATH, index=False)\n",
    "print(f\"\\nSaved metrics  -> {METRICS_PATH}\")\n",
    "print(f\"Saved preds    -> {PREDS_PATH}\")\n",
    "\n",
    "# CHARTS (hanya seri dengan test)\n",
    "if not forecasts_df.empty:\n",
    "    for cab, sk in (\n",
    "        forecasts_df[[\"cabang\", \"sku\"]].drop_duplicates().itertuples(\n",
    "            index=False, name=None\n",
    "        )\n",
    "    ):\n",
    "        plot_test_series(forecasts_df, cab, sk, CHART_DIR)\n",
    "    print(f\"Saved charts   -> {CHART_DIR}\")\n",
    "else:\n",
    "    print(\"Tidak ada prediksi test untuk digambar.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c46326a",
   "metadata": {},
   "source": [
    "ini coba pake qty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b650eee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load panel: D:\\Documents\\Skripsi\\demand-forecasting\\data\\dataset_15\\panel_exog_selected15.csv\n",
      "[INFO] Total baris TEST: 45\n",
      "\n",
      "=== RINGKASAN HASIL (DATASET 15, LEVEL TARGET, TRAIN-ONLY SELECTION) - BEBERAPA BARIS ===\n",
      "cabang          sku         variant                exog_used  RMSE_train    MSE_train   MAE_train  MAPE%_train  sMAPE%_train   RMSE_test     MSE_test    MAE_test  MAPE%_test  sMAPE%_test   LB_p12\n",
      "   02A  BNOP400CHAR     event+level               event_flag  654.381503 4.282152e+05  459.514656   116.739384     69.970671         NaN          NaN         NaN         NaN          NaN 0.971238\n",
      "   02A  BNOP400CPOX     event+level               event_flag  654.381503 4.282152e+05  459.514656   116.739384     69.970671         NaN          NaN         NaN         NaN          NaN 0.971238\n",
      "   02A  BUVW001K194     event+level               event_flag  344.350856 1.185775e+05  279.314674    45.183665     42.549927         NaN          NaN         NaN         NaN          NaN 0.706695\n",
      "   02A   BUVW001KSB event_hol+level event_flag,holiday_count  534.003095 2.851593e+05  423.344046    43.458230     45.205089         NaN          NaN         NaN         NaN          NaN 0.850541\n",
      "   02A  BUVW001KSBM     event+level               event_flag  325.211223 1.057623e+05  237.305846    36.949815     38.231958         NaN          NaN         NaN         NaN          NaN 0.268183\n",
      "   02A   BUVW001KSW event_hol+level event_flag,holiday_count 1704.128350 2.904053e+06 1347.371661    45.481190     39.111025 2048.925400 4.198095e+06 1762.308355   90.571302    56.839945 0.477553\n",
      "   02A  BUVW100C192      none+level                   (none)  411.786983 1.695685e+05  315.370993    40.670681     37.447220         NaN          NaN         NaN         NaN          NaN 0.235439\n",
      "   02A   BUVW100CSB      none+level                   (none)  773.531544 5.983510e+05  534.034258    26.018934     27.281238         NaN          NaN         NaN         NaN          NaN 0.479070\n",
      "   02A   BUVW100CSW      none+level                   (none)  819.030678 6.708113e+05  618.531550    35.294167     34.165597         NaN          NaN         NaN         NaN          NaN 0.726148\n",
      "   02A CKLM001KS607 event_hol+level event_flag,holiday_count  404.737546 1.638125e+05  309.132212    31.690451     35.491614         NaN          NaN         NaN         NaN          NaN 0.828083\n",
      "   02A CKLM001KSPOL      none+level                   (none)  225.553917 5.087457e+04  182.884334    35.088793     33.085072         NaN          NaN         NaN         NaN          NaN 0.705886\n",
      "   02A  DOPQ001K001 event_hol+level event_flag,holiday_count  479.073176 2.295111e+05  376.486111    48.496531     43.172051         NaN          NaN         NaN         NaN          NaN 0.055899\n",
      "   02A  DOPQ001K009      none+level                   (none)  982.486383 9.652795e+05  832.572406    55.603114     44.910874         NaN          NaN         NaN         NaN          NaN 0.122091\n",
      "   02A   FSTU001KSB event_hol+level event_flag,holiday_count  332.965444 1.108660e+05  252.232000    46.699846     39.857318         NaN          NaN         NaN         NaN          NaN 0.594057\n",
      "   02A   FSTU001KSW event_hol+level event_flag,holiday_count  454.128189 2.062324e+05  375.930389    45.999981     38.117325         NaN          NaN         NaN         NaN          NaN 0.473309\n",
      "   05A   BBCD005KSW     event+level               event_flag  590.058927 3.481695e+05  450.916833    23.414582     25.265966         NaN          NaN         NaN         NaN          NaN 0.091925\n",
      "   05A  BUVW001K194      none+level                   (none)  278.379254 7.749501e+04  197.809709    22.503821     24.543219         NaN          NaN         NaN         NaN          NaN 0.948184\n",
      "   05A   BUVW001KSB      none+level                   (none)  467.102995 2.181852e+05  343.810307    22.436132     24.498570         NaN          NaN         NaN         NaN          NaN 0.785239\n",
      "   05A   BUVW001KSW     event+level               event_flag 1793.295523 3.215909e+06 1290.538373    22.964797     24.546576 1024.704754 1.050020e+06  926.241809   21.415802    22.607341 0.532755\n",
      "   05A  BUVW100C192      none+level                   (none)  336.698693 1.133660e+05  243.585912    34.461653     35.418928         NaN          NaN         NaN         NaN          NaN 0.422710\n",
      "\n",
      "Saved metrics  -> D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_level_trainselect\\sarimax_15_level_trainselect_metrics.csv\n",
      "Saved preds    -> D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_level_trainselect\\sarimax_15_level_trainselect_predictions.csv\n",
      "Saved charts   -> D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_level_trainselect\\charts\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# SARIMAX BASELINE (DATASET 15) - LEVEL(QTY)\n",
    "# - Dataset: panel_exog_selected15.csv\n",
    "# - Target: qty (level), evaluasi di level qty\n",
    "# - Seleksi model:\n",
    "#       Utama  : RMSE_train (lebih kecil lebih baik)\n",
    "#       Tie-break: AIC_train (lebih kecil lebih baik)\n",
    "# - Kombinasi exog:\n",
    "#       (1) none\n",
    "#       (2) event_flag\n",
    "#       (3) event_flag + holiday_count\n",
    "#       (4) event_flag + holiday_count + rainfall_lag1\n",
    "# =========================================================\n",
    "\n",
    "import itertools\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------------- PATH ----------------\n",
    "PROJECT_ROOT = Path(r\"D:\\Documents\\Skripsi\\demand-forecasting\")\n",
    "\n",
    "DATA_PATH    = PROJECT_ROOT / \"data\" / \"dataset_15\" / \"panel_exog_selected15.csv\"\n",
    "PROFILE_PATH = PROJECT_ROOT / \"data\" / \"dataset_15\" / \"model_profiles_selected15.csv\"\n",
    "\n",
    "OUT_DIR   = PROJECT_ROOT / \"outputs\" / \"sarimax_15_level_trainselect\"\n",
    "CHART_DIR = OUT_DIR / \"charts\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CHART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------- LOAD ----------------\n",
    "print(\"Load panel:\", DATA_PATH)\n",
    "df = (\n",
    "    pd.read_csv(DATA_PATH, parse_dates=[\"periode\"])\n",
    "      .sort_values([\"cabang\", \"sku\", \"periode\"])\n",
    ")\n",
    "\n",
    "profiles = pd.read_csv(PROFILE_PATH)\n",
    "\n",
    "# map d_suggest per (cabang, sku) dari model_profiles\n",
    "if \"sarimax_d_sug\" in profiles.columns:\n",
    "    d_suggest_map = dict(\n",
    "        zip(\n",
    "            zip(profiles[\"cabang\"], profiles[\"sku\"]),\n",
    "            profiles[\"sarimax_d_sug\"].astype(int),\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(\"[WARN] Kolom sarimax_d_sug tidak ada di model_profiles. Pakai d=1 semua.\")\n",
    "    d_suggest_map = {}\n",
    "\n",
    "# ---------------- QUICK SANITY ----------------\n",
    "expected_cols = [\n",
    "    \"cabang\",\n",
    "    \"sku\",\n",
    "    \"periode\",\n",
    "    \"qty\",\n",
    "    \"event_flag\",\n",
    "    \"holiday_count\",\n",
    "    \"rainfall_lag1\",\n",
    "    \"is_train\",\n",
    "    \"is_test\",\n",
    "]\n",
    "missing = [c for c in expected_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Kolom wajib hilang: {missing}\")\n",
    "\n",
    "dups = df.duplicated(subset=[\"cabang\", \"sku\", \"periode\"]).sum()\n",
    "if dups:\n",
    "    raise ValueError(f\"Duplikat (cabang, sku, periode): {dups} baris\")\n",
    "\n",
    "test_total = int((df[\"is_test\"] == 1).sum())\n",
    "print(f\"[INFO] Total baris TEST: {test_total}\")\n",
    "\n",
    "for c in [\"qty\", \"event_flag\", \"holiday_count\", \"rainfall_lag1\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# ---------------- METRICS ----------------\n",
    "def mse(a, f):\n",
    "    a, f = np.asarray(a, float), np.asarray(f, float)\n",
    "    return float(np.mean((a - f) ** 2))\n",
    "\n",
    "def mape(a, f):\n",
    "    a, f = np.asarray(a, float), np.asarray(f, float)\n",
    "    mask = a != 0\n",
    "    return float(np.mean(np.abs((a[mask] - f[mask]) / a[mask])) * 100) if mask.any() else np.nan\n",
    "\n",
    "def smape(a, f):\n",
    "    a, f = np.asarray(a, float), np.asarray(f, float)\n",
    "    denom = (np.abs(a) + np.abs(f)) / 2.0\n",
    "    mask = denom != 0\n",
    "    return float(np.mean(np.abs(a[mask] - f[mask]) / denom[mask]) * 100) if mask.any() else np.nan\n",
    "\n",
    "# ---------------- PARAM GRID ----------------\n",
    "def param_grid_small(d_fix=None):\n",
    "    \"\"\"\n",
    "    Grid kecil untuk (p,d,q) dan (P,D,Q,12).\n",
    "    Kalau d_fix tidak None, pakai hanya d_fix.\n",
    "    \"\"\"\n",
    "    yielded = set()\n",
    "    d_values = [0, 1] if d_fix is None else [int(d_fix)]\n",
    "\n",
    "    for p, d, q in itertools.product([0, 1, 2], d_values, [0, 1, 2]):\n",
    "        for P, D, Q in itertools.product([0, 1], [0, 1], [0, 1]):\n",
    "            if (p + q + P + Q) <= 6:\n",
    "                od, sod = (p, d, q), (P, D, Q, 12)\n",
    "                if (od, sod) in yielded:\n",
    "                    continue\n",
    "                yielded.add((od, sod))\n",
    "                yield od, sod\n",
    "\n",
    "# ---------------- FIT 1 KANDIDAT (LEVEL QTY) ----------------\n",
    "def fit_eval_level(y_tr, X_tr, y_te, X_te, order, sorder):\n",
    "    \"\"\"\n",
    "    Train SARIMAX dengan target qty level, evaluasi di level qty.\n",
    "    Seleksi pakai RMSE_train + AIC_train, test cuma buat laporan.\n",
    "    \"\"\"\n",
    "    ytr = np.asarray(y_tr, float)\n",
    "\n",
    "    model = SARIMAX(\n",
    "        ytr,\n",
    "        exog=X_tr,\n",
    "        order=order,\n",
    "        seasonal_order=sorder,\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False,\n",
    "    )\n",
    "    res = model.fit(disp=False)\n",
    "\n",
    "    # fitted train di level\n",
    "    fitted_tr = np.asarray(res.fittedvalues, float)\n",
    "    n_tr = min(len(ytr), len(fitted_tr))\n",
    "    y_tr_cut = ytr[-n_tr:]\n",
    "    fitted_tr = fitted_tr[-n_tr:]\n",
    "\n",
    "    rmse_train = float(np.sqrt(np.mean((y_tr_cut - fitted_tr) ** 2)))\n",
    "    mse_train  = mse(y_tr_cut, fitted_tr)\n",
    "    mae_train  = float(np.mean(np.abs(y_tr_cut - fitted_tr)))\n",
    "    mape_train = mape(y_tr_cut, fitted_tr)\n",
    "    smape_train = smape(y_tr_cut, fitted_tr)\n",
    "\n",
    "    # forecast test (level)\n",
    "    if y_te is not None and len(y_te) > 0:\n",
    "        fh = len(y_te)\n",
    "        pred = res.get_forecast(steps=fh, exog=X_te).predicted_mean\n",
    "        yhat = np.asarray(pred, float)\n",
    "\n",
    "        rmse_test = float(np.sqrt(np.mean((y_te - yhat) ** 2)))\n",
    "        mse_test  = mse(y_te, yhat)\n",
    "        mae_test  = float(np.mean(np.abs(y_te - yhat)))\n",
    "        mape_test = mape(y_te, yhat)\n",
    "        smape_test = smape(y_te, yhat)\n",
    "    else:\n",
    "        yhat = np.array([], float)\n",
    "        rmse_test = np.nan\n",
    "        mse_test  = np.nan\n",
    "        mae_test  = np.nan\n",
    "        mape_test = np.nan\n",
    "        smape_test = np.nan\n",
    "\n",
    "    resid = res.resid\n",
    "    try:\n",
    "        lb_p = float(\n",
    "            acorr_ljungbox(resid, lags=[12], return_df=True)[\"lb_pvalue\"].iloc[-1]\n",
    "        )\n",
    "    except Exception:\n",
    "        lb_p = np.nan\n",
    "\n",
    "    return dict(\n",
    "        order=order,\n",
    "        seasonal_order=sorder,\n",
    "        AIC_train=float(res.aic),\n",
    "\n",
    "        RMSE_train=rmse_train,\n",
    "        MSE_train=mse_train,\n",
    "        MAE_train=mae_train,\n",
    "        MAPE_train=mape_train,\n",
    "        sMAPE_train=smape_train,\n",
    "\n",
    "        RMSE_test=rmse_test,\n",
    "        MSE_test=mse_test,\n",
    "        MAE_test=mae_test,\n",
    "        MAPE_test=mape_test,\n",
    "        sMAPE_test=smape_test,\n",
    "\n",
    "        LB_p12=lb_p,\n",
    "        yhat=yhat,\n",
    "    )\n",
    "\n",
    "# ---------------- GRID 1 SERI + 1 VARIAN EXOG ----------------\n",
    "def grid_fit_series_level(g, exog_cols=None, d_fix=None):\n",
    "    \"\"\"\n",
    "    Grid search untuk 1 seri (cabang, sku) dan 1 set exog_cols tertentu.\n",
    "    Target qty level.\n",
    "\n",
    "    PEMILIHAN MODEL:\n",
    "      - Utama: RMSE_train (lebih kecil lebih baik)\n",
    "      - Tie-break: AIC_train (lebih kecil lebih baik)\n",
    "    \"\"\"\n",
    "    g = g.sort_values(\"periode\").copy()\n",
    "    y = g[\"qty\"].astype(float).values\n",
    "    X = g[exog_cols].astype(float).values if exog_cols else None\n",
    "\n",
    "    m_tr = g[\"is_train\"].astype(bool).values\n",
    "    m_te = g[\"is_test\"].astype(bool).values\n",
    "\n",
    "    y_tr = y[m_tr]\n",
    "    y_te = y[m_te]\n",
    "    X_tr = X[m_tr] if X is not None else None\n",
    "    X_te = X[m_te] if X is not None else None\n",
    "\n",
    "    if X_tr is not None:\n",
    "        ok = ~np.isnan(y_tr)\n",
    "        y_tr, X_tr = y_tr[ok], X_tr[ok]\n",
    "        ok = ~np.isnan(X_tr).any(axis=1)\n",
    "        y_tr, X_tr = y_tr[ok], X_tr[ok]\n",
    "    else:\n",
    "        y_tr = y_tr[~np.isnan(y_tr)]\n",
    "\n",
    "    if len(y_tr) < 24:\n",
    "        return None, pd.DataFrame()\n",
    "\n",
    "    if X_te is not None and len(X_te) > 0:\n",
    "        ok_te = ~np.isnan(X_te).any(axis=1)\n",
    "        y_te = y_te[ok_te]\n",
    "        X_te = X_te[ok_te]\n",
    "\n",
    "    tried, best = [], None\n",
    "\n",
    "    for od, sod in param_grid_small(d_fix=d_fix):\n",
    "        try:\n",
    "            rec = fit_eval_level(y_tr, X_tr, y_te, X_te, od, sod)\n",
    "            tried.append(\n",
    "                {\n",
    "                    k: rec[k]\n",
    "                    for k in [\n",
    "                        \"order\",\n",
    "                        \"seasonal_order\",\n",
    "                        \"AIC_train\",\n",
    "                        \"RMSE_train\",\n",
    "                        \"MSE_train\",\n",
    "                        \"MAE_train\",\n",
    "                        \"MAPE_train\",\n",
    "                        \"sMAPE_train\",\n",
    "                        \"RMSE_test\",\n",
    "                        \"MSE_test\",\n",
    "                        \"MAE_test\",\n",
    "                        \"MAPE_test\",\n",
    "                        \"sMAPE_test\",\n",
    "                        \"LB_p12\",\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # seleksi model pakai RMSE_train + AIC_train\n",
    "            if best is None:\n",
    "                best = rec\n",
    "            else:\n",
    "                better = (\n",
    "                    (rec[\"RMSE_train\"] < best[\"RMSE_train\"]) or\n",
    "                    (\n",
    "                        rec[\"RMSE_train\"] == best[\"RMSE_train\"]\n",
    "                        and rec[\"AIC_train\"] < best[\"AIC_train\"]\n",
    "                    )\n",
    "                )\n",
    "                if better:\n",
    "                    best = rec\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    tried_df = (\n",
    "        pd.DataFrame(tried)\n",
    "        .sort_values([\"RMSE_train\", \"AIC_train\"])\n",
    "        .reset_index(drop=True)\n",
    "        if tried\n",
    "        else pd.DataFrame()\n",
    "    )\n",
    "    return best, tried_df\n",
    "\n",
    "# ---------------- PLOT TEST ----------------\n",
    "def plot_test_series(preds_df, cabang, sku, out_dir: Path):\n",
    "    d = preds_df[(preds_df[\"cabang\"] == cabang) & (preds_df[\"sku\"] == sku)].copy()\n",
    "    if d.empty:\n",
    "        return\n",
    "    d = d.sort_values(\"periode\")\n",
    "    d[\"periode\"] = pd.to_datetime(d[\"periode\"])\n",
    "    rmse_val = float(np.sqrt(np.mean((d[\"qty\"].values - d[\"pred\"].values) ** 2)))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10.5, 3.6))\n",
    "    locator = mdates.MonthLocator(interval=1)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(mdates.ConciseDateFormatter(locator))\n",
    "    ax.plot(d[\"periode\"], d[\"qty\"], lw=1.8, marker=\"o\", label=\"Actual\")\n",
    "    ax.plot(d[\"periode\"], d[\"pred\"], lw=1.8, marker=\"s\", label=\"Pred\")\n",
    "    ax.set_title(f\"{cabang}-{sku} | RMSE_test={rmse_val:.1f}\")\n",
    "    ax.set_xlabel(\"Periode\")\n",
    "    ax.set_ylabel(\"Qty\")\n",
    "    ax.grid(True, axis=\"y\", alpha=0.25)\n",
    "    ax.legend(loc=\"center left\", bbox_to_anchor=(1.02, 0.5), frameon=False)\n",
    "    fig.tight_layout(rect=[0, 0, 0.82, 1])\n",
    "    fpath = out_dir / f\"test_plot__{cabang}__{sku}.png\"\n",
    "    fig.savefig(fpath, dpi=160)\n",
    "    plt.close(fig)\n",
    "\n",
    "# ---------------- LOOP PER SERI ----------------\n",
    "records, preds = [], []\n",
    "\n",
    "pairs = (\n",
    "    df[[\"cabang\", \"sku\"]]\n",
    "    .drop_duplicates()\n",
    "    .itertuples(index=False, name=None)\n",
    ")\n",
    "\n",
    "for cab, sku in pairs:\n",
    "    g = df[(df[\"cabang\"] == cab) & (df[\"sku\"] == sku)].copy()\n",
    "\n",
    "    d_val = int(d_suggest_map.get((cab, sku), 1))\n",
    "\n",
    "    exog_candidates = []\n",
    "    exog_candidates.append((\"none\", []))\n",
    "    exog_candidates.append((\"event\", [\"event_flag\"]))\n",
    "    exog_candidates.append((\"event_hol\", [\"event_flag\", \"holiday_count\"]))\n",
    "    exog_candidates.append(\n",
    "        (\"event_hol_rain\", [\"event_flag\", \"holiday_count\", \"rainfall_lag1\"])\n",
    "    )\n",
    "\n",
    "    best_tag = None\n",
    "    best_rec = None\n",
    "    best_exog_cols = []\n",
    "\n",
    "    # pilih kombinasi exog terbaik pakai RMSE_train + AIC_train\n",
    "    for tag, cols in exog_candidates:\n",
    "        if cols and not set(cols).issubset(g.columns):\n",
    "            continue\n",
    "\n",
    "        b, _ = grid_fit_series_level(\n",
    "            g,\n",
    "            exog_cols=cols if cols else None,\n",
    "            d_fix=d_val,\n",
    "        )\n",
    "        if not b:\n",
    "            continue\n",
    "\n",
    "        if best_rec is None:\n",
    "            best_tag = tag\n",
    "            best_rec = b\n",
    "            best_exog_cols = cols\n",
    "        else:\n",
    "            better = (\n",
    "                (b[\"RMSE_train\"] < best_rec[\"RMSE_train\"]) or\n",
    "                (\n",
    "                    b[\"RMSE_train\"] == best_rec[\"RMSE_train\"]\n",
    "                    and b[\"AIC_train\"] < best_rec[\"AIC_train\"]\n",
    "                )\n",
    "            )\n",
    "            if better:\n",
    "                best_tag = tag\n",
    "                best_rec = b\n",
    "                best_exog_cols = cols\n",
    "\n",
    "    if best_rec is None:\n",
    "        print(f\"[SKIP] {cab}-{sku}: gagal fit (train terlalu pendek atau error).\")\n",
    "        continue\n",
    "\n",
    "    records.append(\n",
    "        {\n",
    "            \"cabang\": cab,\n",
    "            \"sku\": sku,\n",
    "            \"variant\": best_tag + \"+level\",\n",
    "            \"exog_used\": \",\".join(best_exog_cols) if best_exog_cols else \"(none)\",\n",
    "\n",
    "            \"order\": best_rec[\"order\"],\n",
    "            \"seasonal_order\": best_rec[\"seasonal_order\"],\n",
    "            \"AIC_train\": best_rec[\"AIC_train\"],\n",
    "\n",
    "            \"RMSE_train\": best_rec[\"RMSE_train\"],\n",
    "            \"MSE_train\": best_rec[\"MSE_train\"],\n",
    "            \"MAE_train\": best_rec[\"MAE_train\"],\n",
    "            \"MAPE%_train\": best_rec[\"MAPE_train\"],\n",
    "            \"sMAPE%_train\": best_rec[\"sMAPE_train\"],\n",
    "\n",
    "            \"RMSE_test\": best_rec[\"RMSE_test\"],\n",
    "            \"MSE_test\": best_rec[\"MSE_test\"],\n",
    "            \"MAE_test\": best_rec[\"MAE_test\"],\n",
    "            \"MAPE%_test\": best_rec[\"MAPE_test\"],\n",
    "            \"sMAPE%_test\": best_rec[\"sMAPE_test\"],\n",
    "\n",
    "            \"LB_p12\": best_rec[\"LB_p12\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    m_te = g[\"is_test\"] == 1\n",
    "    if m_te.any() and len(best_rec[\"yhat\"]) > 0:\n",
    "        preds.append(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"periode\": g.loc[m_te, \"periode\"].values,\n",
    "                    \"qty\": g.loc[m_te, \"qty\"].values,\n",
    "                    \"pred\": np.asarray(best_rec[\"yhat\"], float),\n",
    "                    \"cabang\": cab,\n",
    "                    \"sku\": sku,\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "# ---------------- OUTPUT & SAVE ----------------\n",
    "results_df = (\n",
    "    pd.DataFrame(records)\n",
    "    .sort_values([\"cabang\", \"sku\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "forecasts_df = (\n",
    "    pd.concat(preds, ignore_index=True) if len(preds) else pd.DataFrame()\n",
    ")\n",
    "\n",
    "print(\"\\n=== RINGKASAN HASIL (DATASET 15, LEVEL TARGET, TRAIN-ONLY SELECTION) - BEBERAPA BARIS ===\")\n",
    "if not results_df.empty:\n",
    "    print(\n",
    "        results_df[\n",
    "            [\n",
    "                \"cabang\",\n",
    "                \"sku\",\n",
    "                \"variant\",\n",
    "                \"exog_used\",\n",
    "                \"RMSE_train\",\n",
    "                \"MSE_train\",\n",
    "                \"MAE_train\",\n",
    "                \"MAPE%_train\",\n",
    "                \"sMAPE%_train\",\n",
    "                \"RMSE_test\",\n",
    "                \"MSE_test\",\n",
    "                \"MAE_test\",\n",
    "                \"MAPE%_test\",\n",
    "                \"sMAPE%_test\",\n",
    "                \"LB_p12\",\n",
    "            ]\n",
    "        ].head(20).to_string(index=False)\n",
    "    )\n",
    "else:\n",
    "    print(\"Tidak ada hasil. Seri terlalu pendek atau split bermasalah.\")\n",
    "\n",
    "METRICS_PATH = OUT_DIR / \"sarimax_15_level_trainselect_metrics.csv\"\n",
    "PREDS_PATH   = OUT_DIR / \"sarimax_15_level_trainselect_predictions.csv\"\n",
    "results_df.to_csv(METRICS_PATH, index=False)\n",
    "forecasts_df.to_csv(PREDS_PATH, index=False)\n",
    "print(f\"\\nSaved metrics  -> {METRICS_PATH}\")\n",
    "print(f\"Saved preds    -> {PREDS_PATH}\")\n",
    "\n",
    "if not forecasts_df.empty:\n",
    "    for cab, sk in (\n",
    "        forecasts_df[[\"cabang\", \"sku\"]].drop_duplicates().itertuples(\n",
    "            index=False, name=None\n",
    "        )\n",
    "    ):\n",
    "        plot_test_series(forecasts_df, cab, sk, CHART_DIR)\n",
    "    print(f\"Saved charts   -> {CHART_DIR}\")\n",
    "else:\n",
    "    print(\"Tidak ada prediksi test untuk digambar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a0d364b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows panel 15 : 4965\n",
      "Rows profiles : 120\n",
      "NaN rainfall_lag1: 15\n",
      "Series with test rows: 9\n",
      "\n",
      "Fitting 02A-BNOP400CHAR\n",
      "\n",
      "Fitting 02A-BNOP400CPOX\n",
      "\n",
      "Fitting 02A-BUVW001K194\n",
      "\n",
      "Fitting 02A-BUVW001KSB\n",
      "\n",
      "Fitting 02A-BUVW001KSBM\n",
      "\n",
      "Fitting 02A-BUVW001KSW\n",
      "\n",
      "Fitting 02A-BUVW100C192\n",
      "\n",
      "Fitting 02A-BUVW100CSB\n",
      "\n",
      "Fitting 02A-BUVW100CSW\n",
      "\n",
      "Fitting 02A-CKLM001KS607\n",
      "\n",
      "Fitting 02A-CKLM001KSPOL\n",
      "\n",
      "Fitting 02A-DOPQ001K001\n",
      "\n",
      "Fitting 02A-DOPQ001K009\n",
      "\n",
      "Fitting 02A-FSTU001KSB\n",
      "\n",
      "Fitting 02A-FSTU001KSW\n",
      "\n",
      "Fitting 05A-BBCD005KSW\n",
      "\n",
      "Fitting 05A-BUVW001K194\n",
      "\n",
      "Fitting 05A-BUVW001KSB\n",
      "\n",
      "Fitting 05A-BUVW001KSW\n",
      "\n",
      "Fitting 05A-BUVW100C192\n",
      "\n",
      "Fitting 05A-BUVW100CSB\n",
      "\n",
      "Fitting 05A-BUVW100CSW\n",
      "\n",
      "Fitting 05A-CKLM001KS600\n",
      "\n",
      "Fitting 05A-CKLM001KS607\n",
      "\n",
      "Fitting 05A-CKLM001KS610\n",
      "\n",
      "Fitting 05A-DKLM350C\n",
      "\n",
      "Fitting 05A-DOPQ001K009\n",
      "\n",
      "Fitting 05A-DOPQ004K009\n",
      "\n",
      "Fitting 05A-FIJK250C\n",
      "\n",
      "Fitting 05A-FSTU001KSW\n",
      "\n",
      "Fitting 13A-BBCD005KSW\n",
      "\n",
      "Fitting 13A-BUVW001KSB\n",
      "\n",
      "Fitting 13A-BUVW001KSW\n",
      "\n",
      "Fitting 13A-BUVW100CSB\n",
      "\n",
      "Fitting 13A-BUVW100CSW\n",
      "\n",
      "Fitting 13A-DKLM350C\n",
      "\n",
      "Fitting 13A-DOPQ001K002\n",
      "\n",
      "Fitting 13A-DOPQ001K009\n",
      "\n",
      "Fitting 13A-DOPQ004K002\n",
      "\n",
      "Fitting 13A-FSTU001KSW\n",
      "\n",
      "Fitting 13I-BBCD005KSW\n",
      "\n",
      "Fitting 13I-BUVW001KSB\n",
      "\n",
      "Fitting 13I-BUVW001KSW\n",
      "\n",
      "Fitting 13I-BUVW100CSB\n",
      "\n",
      "Fitting 13I-BUVW200CSB\n",
      "\n",
      "Fitting 13I-BUVW200CSW\n",
      "\n",
      "Fitting 13I-BUVW500CSB\n",
      "\n",
      "Fitting 13I-BUVW500CSW\n",
      "\n",
      "Fitting 13I-CFGH001K711\n",
      "\n",
      "Fitting 13I-CFGH001K724\n",
      "\n",
      "Fitting 13I-DOPQ001K002\n",
      "\n",
      "Fitting 13I-DOPQ001K009\n",
      "\n",
      "Fitting 13I-DOPQ004K002\n",
      "\n",
      "Fitting 13I-DOPQ004K009\n",
      "\n",
      "Fitting 13I-FIJK250C\n",
      "\n",
      "Fitting 14A-BBCD005KSW\n",
      "\n",
      "Fitting 14A-BUVW001KSB\n",
      "\n",
      "Fitting 14A-BUVW001KSW\n",
      "\n",
      "Fitting 14A-BUVW050CSB\n",
      "\n",
      "Fitting 14A-BUVW100C192\n",
      "\n",
      "Fitting 14A-BUVW100CSB\n",
      "\n",
      "Fitting 14A-BUVW100CSW\n",
      "\n",
      "Fitting 14A-BUVW200CSB\n",
      "\n",
      "Fitting 14A-BUVW200CSW\n",
      "\n",
      "Fitting 14A-DOPQ001K002\n",
      "\n",
      "Fitting 14A-DOPQ001K007\n",
      "\n",
      "Fitting 14A-DOPQ001K009\n",
      "\n",
      "Fitting 14A-DOPQ001K010\n",
      "\n",
      "Fitting 14A-DOPQ004K009\n",
      "\n",
      "Fitting 14A-FIJK250C\n",
      "\n",
      "Fitting 16C-ATUV005KSW\n",
      "\n",
      "Fitting 16C-BKLM001KHAR\n",
      "\n",
      "Fitting 16C-BKLM001KPOX\n",
      "\n",
      "Fitting 16C-BKLM200CHAR\n",
      "\n",
      "Fitting 16C-BKLM200CPOX\n",
      "\n",
      "Fitting 16C-BNOP400CPOX\n",
      "\n",
      "Fitting 16C-BUVW001KSB\n",
      "\n",
      "Fitting 16C-BUVW001KSW\n",
      "\n",
      "Fitting 16C-CFGH001K711\n",
      "\n",
      "Fitting 16C-CKLM001KS600\n",
      "\n",
      "Fitting 16C-DOPQ001K002\n",
      "\n",
      "Fitting 16C-DOPQ001K009\n",
      "\n",
      "Fitting 16C-DOPQ004K002\n",
      "\n",
      "Fitting 16C-EVWX200CHAR\n",
      "\n",
      "Fitting 16C-FIJK250C\n",
      "\n",
      "Fitting 17A-BKLM200CHAR\n",
      "\n",
      "Fitting 17A-BUVW001KSW\n",
      "\n",
      "Fitting 17A-DOPQ001K002\n",
      "\n",
      "Fitting 17A-DOPQ001K003\n",
      "\n",
      "Fitting 17A-DOPQ001K009\n",
      "\n",
      "Fitting 17A-DOPQ001K010\n",
      "\n",
      "Fitting 17A-DOPQ004K002\n",
      "\n",
      "Fitting 17A-DOPQ004K003\n",
      "\n",
      "Fitting 17A-DOPQ004K009\n",
      "\n",
      "Fitting 17A-DOPQ004K010\n",
      "\n",
      "Fitting 23A-AUVW001KA\n",
      "\n",
      "Fitting 23A-AUVW001KASP\n",
      "\n",
      "Fitting 23A-BKLM200CHAR\n",
      "\n",
      "Fitting 23A-BKLM200CPOX\n",
      "\n",
      "Fitting 23A-BNOP400CHAR\n",
      "\n",
      "Fitting 23A-BNOP400CPOX\n",
      "\n",
      "Fitting 23A-BUVW001KSB\n",
      "\n",
      "Fitting 23A-BUVW001KSW\n",
      "\n",
      "Fitting 23A-BUVW200CSW\n",
      "\n",
      "Fitting 23A-FIJK250C\n",
      "\n",
      "Fitting 29A-APQR005KSW\n",
      "\n",
      "Fitting 29A-BKLM200CHAR\n",
      "\n",
      "Fitting 29A-BKLM200CPOX\n",
      "\n",
      "Fitting 29A-BNOP400CHAR\n",
      "\n",
      "Fitting 29A-BNOP400CPOX\n",
      "\n",
      "Fitting 29A-BUVW001K192\n",
      "\n",
      "Fitting 29A-BUVW001K306\n",
      "\n",
      "Fitting 29A-BUVW001KSB\n",
      "\n",
      "Fitting 29A-BUVW001KSW\n",
      "\n",
      "Fitting 29A-BUVW200CSB\n",
      "\n",
      "Fitting 29A-BUVW200CSW\n",
      "\n",
      "Fitting 29A-BVWX001KA\n",
      "\n",
      "Fitting 29A-BVWX001KBAS\n",
      "\n",
      "Fitting 29A-FIJK250C\n",
      "\n",
      "Fitting 29A-FQRS001KLOO\n",
      "\n",
      "Saved metrics to: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_gridsearch_final\\sarimax_15_gridsearch_metrics.csv\n",
      "\n",
      "Preview metrics:\n",
      "  cabang          sku                 exog_cols      order seasonal_order  \\\n",
      "0    02A  BNOP400CHAR                event_flag  (1, 1, 0)  (0, 0, 0, 12)   \n",
      "1    02A  BNOP400CPOX                event_flag  (1, 1, 0)  (0, 0, 0, 12)   \n",
      "2    02A  BUVW001K194  event_flag+holiday_count  (1, 0, 1)  (0, 0, 0, 12)   \n",
      "3    02A   BUVW001KSB                      none  (1, 0, 2)  (0, 1, 0, 12)   \n",
      "4    02A  BUVW001KSBM  event_flag+holiday_count  (1, 0, 1)  (0, 0, 0, 12)   \n",
      "\n",
      "          aic         bic   train_mae      train_mse  train_rmse  train_mape  \\\n",
      "0  118.161986  123.152671  469.345006  381916.461476  617.993901  104.499907   \n",
      "1  118.161986  123.152671  469.345006  381916.461476  617.993901  104.499907   \n",
      "2   59.599935   67.917743  275.742308  119593.269841  345.822599   42.007140   \n",
      "3   35.127884   40.160270  569.412737  634304.302677  796.432234   55.108361   \n",
      "4   52.103048   60.420856  245.179561  107237.491490  327.471360   38.851427   \n",
      "\n",
      "   train_smape  test_mae  test_mse  test_rmse  test_mape  test_smape  \\\n",
      "0    79.450947       NaN       NaN        NaN        NaN         NaN   \n",
      "1    79.450947       NaN       NaN        NaN        NaN         NaN   \n",
      "2    42.059290       NaN       NaN        NaN        NaN         NaN   \n",
      "3    80.987855       NaN       NaN        NaN        NaN         NaN   \n",
      "4    37.640848       NaN       NaN        NaN        NaN         NaN   \n",
      "\n",
      "   gap_RMSE  ratio_RMSE  \n",
      "0       NaN         NaN  \n",
      "1       NaN         NaN  \n",
      "2       NaN         NaN  \n",
      "3       NaN         NaN  \n",
      "4       NaN         NaN  \n",
      "Saved overfit scatter: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_gridsearch_final\\sarimax_train_vs_test_rmse_scatter.png\n",
      "Plot pred vs actual: 02A BUVW001KSW\n",
      "Plot pred vs actual: 05A BUVW001KSW\n",
      "Plot pred vs actual: 13A DOPQ001K002\n",
      "Plot pred vs actual: 13I BUVW001KSW\n",
      "Plot pred vs actual: 14A BUVW001KSW\n",
      "Plot pred vs actual: 16C DOPQ001K009\n",
      "Plot pred vs actual: 17A DOPQ001K002\n",
      "Plot pred vs actual: 23A BUVW001KSW\n",
      "Plot pred vs actual: 29A BUVW001KSW\n",
      "\n",
      "Selesai SARIMAX 15 grid search + metrics + plots.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "PROJECT_ROOT  = Path(r\"D:\\Documents\\Skripsi\\demand-forecasting\")\n",
    "DATASET15_DIR = PROJECT_ROOT / \"data\" / \"dataset_15\"\n",
    "OUT_DIR       = PROJECT_ROOT / \"outputs\" / \"sarimax_15_gridsearch_final\"\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PLOT_DIR = OUT_DIR / \"plots_pred\"\n",
    "PLOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PANEL_PATH   = DATASET15_DIR / \"panel_exog_selected15.csv\"\n",
    "PROFILE_PATH = DATASET15_DIR / \"model_profiles_selected15.csv\"\n",
    "\n",
    "panel = pd.read_csv(PANEL_PATH, parse_dates=[\"periode\"])\n",
    "profiles = pd.read_csv(PROFILE_PATH)\n",
    "\n",
    "print(\"Rows panel 15 :\", len(panel))\n",
    "print(\"Rows profiles :\", len(profiles))\n",
    "\n",
    "panel = panel.sort_values([\"cabang\", \"sku\", \"periode\"]).reset_index(drop=True)\n",
    "\n",
    "if \"rainfall_lag1\" in panel.columns:\n",
    "    mask_nan = panel[\"rainfall_lag1\"].isna()\n",
    "    print(\"NaN rainfall_lag1:\", mask_nan.sum())\n",
    "    panel.loc[mask_nan, \"rainfall_lag1\"] = 0.0\n",
    "\n",
    "test_info = (\n",
    "    panel.groupby([\"cabang\", \"sku\"], as_index=False)[\"is_test\"]\n",
    "         .sum()\n",
    "         .rename(columns={\"is_test\": \"n_test\"})\n",
    ")\n",
    "eval9 = test_info.query(\"n_test > 0\").copy()\n",
    "print(\"Series with test rows:\", len(eval9))\n",
    "eval9.to_csv(OUT_DIR / \"sarimax_eval9_series.csv\", index=False)\n",
    "\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mse(y_true, y_pred))\n",
    "\n",
    "\n",
    "def mape(y_true, y_pred, eps=1e-8):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    denom = np.maximum(np.abs(y_true), eps)\n",
    "    return np.mean(np.abs(y_true - y_pred) / denom) * 100.0\n",
    "\n",
    "\n",
    "def smape(y_true, y_pred, eps=1e-8):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    denom = np.maximum(np.abs(y_true) + np.abs(y_pred), eps)\n",
    "    return np.mean(2.0 * np.abs(y_true - y_pred) / denom) * 100.0\n",
    "\n",
    "\n",
    "EXOG_COMBOS = [\n",
    "    [],\n",
    "    [\"event_flag\"],\n",
    "    [\"holiday_count\"],\n",
    "    [\"rainfall_lag1\"],\n",
    "    [\"event_flag\", \"holiday_count\"],\n",
    "    [\"event_flag\", \"rainfall_lag1\"],\n",
    "    [\"holiday_count\", \"rainfall_lag1\"],\n",
    "    [\"event_flag\", \"holiday_count\", \"rainfall_lag1\"],\n",
    "]\n",
    "\n",
    "\n",
    "def fit_sarimax_one_series(\n",
    "    g: pd.DataFrame,\n",
    "    prof_row: pd.Series,\n",
    "    seasonal_period: int = 12,\n",
    "    max_p: int = 2,\n",
    "    max_q: int = 2,\n",
    "):\n",
    "    cab = g[\"cabang\"].iloc[0]\n",
    "    sku = g[\"sku\"].iloc[0]\n",
    "\n",
    "    g = g.sort_values(\"periode\").reset_index(drop=True)\n",
    "\n",
    "    y_level = g[\"qty\"].astype(float)\n",
    "    y_log = np.log1p(y_level)\n",
    "\n",
    "    train_mask = g[\"is_train\"] == 1\n",
    "    test_mask  = g[\"is_test\"] == 1\n",
    "\n",
    "    y_train = y_log[train_mask]\n",
    "    y_test  = y_log[test_mask]\n",
    "\n",
    "    if len(y_train) < 24:\n",
    "        print(f\"{cab}-{sku}: train terlalu pendek ({len(y_train)}), skip.\")\n",
    "        return None\n",
    "\n",
    "    d_sug = int(prof_row.get(\"sarimax_d_sug\", 1))\n",
    "    D_sug = int(prof_row.get(\"sarimax_D_sug\", 0))\n",
    "    seasonal_flag = int(prof_row.get(\"seasonal_flag\", 0))\n",
    "\n",
    "    if seasonal_flag == 0:\n",
    "        P_opts = [0]\n",
    "        Q_opts = [0]\n",
    "        D_sug  = 0\n",
    "    else:\n",
    "        P_opts = [0, 1]\n",
    "        Q_opts = [0, 1]\n",
    "\n",
    "    best_result = None\n",
    "    best_res = None\n",
    "    best_exog_key = \"none\"\n",
    "    best_X_test = None\n",
    "\n",
    "    def is_better_train(new, old):\n",
    "        if old is None:\n",
    "            return True\n",
    "        # prioritas: train_rmse lebih kecil, kalau mirip pakai AIC\n",
    "        if new[\"train_rmse\"] < old[\"train_rmse\"] - 1e-6:\n",
    "            return True\n",
    "        if abs(new[\"train_rmse\"] - old[\"train_rmse\"]) <= 1e-6:\n",
    "            return new[\"aic\"] < old[\"aic\"]\n",
    "        return False\n",
    "\n",
    "    for exog_cols in EXOG_COMBOS:\n",
    "        if exog_cols:\n",
    "            X_all = g[exog_cols].copy()\n",
    "            X_train = X_all.loc[train_mask].copy()\n",
    "            X_test  = X_all.loc[test_mask].copy()\n",
    "\n",
    "            nunique_train = X_train.nunique(dropna=True)\n",
    "            keep_cols = [c for c in exog_cols if nunique_train.get(c, 0) > 1]\n",
    "\n",
    "            if not keep_cols:\n",
    "                X_all = None\n",
    "                X_train = None\n",
    "                X_test = None\n",
    "                exog_key = \"none\"\n",
    "            else:\n",
    "                X_all = X_all[keep_cols]\n",
    "                X_train = X_train[keep_cols]\n",
    "                X_test  = X_test[keep_cols]\n",
    "                exog_key = \"+\".join(keep_cols)\n",
    "        else:\n",
    "            X_all = None\n",
    "            X_train = None\n",
    "            X_test = None\n",
    "            exog_key = \"none\"\n",
    "\n",
    "        if X_train is not None and X_train.isna().any(axis=1).sum() > 0:\n",
    "            keep = ~X_train.isna().any(axis=1)\n",
    "            X_train = X_train.loc[keep]\n",
    "            y_train_eff = y_train.loc[keep]\n",
    "        else:\n",
    "            y_train_eff = y_train\n",
    "\n",
    "        if len(y_train_eff) < 20:\n",
    "            continue\n",
    "\n",
    "        for p in range(0, max_p + 1):\n",
    "            for q in range(0, max_q + 1):\n",
    "                order = (p, d_sug, q)\n",
    "\n",
    "                for P in P_opts:\n",
    "                    for Q in Q_opts:\n",
    "                        seasonal_order = (P, D_sug, Q, seasonal_period)\n",
    "\n",
    "                        try:\n",
    "                            model = SARIMAX(\n",
    "                                y_train_eff,\n",
    "                                exog=X_train,\n",
    "                                order=order,\n",
    "                                seasonal_order=seasonal_order,\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False,\n",
    "                            )\n",
    "                            res = model.fit(disp=False)\n",
    "                        except Exception:\n",
    "                            continue\n",
    "\n",
    "                        aic = res.aic\n",
    "                        bic = res.bic\n",
    "\n",
    "                        pred_train_log = res.get_prediction().predicted_mean\n",
    "                        pred_train = np.expm1(pred_train_log)\n",
    "                        y_train_level = np.expm1(y_train_eff)\n",
    "\n",
    "                        train_mae_v   = mae(y_train_level, pred_train)\n",
    "                        train_mse_v   = mse(y_train_level, pred_train)\n",
    "                        train_rmse_v  = rmse(y_train_level, pred_train)\n",
    "                        train_mape_v  = mape(y_train_level, pred_train)\n",
    "                        train_smape_v = smape(y_train_level, pred_train)\n",
    "\n",
    "                        cand = {\n",
    "                            \"cabang\": cab,\n",
    "                            \"sku\": sku,\n",
    "                            \"exog_cols\": exog_key,\n",
    "                            \"order\": order,\n",
    "                            \"seasonal_order\": seasonal_order,\n",
    "                            \"aic\": aic,\n",
    "                            \"bic\": bic,\n",
    "                            \"train_mae\": train_mae_v,\n",
    "                            \"train_mse\": train_mse_v,\n",
    "                            \"train_rmse\": train_rmse_v,\n",
    "                            \"train_mape\": train_mape_v,\n",
    "                            \"train_smape\": train_smape_v,\n",
    "                        }\n",
    "\n",
    "                        if is_better_train(cand, best_result):\n",
    "                            best_result = cand\n",
    "                            best_res = res\n",
    "                            best_exog_key = exog_key\n",
    "                            best_X_test = X_test\n",
    "\n",
    "    if best_result is None or best_res is None:\n",
    "        print(f\"{cab}-{sku}: tidak ada model yang konvergen.\")\n",
    "        return None\n",
    "\n",
    "    result = best_result.copy()\n",
    "\n",
    "    test_mae_v = test_mse_v = test_rmse_v = np.nan\n",
    "    test_mape_v = test_smape_v = np.nan\n",
    "\n",
    "    if len(y_test) > 0:\n",
    "        try:\n",
    "            if best_exog_key == \"none\" or best_X_test is None or len(best_X_test) == 0:\n",
    "                fc = best_res.get_forecast(steps=len(y_test))\n",
    "            else:\n",
    "                fc = best_res.get_forecast(steps=len(y_test), exog=best_X_test)\n",
    "\n",
    "            pred_test_log = fc.predicted_mean\n",
    "            pred_test = np.expm1(pred_test_log)\n",
    "            y_test_level = np.expm1(y_test.values)\n",
    "\n",
    "            test_mae_v   = mae(y_test_level, pred_test)\n",
    "            test_mse_v   = mse(y_test_level, pred_test)\n",
    "            test_rmse_v  = rmse(y_test_level, pred_test)\n",
    "            test_mape_v  = mape(y_test_level, pred_test)\n",
    "            test_smape_v = smape(y_test_level, pred_test)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    result[\"test_mae\"]   = test_mae_v\n",
    "    result[\"test_mse\"]   = test_mse_v\n",
    "    result[\"test_rmse\"]  = test_rmse_v\n",
    "    result[\"test_mape\"]  = test_mape_v\n",
    "    result[\"test_smape\"] = test_smape_v\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def refit_and_plot_pred(g: pd.DataFrame,\n",
    "                        order,\n",
    "                        seasonal_order,\n",
    "                        exog_key: str,\n",
    "                        save_path: Path):\n",
    "    cab = g[\"cabang\"].iloc[0]\n",
    "    sku = g[\"sku\"].iloc[0]\n",
    "\n",
    "    g = g.sort_values(\"periode\").reset_index(drop=True)\n",
    "\n",
    "    y_level = g[\"qty\"].astype(float)\n",
    "    y_log = np.log1p(y_level)\n",
    "\n",
    "    train_mask = g[\"is_train\"] == 1\n",
    "    test_mask  = g[\"is_test\"] == 1\n",
    "\n",
    "    y_train = y_log[train_mask]\n",
    "    y_test  = y_log[test_mask]\n",
    "\n",
    "    if len(y_train) == 0:\n",
    "        return\n",
    "\n",
    "    if exog_key == \"none\" or exog_key == \"\" or exog_key is None:\n",
    "        X_train = None\n",
    "        X_test = None\n",
    "    else:\n",
    "        cols = exog_key.split(\"+\")\n",
    "        X_all = g[cols].copy()\n",
    "        X_train = X_all.loc[train_mask].copy()\n",
    "        X_test  = X_all.loc[test_mask].copy()\n",
    "\n",
    "    model = SARIMAX(\n",
    "        y_train,\n",
    "        exog=X_train,\n",
    "        order=tuple(order),\n",
    "        seasonal_order=tuple(seasonal_order),\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False,\n",
    "    )\n",
    "    res = model.fit(disp=False)\n",
    "\n",
    "    pred_train_log = res.get_prediction().predicted_mean\n",
    "    pred_train = np.expm1(pred_train_log)\n",
    "    y_train_level = np.expm1(y_train)\n",
    "\n",
    "    if len(y_test) > 0:\n",
    "        if X_test is not None and len(X_test) > 0:\n",
    "            fc = res.get_forecast(steps=len(y_test), exog=X_test)\n",
    "        else:\n",
    "            fc = res.get_forecast(steps=len(y_test))\n",
    "        pred_test_log = fc.predicted_mean\n",
    "        pred_test = np.expm1(pred_test_log)\n",
    "        y_test_level = np.expm1(y_test)\n",
    "    else:\n",
    "        pred_test = None\n",
    "        y_test_level = None\n",
    "\n",
    "    periode_train = g.loc[train_mask, \"periode\"]\n",
    "    periode_test  = g.loc[test_mask, \"periode\"]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "    ax.plot(periode_train, y_train_level, marker=\"o\", label=\"actual_train\")\n",
    "    ax.plot(periode_train, pred_train, marker=\"x\", label=\"pred_train\")\n",
    "\n",
    "    if pred_test is not None and len(periode_test) > 0:\n",
    "        ax.plot(periode_test, y_test_level, marker=\"o\", label=\"actual_test\")\n",
    "        ax.plot(periode_test, pred_test, marker=\"x\", label=\"pred_test\")\n",
    "        if len(periode_train) > 0:\n",
    "            last_train = periode_train.max()\n",
    "            ax.axvline(last_train, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    all_vals = list(y_train_level.values)\n",
    "    if y_test_level is not None:\n",
    "        all_vals.extend(list(y_test_level.values))\n",
    "    if len(all_vals) > 0:\n",
    "        upper = np.percentile(all_vals, 99)\n",
    "        if upper > 0:\n",
    "            ax.set_ylim(0, upper * 1.1)\n",
    "\n",
    "    ax.set_title(f\"{cab} - {sku} (qty, train vs test)\")\n",
    "    ax.set_ylabel(\"qty\")\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(save_path, dpi=120)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "grouped = panel.groupby([\"cabang\", \"sku\"], sort=False)\n",
    "\n",
    "for (cab, sku), g in grouped:\n",
    "    prof_row = profiles[(profiles[\"cabang\"] == cab) & (profiles[\"sku\"] == sku)]\n",
    "    if prof_row.empty:\n",
    "        print(f\"Tidak ada profile untuk {cab}-{sku}, skip.\")\n",
    "        continue\n",
    "    prof_row = prof_row.iloc[0]\n",
    "\n",
    "    print(f\"\\nFitting {cab}-{sku}\")\n",
    "    res = fit_sarimax_one_series(g, prof_row)\n",
    "    if res is not None:\n",
    "        results.append(res)\n",
    "\n",
    "metrics_df = pd.DataFrame(results)\n",
    "\n",
    "metrics_df[\"gap_RMSE\"] = metrics_df[\"test_rmse\"] - metrics_df[\"train_rmse\"]\n",
    "metrics_df[\"ratio_RMSE\"] = metrics_df[\"test_rmse\"] / metrics_df[\"train_rmse\"]\n",
    "\n",
    "metrics_path = OUT_DIR / \"sarimax_15_gridsearch_metrics.csv\"\n",
    "metrics_df.to_csv(metrics_path, index=False)\n",
    "\n",
    "print(\"\\nSaved metrics to:\", metrics_path)\n",
    "print(\"\\nPreview metrics:\")\n",
    "print(metrics_df.head())\n",
    "\n",
    "has_test = metrics_df[~metrics_df[\"test_rmse\"].isna()].copy()\n",
    "overfit_path = OUT_DIR / \"sarimax_train_vs_test_rmse_scatter.png\"\n",
    "\n",
    "if not has_test.empty:\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.scatter(has_test[\"train_rmse\"], has_test[\"test_rmse\"])\n",
    "    lim_min = 0\n",
    "    lim_max = max(has_test[\"train_rmse\"].max(), has_test[\"test_rmse\"].max()) * 1.1\n",
    "    ax.plot([lim_min, lim_max], [lim_min, lim_max], linestyle=\"--\")\n",
    "    ax.set_xlabel(\"RMSE train\")\n",
    "    ax.set_ylabel(\"RMSE test\")\n",
    "    ax.set_title(\"Train vs Test RMSE (cek overfit)\")\n",
    "    ax.grid(alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(overfit_path, dpi=120)\n",
    "    plt.close(fig)\n",
    "    print(\"Saved overfit scatter:\", overfit_path)\n",
    "\n",
    "for _, row in has_test.iterrows():\n",
    "    cab = row[\"cabang\"]\n",
    "    sku = row[\"sku\"]\n",
    "    order = row[\"order\"]\n",
    "    seasonal_order = row[\"seasonal_order\"]\n",
    "    exog_key = row[\"exog_cols\"]\n",
    "\n",
    "    g = panel[(panel[\"cabang\"] == cab) & (panel[\"sku\"] == sku)].copy()\n",
    "    save_path = PLOT_DIR / f\"pred_vs_actual_{cab}_{sku}.png\"\n",
    "    print(\"Plot pred vs actual:\", cab, sku)\n",
    "    refit_and_plot_pred(g, order, seasonal_order, exog_key, save_path)\n",
    "\n",
    "print(\"\\nSelesai SARIMAX 15 grid search + metrics + plots.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a37288",
   "metadata": {},
   "source": [
    "cek biang kerok datanya "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "089c9773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows panel: 4965\n",
      "Rows metrics: 120\n",
      "Saved health stats: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_gridsearch_final\\diagnostics_drama\\sarimax_15_health_train.csv\n",
      "Saved train vs test stats: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_gridsearch_final\\diagnostics_drama\\sarimax_15_train_vs_test_stats.csv\n",
      "Saved full diagnostics: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_gridsearch_final\\diagnostics_drama\\sarimax_15_diag_full.csv\n",
      "Saved drama series: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_gridsearch_final\\diagnostics_drama\\sarimax_15_drama_series.csv\n",
      "Jumlah series drama: 44\n",
      "Saved plot: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_gridsearch_final\\diagnostics_drama\\plots_qty_drama\\qty_02A_BUVW001KSW.png\n",
      "Saved plot: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_gridsearch_final\\diagnostics_drama\\plots_qty_drama\\qty_05A_BBCD005KSW.png\n",
      "Saved plot: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_gridsearch_final\\diagnostics_drama\\plots_qty_drama\\qty_02A_FSTU001KSW.png\n",
      "Saved plot: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_gridsearch_final\\diagnostics_drama\\plots_qty_drama\\qty_13I_BUVW001KSW.png\n",
      "Saved plot: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_gridsearch_final\\diagnostics_drama\\plots_qty_drama\\qty_16C_BUVW001KSW.png\n",
      "Saved plot: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_gridsearch_final\\diagnostics_drama\\plots_qty_drama\\qty_16C_DOPQ001K002.png\n",
      "Saved plot: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_gridsearch_final\\diagnostics_drama\\plots_qty_drama\\qty_05A_BUVW001KSW.png\n",
      "Saved plot: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_gridsearch_final\\diagnostics_drama\\plots_qty_drama\\qty_02A_FSTU001KSB.png\n",
      "Saved plot: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_gridsearch_final\\diagnostics_drama\\plots_qty_drama\\qty_13I_BUVW001KSB.png\n",
      "Saved plot: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_gridsearch_final\\diagnostics_drama\\plots_qty_drama\\qty_16C_BKLM200CPOX.png\n",
      "Saved plot: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_gridsearch_final\\diagnostics_drama\\plots_qty_drama\\qty_16C_BKLM200CHAR.png\n",
      "Saved plot: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_gridsearch_final\\diagnostics_drama\\plots_qty_drama\\qty_16C_EVWX200CHAR.png\n",
      "Saved plot: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_gridsearch_final\\diagnostics_drama\\plots_qty_drama\\qty_13I_DOPQ001K002.png\n",
      "Saved plot: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_gridsearch_final\\diagnostics_drama\\plots_qty_drama\\qty_29A_BUVW001KSW.png\n",
      "Saved plot: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_gridsearch_final\\diagnostics_drama\\plots_qty_drama\\qty_16C_DOPQ004K002.png\n",
      "Selesai bikin diagnostics dan plot untuk series drama.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================================\n",
    "# PATH\n",
    "# =========================================\n",
    "PROJECT_ROOT   = Path(r\"D:\\Documents\\Skripsi\\demand-forecasting\")\n",
    "DATASET15_DIR  = PROJECT_ROOT / \"data\" / \"dataset_15\"\n",
    "OUT_DIR        = PROJECT_ROOT / \"outputs\" / \"sarimax_15_gridsearch_final\"\n",
    "\n",
    "PANEL_PATH   = DATASET15_DIR / \"panel_exog_selected15.csv\"\n",
    "METRICS_PATH = OUT_DIR / \"sarimax_15_gridsearch_metrics.csv\"\n",
    "\n",
    "DIAG_DIR     = OUT_DIR / \"diagnostics_drama\"\n",
    "DIAG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =========================================\n",
    "# LOAD DATA\n",
    "# =========================================\n",
    "panel = pd.read_csv(PANEL_PATH, parse_dates=[\"periode\"])\n",
    "metrics = pd.read_csv(METRICS_PATH)\n",
    "\n",
    "print(\"Rows panel:\", len(panel))\n",
    "print(\"Rows metrics:\", len(metrics))\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# 1. HEALTH STAT PER (CABANG, SKU) DI TRAIN\n",
    "# =========================================\n",
    "def build_health(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    g = df[df[\"is_train\"] == 1].copy()\n",
    "    g[\"qty\"] = g[\"qty\"].astype(float)\n",
    "\n",
    "    agg = (\n",
    "        g.groupby([\"cabang\", \"sku\"])[\"qty\"]\n",
    "         .agg(\n",
    "             n_train=\"count\",\n",
    "             qty_min=\"min\",\n",
    "             qty_max=\"max\",\n",
    "             qty_median=\"median\",\n",
    "             qty_mean=\"mean\",\n",
    "             qty_std=\"std\",\n",
    "         )\n",
    "         .reset_index()\n",
    "    )\n",
    "\n",
    "    # hindari bagi nol\n",
    "    eps = 1e-8\n",
    "    agg[\"max_over_median\"] = agg[\"qty_max\"] / (agg[\"qty_median\"].abs() + eps)\n",
    "    agg[\"max_over_mean\"]   = agg[\"qty_max\"] / (agg[\"qty_mean\"].abs() + eps)\n",
    "    agg[\"cv\"]              = agg[\"qty_std\"] / (agg[\"qty_mean\"].abs() + eps)\n",
    "\n",
    "    return agg\n",
    "\n",
    "\n",
    "health_df = build_health(panel)\n",
    "health_path = DIAG_DIR / \"sarimax_15_health_train.csv\"\n",
    "health_df.to_csv(health_path, index=False)\n",
    "print(\"Saved health stats:\", health_path)\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# 2. TRAIN vs TEST STATS PER SERIES\n",
    "# =========================================\n",
    "def build_train_test_stats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for (cab, sku), g in df.groupby([\"cabang\", \"sku\"]):\n",
    "        g = g.copy()\n",
    "        g[\"qty\"] = g[\"qty\"].astype(float)\n",
    "\n",
    "        tr = g[g[\"is_train\"] == 1][\"qty\"]\n",
    "        te = g[g[\"is_test\"] == 1][\"qty\"]\n",
    "\n",
    "        if len(tr) == 0:\n",
    "            continue\n",
    "\n",
    "        row = {\n",
    "            \"cabang\": cab,\n",
    "            \"sku\": sku,\n",
    "            \"train_mean\": tr.mean(),\n",
    "            \"train_std\": tr.std(),\n",
    "            \"train_max\": tr.max(),\n",
    "            \"train_min\": tr.min(),\n",
    "            \"test_mean\": np.nan,\n",
    "            \"test_std\": np.nan,\n",
    "            \"test_max\": np.nan,\n",
    "            \"test_min\": np.nan,\n",
    "            \"n_test\": len(te),\n",
    "        }\n",
    "\n",
    "        if len(te) > 0:\n",
    "            row.update(\n",
    "                test_mean=te.mean(),\n",
    "                test_std=te.std(),\n",
    "                test_max=te.max(),\n",
    "                test_min=te.min(),\n",
    "            )\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "tt_stats_df = build_train_test_stats(panel)\n",
    "tt_stats_path = DIAG_DIR / \"sarimax_15_train_vs_test_stats.csv\"\n",
    "tt_stats_df.to_csv(tt_stats_path, index=False)\n",
    "print(\"Saved train vs test stats:\", tt_stats_path)\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# 3. MERGE: METRICS + HEALTH + TRAIN/TEST STATS\n",
    "# =========================================\n",
    "diag_df = (\n",
    "    metrics\n",
    "    .merge(health_df, on=[\"cabang\", \"sku\"], how=\"left\")\n",
    "    .merge(tt_stats_df, on=[\"cabang\", \"sku\"], how=\"left\")\n",
    ")\n",
    "\n",
    "# pastikan gap_RMSE & ratio_RMSE ada (kalau skrip lama belum hitung)\n",
    "if \"gap_RMSE\" not in diag_df.columns:\n",
    "    diag_df[\"gap_RMSE\"] = diag_df[\"test_rmse\"] - diag_df[\"train_rmse\"]\n",
    "\n",
    "if \"ratio_RMSE\" not in diag_df.columns:\n",
    "    diag_df[\"ratio_RMSE\"] = diag_df[\"test_rmse\"] / diag_df[\"train_rmse\"]\n",
    "\n",
    "diag_full_path = DIAG_DIR / \"sarimax_15_diag_full.csv\"\n",
    "diag_df.to_csv(diag_full_path, index=False)\n",
    "print(\"Saved full diagnostics:\", diag_full_path)\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# 4. FILTER SERIES \"DRAMA\"\n",
    "#    - max_over_median >= 3\n",
    "#    - atau cv >= 0.8\n",
    "#    - atau train_rmse di top 10%\n",
    "# =========================================\n",
    "train_rmse_q90 = diag_df[\"train_rmse\"].quantile(0.90)\n",
    "\n",
    "drama_mask = (\n",
    "    (diag_df[\"max_over_median\"] >= 3) |\n",
    "    (diag_df[\"cv\"] >= 0.8) |\n",
    "    (diag_df[\"train_rmse\"] >= train_rmse_q90)\n",
    ")\n",
    "\n",
    "drama_df = diag_df.loc[drama_mask].copy()\n",
    "drama_df = drama_df.sort_values(\"train_rmse\", ascending=False)\n",
    "\n",
    "drama_path = DIAG_DIR / \"sarimax_15_drama_series.csv\"\n",
    "drama_df.to_csv(drama_path, index=False)\n",
    "print(\"Saved drama series:\", drama_path)\n",
    "print(\"Jumlah series drama:\", len(drama_df))\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# 5. PLOT QTY UNTUK SERIES DRAMA (TOP N)\n",
    "# =========================================\n",
    "def plot_series_qty(df_panel: pd.DataFrame,\n",
    "                    cabang: str,\n",
    "                    sku: str,\n",
    "                    out_dir: Path):\n",
    "    g = df_panel[(df_panel[\"cabang\"] == cabang) & (df_panel[\"sku\"] == sku)].copy()\n",
    "    if g.empty:\n",
    "        return\n",
    "\n",
    "    g = g.sort_values(\"periode\")\n",
    "    g[\"qty\"] = g[\"qty\"].astype(float)\n",
    "\n",
    "    train_mask = g[\"is_train\"] == 1\n",
    "    test_mask  = g[\"is_test\"] == 1\n",
    "\n",
    "    periode = g[\"periode\"]\n",
    "    qty = g[\"qty\"]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 3))\n",
    "    ax.plot(periode, qty, marker=\"o\")\n",
    "\n",
    "    if train_mask.any():\n",
    "        last_train_date = g.loc[train_mask, \"periode\"].max()\n",
    "        ax.axvline(last_train_date, color=\"grey\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    ax.set_title(f\"{cabang} - {sku} (qty bulanan)\")\n",
    "    ax.set_ylabel(\"qty\")\n",
    "    ax.grid(alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fname = f\"qty_{cabang}_{sku}.png\"\n",
    "    save_path = out_dir / fname\n",
    "    fig.savefig(save_path, dpi=120)\n",
    "    plt.close(fig)\n",
    "    print(\"Saved plot:\", save_path)\n",
    "\n",
    "\n",
    "PLOT_DIR = DIAG_DIR / \"plots_qty_drama\"\n",
    "PLOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# plot beberapa seri paling drama (misal 15 teratas)\n",
    "TOP_N = 15\n",
    "for _, row in drama_df.head(TOP_N).iterrows():\n",
    "    plot_series_qty(panel, row[\"cabang\"], row[\"sku\"], PLOT_DIR)\n",
    "\n",
    "print(\"Selesai bikin diagnostics dan plot untuk series drama.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d78c312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows panel_exog_selected15: 4965\n",
      "     periode area cabang          sku     qty  imputed  is_active train_start  \\\n",
      "0 2021-01-01   1A    02A  BNOP400CHAR   412.0        0          1  2021-01-01   \n",
      "1 2021-02-01   1A    02A  BNOP400CHAR   441.0        0          1  2021-01-01   \n",
      "2 2021-03-01   1A    02A  BNOP400CHAR  1760.0        0          1  2021-01-01   \n",
      "3 2021-04-01   1A    02A  BNOP400CHAR   502.0        0          1  2021-01-01   \n",
      "4 2021-05-01   1A    02A  BNOP400CHAR   228.0        0          1  2021-01-01   \n",
      "\n",
      "      nz_last  is_train  ...  qty_rollmean_12  qty_rollstd_12  spike_flag  \\\n",
      "0  2024-05-01         1  ...              NaN             NaN           0   \n",
      "1  2024-05-01         1  ...           412.00             NaN           0   \n",
      "2  2024-05-01         1  ...           426.50       20.506097           0   \n",
      "3  2024-05-01         1  ...           871.00      770.033116           0   \n",
      "4  2024-05-01         1  ...           778.75      655.241113           0   \n",
      "\n",
      "   sample_weight  month  year  qtr  selected15  eligible_model  alive_recent  \n",
      "0            1.0      1  2021    1           1               1             1  \n",
      "1            1.0      2  2021    1           1               1             1  \n",
      "2            1.0      3  2021    1           1               1             1  \n",
      "3            1.0      4  2021    2           1               1             1  \n",
      "4            1.0      5  2021    2           1               1             1  \n",
      "\n",
      "[5 rows x 42 columns]\n",
      "\n",
      "Top 15 SKU paling drama (banyak bulan qty > 3x median):\n",
      "cabang          sku  n_train  qty_median    qty_mean  qty_max  n_spike_3x_median  prop_spike_3x_median  max_over_median  max_over_mean       cv\n",
      "   16C  DOPQ001K002       41      2224.0 4129.804878  16351.0                  9              0.219512         7.352068       3.959267 1.074772\n",
      "   16C  BKLM001KHAR       41      1104.0 2545.024390  16239.0                  8              0.195122        14.709239       6.380685 1.303653\n",
      "   16C  BKLM001KPOX       41      1104.0 2545.024390  16239.0                  8              0.195122        14.709239       6.380685 1.303653\n",
      "   02A  BNOP400CHAR       41       483.0  756.121951   4052.0                  8              0.195122         8.389234       5.358924 1.008508\n",
      "   02A  BNOP400CPOX       41       483.0  756.121951   4052.0                  8              0.195122         8.389234       5.358924 1.008508\n",
      "   16C  DOPQ004K002       41      1369.0 2246.707317   7751.0                  8              0.195122         5.661797       3.449938 0.993664\n",
      "   16C  EVWX200CHAR       41      2154.0 3689.073171  11964.0                  8              0.195122         5.554318       3.243091 0.885410\n",
      "   16C  BKLM200CHAR       41      2237.0 3987.024390  23420.0                  7              0.170732        10.469379       5.874055 1.206657\n",
      "   16C  BKLM200CPOX       41      2237.0 3987.024390  23420.0                  7              0.170732        10.469379       5.874055 1.206657\n",
      "   16C   BUVW001KSW       41      4029.0 6599.121951  28441.0                  7              0.170732         7.059072       4.309816 1.033651\n",
      "   16C  DOPQ001K009       41      1366.0 2095.439024  10086.0                  6              0.146341         7.383602       4.813311 1.012408\n",
      "   16C  BNOP400CPOX       41      1094.0 1621.097561   6414.0                  6              0.146341         5.862888       3.956579 0.911403\n",
      "   13I   BUVW001KSB       41      2327.0 3535.439024  13637.0                  6              0.146341         5.860335       3.857230 0.738839\n",
      "   16C CKLM001KS600       41      1100.0 1479.146341   5928.0                  5              0.121951         5.389091       4.007717 0.924645\n",
      "   13I   BUVW001KSW       41      6881.0 9428.195122  27122.0                  5              0.121951         3.941578       2.876691 0.742850\n",
      "\n",
      "SKU dengan >= 3 bulan qty > 3x median:\n",
      "cabang          sku  n_train  qty_median    qty_mean  qty_max  n_spike_3x_median  prop_spike_3x_median  max_over_median  max_over_mean       cv\n",
      "   16C  DOPQ001K002       41      2224.0 4129.804878  16351.0                  9              0.219512         7.352068       3.959267 1.074772\n",
      "   16C  BKLM001KHAR       41      1104.0 2545.024390  16239.0                  8              0.195122        14.709239       6.380685 1.303653\n",
      "   16C  BKLM001KPOX       41      1104.0 2545.024390  16239.0                  8              0.195122        14.709239       6.380685 1.303653\n",
      "   02A  BNOP400CHAR       41       483.0  756.121951   4052.0                  8              0.195122         8.389234       5.358924 1.008508\n",
      "   02A  BNOP400CPOX       41       483.0  756.121951   4052.0                  8              0.195122         8.389234       5.358924 1.008508\n",
      "   16C  DOPQ004K002       41      1369.0 2246.707317   7751.0                  8              0.195122         5.661797       3.449938 0.993664\n",
      "   16C  EVWX200CHAR       41      2154.0 3689.073171  11964.0                  8              0.195122         5.554318       3.243091 0.885410\n",
      "   16C  BKLM200CHAR       41      2237.0 3987.024390  23420.0                  7              0.170732        10.469379       5.874055 1.206657\n",
      "   16C  BKLM200CPOX       41      2237.0 3987.024390  23420.0                  7              0.170732        10.469379       5.874055 1.206657\n",
      "   16C   BUVW001KSW       41      4029.0 6599.121951  28441.0                  7              0.170732         7.059072       4.309816 1.033651\n",
      "   16C  DOPQ001K009       41      1366.0 2095.439024  10086.0                  6              0.146341         7.383602       4.813311 1.012408\n",
      "   16C  BNOP400CPOX       41      1094.0 1621.097561   6414.0                  6              0.146341         5.862888       3.956579 0.911403\n",
      "   13I   BUVW001KSB       41      2327.0 3535.439024  13637.0                  6              0.146341         5.860335       3.857230 0.738839\n",
      "   16C CKLM001KS600       41      1100.0 1479.146341   5928.0                  5              0.121951         5.389091       4.007717 0.924645\n",
      "   13I   BUVW001KSW       41      6881.0 9428.195122  27122.0                  5              0.121951         3.941578       2.876691 0.742850\n",
      "   16C   BUVW001KSB       41      1496.0 2065.146341  10174.0                  4              0.097561         6.800802       4.926527 0.896248\n",
      "   29A   BUVW001KSW       41      3167.0 4059.926829  15225.0                  4              0.097561         4.807389       3.750068 0.685273\n",
      "   29A  BNOP400CHAR       41       646.0  888.804878   3012.0                  4              0.097561         4.662539       3.388820 0.734430\n",
      "   29A  BNOP400CPOX       41       646.0  888.804878   3012.0                  4              0.097561         4.662539       3.388820 0.734430\n",
      "   16C  CFGH001K711       41       942.0 1313.146341   3850.0                  4              0.097561         4.087049       2.931890 0.678296\n",
      "   13I  CFGH001K711       41      1882.0 2634.926829   7363.0                  4              0.097561         3.912327       2.794385 0.705339\n",
      "   13I  DOPQ004K002       41      1061.0 1569.341463   4040.0                  4              0.097561         3.807729       2.574328 0.683900\n",
      "   13I  DOPQ001K002       41      3191.0 4667.073171  11353.0                  4              0.097561         3.557819       2.432574 0.666798\n",
      "   29A  BKLM200CHAR       41       932.0 1361.073171   6229.0                  3              0.073171         6.683476       4.576536 1.000098\n",
      "   29A  BKLM200CPOX       41       932.0 1361.073171   6229.0                  3              0.073171         6.683476       4.576536 1.000098\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ======================================================\n",
    "# PATH & LOAD DATA\n",
    "# ======================================================\n",
    "PROJECT_ROOT   = Path(r\"D:\\Documents\\Skripsi\\demand-forecasting\")\n",
    "DATASET15_DIR  = PROJECT_ROOT / \"data\" / \"dataset_15\"\n",
    "PANEL_PATH     = DATASET15_DIR / \"panel_exog_selected15.csv\"\n",
    "\n",
    "panel = pd.read_csv(PANEL_PATH, parse_dates=[\"periode\"])\n",
    "\n",
    "print(\"Rows panel_exog_selected15:\", len(panel))\n",
    "print(panel.head())\n",
    "\n",
    "# ======================================================\n",
    "# FILTER TRAIN ONLY (sesuai skema kamu)\n",
    "# ======================================================\n",
    "train = panel[panel[\"is_train\"] == 1].copy()\n",
    "\n",
    "# Kalau kamu mau pastikan hanya 15 SKU terpilih:\n",
    "# train = train[train[\"selected15\"] == 1].copy()\n",
    "\n",
    "group_cols = [\"cabang\", \"sku\"]\n",
    "\n",
    "# ======================================================\n",
    "# 1) STATISTIK PER (CABANG, SKU)\n",
    "# ======================================================\n",
    "agg_stats = (\n",
    "    train\n",
    "    .groupby(group_cols)[\"qty\"]\n",
    "    .agg(\n",
    "        n_train   = \"size\",\n",
    "        qty_min   = \"min\",\n",
    "        qty_max   = \"max\",\n",
    "        qty_median= \"median\",\n",
    "        qty_mean  = \"mean\",\n",
    "        qty_std   = \"std\"\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Turunan: max / median, max / mean, CV\n",
    "agg_stats[\"max_over_median\"] = agg_stats[\"qty_max\"] / agg_stats[\"qty_median\"].replace(0, np.nan)\n",
    "agg_stats[\"max_over_mean\"]   = agg_stats[\"qty_max\"] / agg_stats[\"qty_mean\"].replace(0, np.nan)\n",
    "agg_stats[\"cv\"]              = agg_stats[\"qty_std\"] / agg_stats[\"qty_mean\"].replace(0, np.nan)\n",
    "\n",
    "# ======================================================\n",
    "# 2) HITUNG JUMLAH BULAN DENGAN QTY > 3x MEDIAN\n",
    "# ======================================================\n",
    "\n",
    "# temp: tempel median ke level baris bulanan\n",
    "train = train.merge(\n",
    "    agg_stats[group_cols + [\"qty_median\", \"n_train\"]],\n",
    "    on=group_cols,\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Flag spike 3x median\n",
    "train[\"is_spike_3x_median\"] = train[\"qty\"] > (3 * train[\"qty_median\"])\n",
    "\n",
    "spike_stats = (\n",
    "    train\n",
    "    .groupby(group_cols)[\"is_spike_3x_median\"]\n",
    "    .agg(n_spike_3x_median=\"sum\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Merge balik ke summary\n",
    "merged = agg_stats.merge(spike_stats, on=group_cols, how=\"left\")\n",
    "\n",
    "merged[\"n_spike_3x_median\"] = merged[\"n_spike_3x_median\"].fillna(0).astype(int)\n",
    "merged[\"prop_spike_3x_median\"] = merged[\"n_spike_3x_median\"] / merged[\"n_train\"]\n",
    "\n",
    "# ======================================================\n",
    "# 3) LIST SKU PALING DRAMA\n",
    "# ======================================================\n",
    "\n",
    "top_spiky = (\n",
    "    merged\n",
    "    .sort_values(\n",
    "        [\"n_spike_3x_median\", \"prop_spike_3x_median\", \"max_over_median\"],\n",
    "        ascending=[False, False, False]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\nTop 15 SKU paling drama (banyak bulan qty > 3x median):\")\n",
    "print(\n",
    "    top_spiky[\n",
    "        [\n",
    "            \"cabang\", \"sku\",\n",
    "            \"n_train\",\n",
    "            \"qty_median\", \"qty_mean\", \"qty_max\",\n",
    "            \"n_spike_3x_median\", \"prop_spike_3x_median\",\n",
    "            \"max_over_median\", \"max_over_mean\", \"cv\"\n",
    "        ]\n",
    "    ]\n",
    "    .head(15)\n",
    "    .to_string(index=False)\n",
    ")\n",
    "\n",
    "# Opsional: hanya SKU yang punya >= 3 bulan spike\n",
    "spiky_only = top_spiky[top_spiky[\"n_spike_3x_median\"] >= 3]\n",
    "\n",
    "print(\"\\nSKU dengan >= 3 bulan qty > 3x median:\")\n",
    "print(\n",
    "    spiky_only[\n",
    "        [\n",
    "            \"cabang\", \"sku\",\n",
    "            \"n_train\",\n",
    "            \"qty_median\", \"qty_mean\", \"qty_max\",\n",
    "            \"n_spike_3x_median\", \"prop_spike_3x_median\",\n",
    "            \"max_over_median\", \"max_over_mean\", \"cv\"\n",
    "        ]\n",
    "    ]\n",
    "    .to_string(index=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591cccb4",
   "metadata": {},
   "source": [
    "coba lg tambah spike sebagai exog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "349a480d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows panel_exog_selected15: 4965\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 1) seas=(0, 0, 0, 12) exog=event_holiday_rain target=level | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 1) seas=(0, 0, 0, 12) exog=event_holiday_rain target=log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 1) seas=(0, 0, 0, 12) exog=event_holiday_rain target=robust_log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 1) seas=(0, 0, 0, 12) exog=event_holiday_rain_spike target=level | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 1) seas=(0, 0, 0, 12) exog=event_holiday_rain_spike target=log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 1) seas=(0, 0, 0, 12) exog=event_holiday_rain_spike target=robust_log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 1) seas=(0, 1, 1, 12) exog=event_holiday_rain target=level | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 1) seas=(0, 1, 1, 12) exog=event_holiday_rain target=log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 1) seas=(0, 1, 1, 12) exog=event_holiday_rain target=robust_log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 1) seas=(0, 1, 1, 12) exog=event_holiday_rain_spike target=level | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 1) seas=(0, 1, 1, 12) exog=event_holiday_rain_spike target=log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 1) seas=(0, 1, 1, 12) exog=event_holiday_rain_spike target=robust_log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 2) seas=(0, 0, 0, 12) exog=event_holiday_rain target=level | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 2) seas=(0, 0, 0, 12) exog=event_holiday_rain target=log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 2) seas=(0, 0, 0, 12) exog=event_holiday_rain target=robust_log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 2) seas=(0, 0, 0, 12) exog=event_holiday_rain_spike target=level | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 2) seas=(0, 0, 0, 12) exog=event_holiday_rain_spike target=log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 2) seas=(0, 0, 0, 12) exog=event_holiday_rain_spike target=robust_log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 2) seas=(0, 1, 1, 12) exog=event_holiday_rain target=level | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 2) seas=(0, 1, 1, 12) exog=event_holiday_rain target=log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 2) seas=(0, 1, 1, 12) exog=event_holiday_rain target=robust_log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 2) seas=(0, 1, 1, 12) exog=event_holiday_rain_spike target=level | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 2) seas=(0, 1, 1, 12) exog=event_holiday_rain_spike target=log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(0, 1, 2) seas=(0, 1, 1, 12) exog=event_holiday_rain_spike target=robust_log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 1) seas=(0, 0, 0, 12) exog=event_holiday_rain target=level | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 1) seas=(0, 0, 0, 12) exog=event_holiday_rain target=log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 1) seas=(0, 0, 0, 12) exog=event_holiday_rain target=robust_log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 1) seas=(0, 0, 0, 12) exog=event_holiday_rain_spike target=level | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 1) seas=(0, 0, 0, 12) exog=event_holiday_rain_spike target=log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 1) seas=(0, 0, 0, 12) exog=event_holiday_rain_spike target=robust_log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 1) seas=(0, 1, 1, 12) exog=event_holiday_rain target=level | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 1) seas=(0, 1, 1, 12) exog=event_holiday_rain target=log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 1) seas=(0, 1, 1, 12) exog=event_holiday_rain target=robust_log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 1) seas=(0, 1, 1, 12) exog=event_holiday_rain_spike target=level | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 1) seas=(0, 1, 1, 12) exog=event_holiday_rain_spike target=log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 1) seas=(0, 1, 1, 12) exog=event_holiday_rain_spike target=robust_log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 2) seas=(0, 0, 0, 12) exog=event_holiday_rain target=level | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 2) seas=(0, 0, 0, 12) exog=event_holiday_rain target=log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 2) seas=(0, 0, 0, 12) exog=event_holiday_rain target=robust_log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 2) seas=(0, 0, 0, 12) exog=event_holiday_rain_spike target=level | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 2) seas=(0, 0, 0, 12) exog=event_holiday_rain_spike target=log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 2) seas=(0, 0, 0, 12) exog=event_holiday_rain_spike target=robust_log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 2) seas=(0, 1, 1, 12) exog=event_holiday_rain target=level | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 2) seas=(0, 1, 1, 12) exog=event_holiday_rain target=log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 2) seas=(0, 1, 1, 12) exog=event_holiday_rain target=robust_log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 2) seas=(0, 1, 1, 12) exog=event_holiday_rain_spike target=level | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 2) seas=(0, 1, 1, 12) exog=event_holiday_rain_spike target=log1p | err=exog contains inf or nans\n",
      "Skip 16C DOPQ001K009 | order=(1, 1, 2) seas=(0, 1, 1, 12) exog=event_holiday_rain_spike target=robust_log1p | err=exog contains inf or nans\n",
      "Selesai. Rows hasil: 1032\n",
      "Saved to: D:\\Documents\\Skripsi\\demand-forecasting\\outputs\\sarimax_15_robust_spike\\sarimax_15_robust_spike_results.csv\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# SARIMAX BASELINE + ROBUST + SPIKE_FLAG EXOG\n",
    "# - Data: panel_exog_selected15.csv\n",
    "# - Kombinasi exog:\n",
    "#     (1) none\n",
    "#     (2) event_flag\n",
    "#     (3) event_flag + holiday_count\n",
    "#     (4) event_flag + holiday_count + rainfall_lag1\n",
    "#     (5) event_flag + holiday_count + rainfall_lag1 + spike_flag\n",
    "# - Target mode:\n",
    "#     - \"level\"          : qty\n",
    "#     - \"log1p\"          : log1p(qty)\n",
    "#     - \"robust_log1p\"   : log1p(qty_cap)  [qty_cap = min(qty, 3×median_train) di train]\n",
    "# - Evaluasi SELALU di level qty asli\n",
    "# =========================================================\n",
    "\n",
    "import warnings\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning, ValueWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ValueWarning)\n",
    "\n",
    "# ---------------- PATH ----------------\n",
    "PROJECT_ROOT   = Path(r\"D:\\Documents\\Skripsi\\demand-forecasting\")\n",
    "DATASET15_DIR  = PROJECT_ROOT / \"data\" / \"dataset_15\"\n",
    "OUT_DIR        = PROJECT_ROOT / \"outputs\" / \"sarimax_15_robust_spike\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PANEL_PATH   = DATASET15_DIR / \"panel_exog_selected15.csv\"\n",
    "PROFILE_PATH = DATASET15_DIR / \"model_profiles_selected15.csv\"  # kalau mau pakai d_suggest\n",
    "\n",
    "# ---------------- LOAD DATA ----------------\n",
    "panel = pd.read_csv(PANEL_PATH, parse_dates=[\"periode\"])\n",
    "profiles = pd.read_csv(PROFILE_PATH)\n",
    "\n",
    "print(\"Rows panel_exog_selected15:\", len(panel))\n",
    "\n",
    "# Kita pakai hanya SKU yang selected15 == 1 dan eligible_model == 1\n",
    "panel = panel[(panel[\"selected15\"] == 1) & (panel[\"eligible_model\"] == 1)].copy()\n",
    "\n",
    "# ---------------- ROBUST: HITUNG MEDIAN TRAIN + CAP ----------------\n",
    "train_stats = (\n",
    "    panel[panel[\"is_train\"] == 1]\n",
    "    .groupby([\"cabang\", \"sku\"])[\"qty\"]\n",
    "    .median()\n",
    "    .rename(\"qty_median_train\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "panel = panel.merge(train_stats, on=[\"cabang\", \"sku\"], how=\"left\")\n",
    "\n",
    "factor = 3.0\n",
    "panel[\"qty_cap\"] = np.where(\n",
    "    panel[\"is_train\"] == 1,\n",
    "    np.minimum(panel[\"qty\"], factor * panel[\"qty_median_train\"]),\n",
    "    panel[\"qty\"]  # test tetap pakai qty asli\n",
    ")\n",
    "\n",
    "# ---------------- PARAM: GRID ORDER + EXOG SET ----------------\n",
    "\n",
    "# Kalau kamu punya grid sendiri, ganti bagian ini\n",
    "ORDERS = [\n",
    "    (0, 1, 1),\n",
    "    (0, 1, 2),\n",
    "    (1, 1, 1),\n",
    "    (1, 1, 2),\n",
    "]\n",
    "\n",
    "SEASONAL_ORDERS = [\n",
    "    (0, 0, 0, 12),\n",
    "    (0, 1, 1, 12),\n",
    "]\n",
    "\n",
    "EXOG_SETS = {\n",
    "    \"none\": [],\n",
    "    \"event\": [\"event_flag\"],\n",
    "    \"event_holiday\": [\"event_flag\", \"holiday_count\"],\n",
    "    \"event_holiday_rain\": [\"event_flag\", \"holiday_count\", \"rainfall_lag1\"],\n",
    "    \"event_holiday_rain_spike\": [\"event_flag\", \"holiday_count\", \"rainfall_lag1\", \"spike_flag\"],\n",
    "}\n",
    "\n",
    "TARGET_MODES = [\"level\", \"log1p\", \"robust_log1p\"]  # robust tambahannya\n",
    "\n",
    "# ---------------- METRIC HELPER ----------------\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # MAPE: abaikan bulan dengan qty 0\n",
    "    mask = y_true > 0\n",
    "    if mask.sum() > 0:\n",
    "        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    else:\n",
    "        mape = np.nan\n",
    "\n",
    "    # sMAPE\n",
    "    denom = np.abs(y_true) + np.abs(y_pred)\n",
    "    smape = np.mean(\n",
    "        np.where(\n",
    "            denom == 0,\n",
    "            0,\n",
    "            2 * np.abs(y_true - y_pred) / denom\n",
    "        )\n",
    "    ) * 100\n",
    "\n",
    "    return mae, mse, rmse, mape, smape\n",
    "\n",
    "# ---------------- LOOP PER SERI ----------------\n",
    "\n",
    "results = []\n",
    "\n",
    "# Ambil daftar seri dari profiles biar konsisten\n",
    "keys = profiles[[\"cabang\", \"sku\"]].drop_duplicates()\n",
    "\n",
    "for _, row in keys.iterrows():\n",
    "    cabang = row[\"cabang\"]\n",
    "    sku    = row[\"sku\"]\n",
    "\n",
    "    df_cs = panel[(panel[\"cabang\"] == cabang) & (panel[\"sku\"] == sku)].sort_values(\"periode\")\n",
    "    if df_cs.empty:\n",
    "        continue\n",
    "\n",
    "    train_df = df_cs[df_cs[\"is_train\"] == 1]\n",
    "    test_df  = df_cs[df_cs[\"is_test\"] == 1]\n",
    "\n",
    "    if len(train_df) < 24 or len(test_df) == 0:\n",
    "        # malas berantem dengan seri yang pendek\n",
    "        continue\n",
    "\n",
    "    y_train_level = train_df[\"qty\"].astype(float)\n",
    "    y_train_log   = np.log1p(y_train_level.clip(lower=0))\n",
    "    y_train_cap   = train_df[\"qty_cap\"].astype(float)\n",
    "    y_train_robust_log = np.log1p(y_train_cap.clip(lower=0))\n",
    "\n",
    "    y_test = test_df[\"qty\"].astype(float)\n",
    "\n",
    "    # optional: ambil d_suggest kalau mau nyocokkan order dengan profil\n",
    "    prof_row = profiles[(profiles[\"cabang\"] == cabang) & (profiles[\"sku\"] == sku)]\n",
    "    if not prof_row.empty and \"suggest_d\" in prof_row.columns:\n",
    "        d_suggest = int(prof_row[\"suggest_d\"].iloc[0])\n",
    "    else:\n",
    "        d_suggest = 1\n",
    "\n",
    "    # filter ORDERS yang d-nya sesuai d_suggest, kalau ingin\n",
    "    orders_use = [o for o in ORDERS if o[1] == d_suggest] or ORDERS\n",
    "\n",
    "    for order, seasonal_order, (exog_name, exog_cols), target_mode in itertools.product(\n",
    "        orders_use,\n",
    "        SEASONAL_ORDERS,\n",
    "        EXOG_SETS.items(),\n",
    "        TARGET_MODES\n",
    "    ):\n",
    "        # siapkan exog\n",
    "        if exog_cols:\n",
    "            exog_train = train_df[exog_cols].astype(float)\n",
    "            exog_test  = test_df[exog_cols].astype(float)\n",
    "        else:\n",
    "            exog_train = None\n",
    "            exog_test  = None\n",
    "\n",
    "        # pilih target train sesuai mode\n",
    "        if target_mode == \"level\":\n",
    "            y_train = y_train_level\n",
    "            use_log = False\n",
    "            use_robust = False\n",
    "        elif target_mode == \"log1p\":\n",
    "            y_train = y_train_log\n",
    "            use_log = True\n",
    "            use_robust = False\n",
    "        elif target_mode == \"robust_log1p\":\n",
    "            y_train = y_train_robust_log\n",
    "            use_log = True\n",
    "            use_robust = True\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            model = SARIMAX(\n",
    "                endog=y_train,\n",
    "                exog=exog_train,\n",
    "                order=order,\n",
    "                seasonal_order=seasonal_order,\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False,\n",
    "            )\n",
    "            res = model.fit(disp=False)\n",
    "\n",
    "            # forecasting untuk test\n",
    "            n_test = len(test_df)\n",
    "            fc = res.get_forecast(steps=n_test, exog=exog_test)\n",
    "            y_pred_raw = fc.predicted_mean\n",
    "\n",
    "            if use_log:\n",
    "                y_pred = np.expm1(y_pred_raw)\n",
    "                y_pred = np.clip(y_pred, a_min=0, a_max=None)\n",
    "            else:\n",
    "                y_pred = y_pred_raw\n",
    "\n",
    "            mae, mse, rmse, mape, smape = calc_metrics(y_test, y_pred)\n",
    "\n",
    "            results.append({\n",
    "                \"cabang\": cabang,\n",
    "                \"sku\": sku,\n",
    "                \"order\": order,\n",
    "                \"seasonal_order\": seasonal_order,\n",
    "                \"exog_name\": exog_name,\n",
    "                \"target_mode\": target_mode,\n",
    "                \"aic\": res.aic,\n",
    "                \"bic\": res.bic,\n",
    "                \"train_n\": len(train_df),\n",
    "                \"test_n\": len(test_df),\n",
    "                \"train_end\": train_df[\"periode\"].max(),\n",
    "                \"test_start\": test_df[\"periode\"].min(),\n",
    "                \"test_end\": test_df[\"periode\"].max(),\n",
    "                \"test_mae\": mae,\n",
    "                \"test_mse\": mse,\n",
    "                \"test_rmse\": rmse,\n",
    "                \"test_mape\": mape,\n",
    "                \"test_smape\": smape,\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            # kalau seri ini kombinasi tertentu meledak, abaikan\n",
    "            print(f\"Skip {cabang} {sku} | order={order} seas={seasonal_order} exog={exog_name} target={target_mode} | err={e}\")\n",
    "            continue\n",
    "\n",
    "# ---------------- SIMPAN HASIL ----------------\n",
    "results_df = pd.DataFrame(results)\n",
    "out_path = OUT_DIR / \"sarimax_15_robust_spike_results.csv\"\n",
    "results_df.to_csv(out_path, index=False)\n",
    "print(\"Selesai. Rows hasil:\", len(results_df))\n",
    "print(\"Saved to:\", out_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
